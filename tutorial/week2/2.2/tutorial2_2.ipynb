{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"tutorial2_2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2.2: Dictionaries\n",
    "\n",
    "Welcome to Tutorial 2.2!  In Thursday's class we discussed some dictionary based methods\n",
    "\n",
    "In this tutorial, we will learn how to use 2 popular dictionaries: `WordNet` and `VADER`. \n",
    "We will use `WordNet` to explore the relationship between different words and coginitive concepts and we will use `VADER` to re-implement this [NPR story](https://www.npr.org/2017/04/30/526106612/what-we-learned-about-the-mood-of-trumps-tweets) that shows these last first 100 days of Trump's Presidency were a roller coaster of emotion.\n",
    "\n",
    "First, set up the tests and imports by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, but please don't change it.\n",
    "\n",
    "# These lines load the tests.\n",
    "import otter\n",
    "grader = otter.Notebook()\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. WordNet\n",
    "\n",
    "WordNet is lexical database where nouns, verbs, adjectives, and adverbs are group into distinct cognitive concepts. \n",
    "The concepts are called synsets. According to the [NLTK textbook](http://www.nltk.org/book/ch02.html#sec-wordnet):\n",
    "\n",
    "> WordNet is a semantically-oriented dictionary of English, similar to a traditional thesaurus but with a richer structure.\n",
    "\n",
    "In WordNet, synsets are linked via semantic relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_1\n",
    "points: 6\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "Begin by reading this short [paper](https://dl.acm.org/doi/pdf/10.1145/219717.219748) that provides an overview of WordNet.\n",
    "\n",
    "**Question 1.1:** What are the 6 types of semantic relations in WordNet? Briefly explain in your own words each semantic relationship and provide an example for each. The examples should not be one from the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### 1.1 Using WordNet in NLTK \n",
    "\n",
    "The next line will import `WordNet` from `nltk`. The `as` command in the import statement renames the `wordnet` module as `wn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can determine the synset of a word by using the `wn.synsets()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_motorcar = wn.synsets('motorcars')\n",
    "syn_motorcar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_2\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "**Question 1.2:** When we pass in a word as an argument to `wn.sysnsets()`, why data type is returned?\n",
    "Assign the type to the variable `sysnsets_func_return_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sysnsets_func_return_type = ...\n",
    "sysnsets_func_return_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can see that WordNet only has one synset for the word `motorcars`. Run the next cell to see how many sysnsets WordNet has for the word \"car\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synsets('car')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_3\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "**Question 1.3:** How many sysnsets are there for the word `car`? Assign the value to the variable named `num_car_syns` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_car_syns = ...\n",
    "num_car_syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 WordNet Online Interface\n",
    "\n",
    "WordNet has an [online interface](http://wordnetweb.princeton.edu/perl/webwn) where you can interactively search WordNet via your web browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_4\n",
    "points: 2.5\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 1.4:** Use the online interface to search for `car`. According to your search, what is the gloss (definition) for each of these synsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "#### 1.1.2 Synset Object\n",
    "\n",
    "NLTK has an object type called `Synset` that it uses to represent WordNet sysnets.\n",
    "\n",
    "The next line extracts the first synset for the word car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_syns = wn.synsets('car')\n",
    "first_car_syn = cars_syns[0]\n",
    "first_car_syn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next line prints out all functions and attributes that each `Synset` object has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(dir(first_car_syn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_5\n",
    "points: 2\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 1.5:** Complete the missing lines in the next cell to print out the names and definitions of each synset in `cars_syns`.\n",
    "\n",
    "*Hint:* The necessary functions or attributes are listed in the output of the previous cell\n",
    "    \n",
    "*Hint:* The definitions should match (or be close) to what you found online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for car_syn in cars_syns:\n",
    "    syn_name = ...\n",
    "    syn_explanation = ...\n",
    "    print(syn_name, syn_explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "A synset object lists the lemmas that are associated with the synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_car_syn.lemma_names(), first_car_syn.lemmas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above are the lemmas that are associated with the synset `car.n.01`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [documentation](https://www.nltk.org/api/nltk.corpus.reader.html#nltk.corpus.reader.wordnet.Lemma), each lemma object in WordNet has the following attributes:\n",
    ">     - name: The canonical name of this lemma.\n",
    "    - synset: The synset that this lemma belongs to.\n",
    "    - syntactic_marker: For adjectives, the WordNet string identifying the\n",
    "      syntactic position relative modified noun. See:\n",
    "      https://wordnet.princeton.edu/documentation/wninput5wn\n",
    "      For all other parts of speech, this attribute is None.\n",
    "    - count: The frequency of this lemma in wordnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_6\n",
    "points: \n",
    "    - 0.1\n",
    "    - 0.9\n",
    "-->\n",
    "\n",
    "**Question 1.6:** Based on the documentation, which of `first_car_syn`'s lemmas appears the most in WordNet? Assign the name of the lemma to the variable `most_freq_car_n_01_lemma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_car_n_01_lemma = ...\n",
    "f\"The most frequency lemma is {most_freq_car_n_01_lemma}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Tree Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`WordNet` is structured as a tree where Sysnsets have a hierarchy based on the relationships described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_7\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 1.7:** Run and then briefly describe the next line in light of the structure of WordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_car_syn.hypernym_paths()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "In the next line we can see how a synset can have multiple paths to the root of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_car_syn.hypernym_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_8\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 1.8:** These two paths look similar but there is a difference. What is the difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "We can use this tree structure to determine what type of synset one sysnet is as well as what are the types of sysnet that are examples of a synset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_9\n",
    "points: \n",
    "    - 0.1\n",
    "    - 0.9\n",
    "-->\n",
    "\n",
    "**Question 1.9:** According to WordNet, `first_car_synset` is a type of what synset? Use the function that represents the correct relationship you described in the begining of this assignment and assign the name of that sysnset to the variable `first_car_syn_type_of`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_car_syn_type_of = ...\n",
    "f\"The first car synset is a type of {first_car_syn_type_of}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_10\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 1.10:** What relationship will give us examples of this car synset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_11\n",
    "points: \n",
    "    - 0.1\n",
    "    - 0.9\n",
    "-->\n",
    "\n",
    "**Question 1.11:** Use the corresponding function to extract a list of synsets that are a type of the `first_car_synset`. Assign the list to the variable named `type_of_first_car_syns`.\n",
    "\n",
    "*Hint:* The name of the function should map the name of the relationship you answered in the last question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_of_first_car_syns = ...\n",
    "type_of_first_car_syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_12\n",
    "points: \n",
    "    - 0.1\n",
    "    - 0.9\n",
    "    - 1\n",
    "-->\n",
    "\n",
    "**Question 1.12:** Loop through the lemmas of the synsets in `type_of_first_car_syns` and determine which lemma appears the most in WordNet. Assign the name of the lemma to the variable `most_common_car_lemma`.\n",
    "\n",
    "*(There are two that are tied, you can choose either of those)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "most_common_car_lemma = ...\n",
    "\n",
    "f\"The most common car lemma is {most_common_car_lemma}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Similarity\n",
    "\n",
    "We can use the paths in WordNet to find similarities between different synsets.\n",
    "The next line shows sysnets that we think should be similar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synsets(\"college\")[1].definition(), wn.synsets(\"high_school\")[0].definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute how similar two synsets are using the function `path_similarity()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synsets(\"college\")[1].path_similarity(wn.synsets(\"high_school\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another synset of \"college\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synsets(\"college\")[0].definition(), wn.synsets(\"high_school\")[0].definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next line will determine the similarity between this new synset of college and the synset of highschool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.synsets(\"college\")[0].path_similarity(wn.synsets(\"high_school\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_13\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 1.13:** Looking at the different similarity scores computed, what does this mean and do you agree with this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_14\n",
    "points: \n",
    "    - 0.1\n",
    "    - 0.4\n",
    "    - 0.5\n",
    "    - 0.5\n",
    "    - 2\n",
    "-->\n",
    "\n",
    "**Question  1.14:** Complete the next cell to sort the pair of words in `word_pairs` based on the similarity of the pair, in decreasing order. Store the sorted pairs as a list in the variable named `sorted_pairs`. Each item in the list should be a tuple where the first item is a word pair represented as a tuple (like in the code below) and the second item is the similarity score.\n",
    "\n",
    "*Note*: the similarity of\n",
    "a pair should be represented by the similarity of the most similar pair of synsets\n",
    "they have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs = [('car', 'automobile'), ('gem', 'jewel'), ('journey', 'voyage'), ('boy', 'lad'), ('coast', 'shore'), \n",
    "              ('asylum', 'madhouse',), ('magician', 'wizard'), ('midday', 'noon'), ('furnace', ' stove'), \n",
    "              ('food', 'fruit'), ('bird', 'cock'), ('bird', 'crane'),('tool', 'implement'), ('brother', 'monk'),\n",
    "              ('lad', 'brother'), ('crane', 'implement'), ('journey', 'car'), ('monk', 'oracle'),\n",
    "              ('cemetery', 'woodland'), ('food', 'rooster'), ('coast', 'hill'), ('forest', 'graveyard'), \n",
    "              ('shore', 'woodland'), ('monk', 'slave'), ('coast', 'forest'), ('lad', 'wizard'), ('chord', 'smile'),\n",
    "              ('glass', 'magician'), ('rooster', 'voyage'), ('noon', 'string')]\n",
    "\n",
    "sorted_pairs = ...\n",
    "...\n",
    "sorted_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_15\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 1.15:** How could we use WordNet to reduce variation when building a Document-Term matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## 2. VADER (for Valence Aware Dictionary forsEntiment Reasoning)\n",
    "\n",
    "Now we will look at how to use a dictionary-based method to categorize text and convert word counts into a quantifiable attribute that we want to measure.\n",
    "\n",
    "VADER is a *a simple rule-based model for general sentiment analysis* introduced in this [paper](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf) from the 2014 International Conference on Web and Social Media (ICWSM).\n",
    "VADER is a popular method and is included in many python packages, like nltk and spacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's download the VADER lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Exploring VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vader lexicon can be found online on GitHub: https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt.\n",
    "\n",
    "If we look at the [4140-th line in the file](https://github.com/cjhutto/vaderSentiment/blob/d8da3e21374a57201b557a4c91ac4dc411a08fed/vaderSentiment/vader_lexicon.txt#L4140), we see the following:\n",
    "\n",
    "> irate\t-2.9\t0.53852\t[-3, -3, -3, -2, -3, -4, -3, -3, -2, -3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1\n",
    "points: 2\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.1:** Based on the documentation found [here](https://github.com/cjhutto/vaderSentiment/#resources-and-dataset-descriptions), what does this line mean? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "Now, in the next line let's import the `vader` module from NLTK and create a new SentimentIntensityAnalyzer object and assign it to the variable named `sentiment_analyzer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import vader  \n",
    "\n",
    "sentiment_analyzer = vader.SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lexicon (or a similar lexicon) we just looked is stored in the `sentiment_analyzer` variable.\n",
    "We can access the sentiment intensity for each via a dictionary lookup, as shown in the next line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyzer.lexicon['irate'], sentiment_analyzer.lexicon['ecstatic'], sentiment_analyzer.lexicon['mad']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_2\n",
    "points: 2\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.2:** Compare the values just printed above with the values in the [lexicon on GitHub](https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt). Do the values match up, and if not why do you think that is the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "The lexicon in VADER contains scores for individual words. However, the sentiment of some phrases might be very different\n",
    "than the sentiment of each of the words. The next line prints out sentiment intensity scores for special idioms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader.VaderConstants.SPECIAL_CASE_IDIOMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_3\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.3:** In the next cell, choose one of the idioms and print out the score in the lexicon for the individual words to see how the scores for the individual words differ from the idiom.\n",
    "\n",
    "*Note:* If there is a word in the idiom that is not in the lexicon, choose a different idioms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "In this tutorial we won't go into the details of how exactly VADER works, we encourage you to read the paper and have included it in one of the options for Week 2's Readings. \n",
    "<br>\n",
    "As a high level overview, to determine the sentiment of a text, VADER uses a bunch of rules to combine the polarity of words in a given sentence. \n",
    "\n",
    "\n",
    "The function `polarity_score` will leverage the rules to compute a score for how *negative*, *neutral*, and *positive* a text is. The next line demonstrate how to use this function and the scores that it returns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyzer.polarity_scores(\"As a high level overview, to determine the sentiment of a text, VADER uses a bunch of rules to combine the polarity of words in a given sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`polarity_score` also computes a compund score. According to the documentation on GitHub:\n",
    "    \n",
    "> the compound score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This is the most useful metric if you want a single unidimensional measure of sentiment for a given sentence. Calling it a 'normalized, weighted composite score' is accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_4\n",
    "points: 2\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.4:** Based on the documentation, what are typical threshold values useds to determine if a text is positive, neutral, or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "#### 2.1.1 VADER Rules\n",
    "\n",
    "The rules in VADER were developed to work well on text from social media, like Twitter and Reddit. Here will look look at aspects of two rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the rules are based on if a sentence has any of these *booster* words, the polarity will be boosted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader.VaderConstants.BOOSTER_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_5\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.5:** In the next cell, add one of these booster terms to a sentence and see how the `polarity_score` results change when the booster word is included or not-included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_6\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.6:** Another rule in VADER is based on captialization. In the next cell, demonstrate how the values computed by the `polarity_score` function change when some words in a text are capitalized or are all lower cased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### 2.2 Analyzing Trump's 100 days of office via Sentiment\n",
    "\n",
    "We are now going to leverage VADER to explore the sentiment of Trump's Tweets during his first 100 days of office. This is based on an [NPR Story](https://www.npr.org/2017/04/30/526106612/what-we-learned-about-the-mood-of-trumps-tweets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_7\n",
    "points: 2\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.7:** Summarize and describe the findings from the NPR story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "#### 2.2.1 - Collecting Data and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later in the course we will learn how to extract Tweets directly from Twitter but for now we will use a collection already collected for us.\n",
    "\n",
    "Melanie Walsh has collected and cleaned Donald Trump's Tweets from the [Trump Twitter Archive](http://www.trumptwitterarchive.com/). We can download the Tweets from https://melaniewalsh.github.io/Intro-Cultural-Analytics/_downloads/c3e837cce30a959abc84cbc8914dc7a2/Trump-Tweets.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_8\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.8:** In the next line, use one bash command to download the `csv` file of tweets. Then use another bash command to move the file to the `data/` directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "Run the next cell to read in the csv file of Trump's Tweets. You can use the next cell to test whether the data was downloaded and renamed correctly. There should be about 29K rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweet_df = pd.read_csv(\"data/Trump-Tweets.csv\")\n",
    "trump_tweet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_9\n",
    "points: \n",
    "    - 0.2\n",
    "    - 0.8\n",
    "-->\n",
    "\n",
    "**Question 2.9:** Extract the names of the columns and store them in the variable called `column_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ...\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_10\n",
    "points: 2\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.10:** Briefly explain what each column is and the type of variable that is stored in the column?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "During Week 4 when we focus on Data Collection, we will go over different properties of Tweets that we can get when we collect Tweets from Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Data Filtering\n",
    "\n",
    "Whenever we have a dataset, it is important to filter out data that is not relevant for our study the research question we are interested in exploring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.2.1 Retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see the senitment of Trump's Tweets, not those that he has re-tweeted. The `is_retweet` column indicates if the Tweet is a retweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_11\n",
    "points: \n",
    "    - 0.5\n",
    "    - 0.5\n",
    "-->\n",
    "\n",
    "**Question 2.11:** In the next cell, remove all Tweets that are retweets. You can override the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweet_df = ...\n",
    "trump_tweet_df['is_retweet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_12\n",
    "points: \n",
    "    - 1\n",
    "-->\n",
    "\n",
    "**Question 2.12:** Since we now know that all of these tweets are Trump's tweets and not retweets, go ahead and remove the column `is_retweet` from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweet_df = ...\n",
    "trump_tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.2.2 Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will tell us the type that is stored in the `created_at` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweet_df['created_at'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the next line shows that `created_at` in fact represents date. `created_at` tells us the time when the Tweet was posted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweet_df['created_at']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[datetime](https://www.w3schools.com/python/python_datetime.asp) is a python module that allows us to easily work with dates. The next line will import the datetime module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Pandas has a nifty function [`to_datetime()` function](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html) that will convert the argument to a TimeStamp object. \n",
    "\n",
    "The next line shows how to create a datetime object from a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = pd.to_datetime(\"2020-05-11 01:01:23\")\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_13\n",
    "points: \n",
    "    - 1\n",
    "-->\n",
    "\n",
    "**Question 2.13:** Apply the `.to_datetime()` function to replace the values in `created_at` to timestamp objects. \n",
    "\n",
    "*You should notice the dtype of the column will change*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweet_df['created_at'] = trump_tweet_df['created_at'].apply(pd.to_datetime)\n",
    "trump_tweet_df['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract time related information easily from a TimeStamp object as shown in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp.day_name(), timestamp.day_of_week, timestamp.week, timestamp.month_name(), timestamp.month, timestamp.quarter, timestamp.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare times, as seen in the next line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp.now() > timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_14\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.14:** Briefly explain what the previous python cell is checking and what the resulting value indicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "We can use the `.timedelta()` function to add time a timestamp object. The next cell adds one day to the value stored in `timestamp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp, datetime.timedelta(days=1) + timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Trump's first day in office was January 20th 2017. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_15\n",
    "points: \n",
    "    - 0.1\n",
    "    - 0.1\n",
    "    - 0.1\n",
    "    - 0.7\n",
    "-->\n",
    "\n",
    "**Question 2.15:** In the next cell, use the `pd.to_datetime()` function to create a timestamp of Trump's first day in office. Even though the President is sworn in at noon, lets ignore time for now and just focus on the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_first_day = ...\n",
    "trump_first_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_16\n",
    "points: \n",
    "    - 0.3\n",
    "    - 0.7\n",
    "-->\n",
    "\n",
    "**Question:** Use a Timestamp object function to determine what day of the week was Trump's Inaugaration? Assign the answer to the variable named `trump_first_day_of_the_week`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_first_day_of_the_week = ...\n",
    "trump_first_day_of_the_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_17\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "**Question 2.17:** We want to measure the sentiment of Trump's Tweets during his first 100 days of office. Create a new datetime object that is 101 days after `trump_first_day` and assign the value to the variable named `trump_100_day`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_101_day = ...\n",
    "trump_101_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_17\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_18\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.18:** Why are we adding 101 days rather than 100 days?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Since we only want to look at the Tweets from Trump's first 100 days in office, lets filter out all tweets that are not within the first one-hundrad_days.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_19\n",
    "points: \n",
    "    - 0.1\n",
    "    - 0.2\n",
    "    - 0.6\n",
    "    - 0.5\n",
    "    - 0.5\n",
    "-->\n",
    "\n",
    "**Question 2.19:**  In the next cell, create a new dataframe called `trump_100_days_tweet_df` that contains the Tweets between `trump_101_day` and `trump_first_day. \n",
    "\n",
    "*Hint:* Make sure to reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "trump_100_days_tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_19\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Applying VADER to Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now we are ready to apply VADER to Trump's tweets. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_20\n",
    "points: \n",
    "    - 0.5\n",
    "    - 0.5\n",
    "    - 0.5\n",
    "    - 0.5\n",
    "-->\n",
    "\n",
    "**Question 2.20:** In the next cells, apply the the `sentiment_analyzer.polarity_scores` function to the tweets. Store the resulting dictionaries in a column called `polarity_scores` and the compound polarity in a new column called `compound_polarity`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_100_days_tweet_df['polarity_scores'] = trump_100_days_tweet_df['text'].apply(sentiment_analyzer.polarity_scores)\n",
    "trump_100_days_tweet_df['compound_polarity'] = trump_100_days_tweet_df['polarity_scores'].map(lambda x: x['compound'])\n",
    "trump_100_days_tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.3.1 Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "It is always important to sample some example after applying a method to classify text or add attributes to text.\n",
    "*(In my work I'll often sample about 50 random examples but here we will just look at two specific examples.)*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_21\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.21:** The next line uses `argmax` to find the index of the Tweet with the highest compound polarity score.\n",
    "Use the index to determine the highest `compound_polarity` value, the corresponding `text`, and when that tweet was written. Assign the values to the variables respectively named `max_compound_polarity`, `max_compound_polarity_tweet`, and `max_compound_polarity_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_compound_polarity_index = np.argmax(trump_100_days_tweet_df['compound_polarity'])\n",
    "max_compound_polarity = ...\n",
    "max_compound_polarity_tweet = ...\n",
    "max_compound_polarity_time = ...\n",
    "\n",
    "f\"The Tweet from {max_compound_polarity_time}: \\\"{max_compound_polarity_tweet}\\\" had the highest compound polarity of {max_compound_polarity}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_22\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.22:** Find the index of the Tweet with the lowest highest `compound_polarity` value, the corresponding `text`, and when that tweet was written. Assign the values to the variables respectively named `min_compound_index`, `min_compound_polarity`, `min_compound_polarity_tweet`, and `min_compound_polarity_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_compound_polarity_index = ...\n",
    "min_compound_polarity = ...\n",
    "min_compound_polarity_tweet = ...\n",
    "min_compound_polarity_time = ...\n",
    "\n",
    "f\"The Tweet from {min_compound_polarity_time}: \\\"{min_compound_polarity_tweet}\\\" had the highest compound polarity of {min_compound_polarity}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_23\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.23:** Looking at those two examples, do agree that these could be the Tweets with the highest and lowest sentiment scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "The next cell will compute the correlation between different columns in our dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_100_days_tweet_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_24\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.24:** Which two columns are the most correlated with each other and is this suprising?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_25\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.25:** Is the correlation between how many days Trump was in office and people's engagement with his tweets negative, positive, or neutral? Briefly, describe what this means.\n",
    "\n",
    "\n",
    "*Note:* We can measure engagement by retweets and favorting tweets. Replies is another way to measure engagement but this dataset does not include replies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "#### 2.2.2.4 - Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we will generate a line plot to show the compound polarity of a tweet ('y-axis') across each time stamp ('x-axis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_100_days_tweet_df.plot(kind='line', y='compound_polarity', x='created_at')\n",
    "plt.axhline(y=0, color='black', linestyle='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot you just generated is likely hard to understand. Trump tweeted a lot each day and his mood can change through out the day. Here we plot the score of each tweet since each tweet has it's own timestamp (that includes hours, minutes, and seconds).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Let's look at a large unit of analysis - average sentiment per day. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_26\n",
    "points:\n",
    "    - 0.5\n",
    "    - 0.5\n",
    "-->\n",
    "\n",
    "**Question 2.26:** In the next cell, add a column named `days_in_office` that represents how many days in office Trump had been in so far for each Tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "trump_100_days_tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_26\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_27\n",
    "points:\n",
    "    - 1\n",
    "    - 1\n",
    "-->\n",
    "\n",
    "**Question 2.27:** Now that each row has a corresponding value indicating how many days Trump has been in office, group the sentiment of Trumps tweets on a daily level and determine the average polarity of the tweet that day. Assign the resulting dataframe to the variable named `trump_daily_avg_sentiment`. Make sure to reset the index of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_daily_avg_sentiment = ...\n",
    "trump_daily_avg_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_27\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_28\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.28:** In the next cell, use a line plot to plot the average compound polarity of each tweet ('y-axis') across each day ('x-axis'). We provided a line that will show the y-axis as a black line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "plt.axhline(y=0, color='black', linestyle='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "We can begin to see some trends of how the sentiment of Trump's tweets changed over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Let's look at a large unit of analysis - average sentiment per week.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_29\n",
    "points:\n",
    "    - 1\n",
    "    - 1\n",
    "-->\n",
    "\n",
    "**Question 2.29:** In the next cell, add a column named `weeks_in_office` that represents how many weeks Trump has been in office based on the timestamp in a given Tweet.\n",
    "\n",
    "*Hint* We can use `.week` to find which week a date was in and we can then subtract two weeks from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "trump_100_days_tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_29\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_30\n",
    "points:\n",
    "    - 1\n",
    "    - 1\n",
    "-->\n",
    "\n",
    "**Question 2.30:** Now that each row has a corresponding value indicating how many weeks Trump has been in office, group the sentiment of Trumps tweets on a weekly level and determine the average polarity of the tweet that week. Assign the resulting dataframe to the variable named `trump_weekly_avg_sentiment`. Make sure to reset the index of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_weekly_avg_sentiment = ...\n",
    "trump_weekly_avg_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_31\n",
    "points: 2\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "**Question 2.31:** In the next cell, use a line plot to plot the average compound polarity of each tweet ('y-axis') across each week ('x-axis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "plt.axhline(y=0, color='black', linestyle='-')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_32\n",
    "points: 2\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.32:** How similar are your results with the findings and figure in the NPR story? If there are differences, do you think these differences are substantial?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_33\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.33:** At the minimum it is likely that your figure does not *exactly* match the one from the NPR story, which is ok. However, why do you think this might be the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_34\n",
    "points: 1\n",
    "manual: true\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.34:** Looking towards your final project, how could you use Vader in your final project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
