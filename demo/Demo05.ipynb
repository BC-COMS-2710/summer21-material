{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5249cdc4",
   "metadata": {},
   "source": [
    "# Demo 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b7dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87a4c23",
   "metadata": {},
   "source": [
    "## Types vs Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = \"We refuse to believe that there are insufficient funds in the great vaults \\\n",
    "of opportunity of this nation. And so we've come to cash this check, a check that \\\n",
    "will give us upon demand the riches of freedom and the security of justice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ddb87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b4b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.tokenize.word_tokenize(speech)\n",
    "\" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0515741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"Number of tokens is {len(tokens)}, number of types is {len(set(tokens))}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2611e87",
   "metadata": {},
   "source": [
    "### Duplicate types?\n",
    "\n",
    "**Question:** Can you find any duplicate types in our vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c14cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(tokens)\n",
    "\" \".join(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b733bb7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Answer</summary>\n",
    "    <b>\"We\"</b> and <b>\"we\"</b>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f38d1",
   "metadata": {},
   "source": [
    "Do we want to treat these as different types?\n",
    "\n",
    "**Question:** What solution would you suggest? \n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<b>Lowercase</b>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba76799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution is below in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c197c60f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e588e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e546bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18758188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7376219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_tokens = nltk.tokenize.word_tokenize(speech.lower())\n",
    "f\"Number of lowered tokens is {len(lower_tokens)}, number of types is {len(set(lower_tokens))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7cd82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a7b42c1",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "\n",
    "## Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31babf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cfeacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"transformed\", \"v\") # The NLTK WordNet Lemmatizer needs to know the part of speech tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c27e7a",
   "metadata": {},
   "source": [
    "#### Go, Goes, Went, Gone, Going\n",
    "\n",
    "**Question:** What do you think the lemma for these terms should be? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbff947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize(\"go\"), lemmatizer.lemmatize(\"goes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1352dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize(\"went\", \"v\"), lemmatizer.lemmatize(\"gone\", \"v\"), lemmatizer.lemmatize(\"going\", \"v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecaf6a7",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7342b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball_stemmer = nltk.stem.SnowballStemmer(\"english\") # Same of PorterStemmer\n",
    "snowball_stemmer.stem(\"babies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf67336",
   "metadata": {},
   "source": [
    "### constituional, constitutionality, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd21af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball_stemmer.stem(\"constitution\"), snowball_stemmer.stem(\"constitutions\"), snowball_stemmer.stem(\"constitutional\"), snowball_stemmer.stem(\"constitutionality\"), snowball_stemmer.stem(\"constitutionalism\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468f289",
   "metadata": {},
   "source": [
    "### Relat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b62124",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball_stemmer.stem(\"relativity\"), snowball_stemmer.stem(\"relative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc19594",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf04f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e71f50b",
   "metadata": {},
   "source": [
    "**Question:** What do we notice about these words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d0de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6ae8556",
   "metadata": {},
   "source": [
    "(back to demo)\n",
    "## Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71653fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450b9849",
   "metadata": {},
   "source": [
    "**Question:** What does this error mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b8c49e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11719f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d17f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484a2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(speech))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4cc1f",
   "metadata": {},
   "source": [
    "Let's look at another tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a7fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(speech), tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6141a88e",
   "metadata": {},
   "source": [
    "Tutorial 2.1 will further explore differences between these sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b88185f",
   "metadata": {},
   "source": [
    "### Tricky examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b542515",
   "metadata": {},
   "source": [
    "***time flies like an arrow***\n",
    "\n",
    "**Question:** What should the POS tags here be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b490a",
   "metadata": {},
   "source": [
    "- time: \n",
    "- flies:\n",
    "- like: \n",
    "- an:\n",
    "- arrow:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9992e4d8",
   "metadata": {},
   "source": [
    "Let's see what nltk tells us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(\"time flies like an arrow\"), tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9464b432",
   "metadata": {},
   "source": [
    "**Question:** Do we agree?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d58d2",
   "metadata": {},
   "source": [
    "Tutorial 2.1 will focus on the difference between these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80d2184",
   "metadata": {},
   "source": [
    "(back to slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba935d4c",
   "metadata": {},
   "source": [
    "## Dependency Parsing\n",
    "\n",
    "### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48190c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89f7b2c",
   "metadata": {},
   "source": [
    "You might need to run \n",
    "\n",
    "> !python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e88a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(speech)\n",
    "doc, type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e915ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18106a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(doc.sents)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc70d21d",
   "metadata": {},
   "source": [
    "Tutorial 2.1 will go into details about the spacy `Doc` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214ca154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(list(doc.sents)[0], style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4451167",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in list(doc.sents)[0]:\n",
    "    print(tok.text, tok.dep_.upper(), tok.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f74239",
   "metadata": {},
   "source": [
    "Spacy dependency parse labels are explained [here](https://github.com/clir/clearnlp-guidelines/blob/master/md/specifications/dependency_labels.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b760bb2f",
   "metadata": {},
   "source": [
    "(back to slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6452fcd5",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_doc = nlp(\"Monday, October 30, Hillary Clinton will present her book in Chicago at the University of Chicago.\")\n",
    "example_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23406da7",
   "metadata": {},
   "source": [
    "**Question:** How do we get the entities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_ents = ...\n",
    "example_ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72567a0",
   "metadata": {},
   "source": [
    "**Question:** Let's get the text of the entities and the label of the entity\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<b>[(ent.text, ent.label_) for ent in example_doc.ents]</b>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0199b984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c486621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3fbdff7",
   "metadata": {},
   "source": [
    "### Entities in Dracula\n",
    "\n",
    "I downloaded Dracula from Project Gutenberg: https://www.gutenberg.org/ebooks/345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123cf2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/Dracula.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1c6ce9",
   "metadata": {},
   "source": [
    "The next line will take about 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a1912",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "doc = nlp(open(\"data/Dracula.txt\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a10a9b0",
   "metadata": {},
   "source": [
    "I ran a [tool](https://github.com/JonathanReeve/chapterize) developed by Jonathan Reeve that splits novels from Project Gutenberg into files for each chapter.\n",
    "\n",
    "[Jonathan](https://jonreeve.com/) is a Computational literary analyst here at Columbia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d21c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/Dracula-chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5936043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "DRACULA_PATH = \"data/Dracula-chapters/\"\n",
    "\n",
    "chapter2doc = {}\n",
    "for file in tqdm(os.listdir(DRACULA_PATH)):\n",
    "    chapter_id = file.split(\".\")[0]\n",
    "    chapter2doc[chapter_id] = nlp(open(DRACULA_PATH + file).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45000cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter2doc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e56c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(chapter2doc['01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4396620",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = [], []\n",
    "for ent in chapter2doc['01'].ents:\n",
    "    texts.append(ent.text)\n",
    "    labels.append(ent.label_)\n",
    "    \n",
    "ents_df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "ents_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5560672d",
   "metadata": {},
   "source": [
    "**Question:** What labels do we see the most in the first Chapter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774408b6",
   "metadata": {},
   "source": [
    "**Question:** What person is mentioned the most in the first chapter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db0a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_df[ents_df['label'] == 'PERSON'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb5a41d",
   "metadata": {},
   "source": [
    "**Question:** Who is mentioned the most throughout the entire book?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters, texts, labels = [], [], []\n",
    "\n",
    "for chapter, doc in chapter2doc.items():\n",
    "    for ent in doc.ents:\n",
    "        texts.append(ent.text)\n",
    "        labels.append(ent.label_)\n",
    "        chapters.append(chapter)\n",
    "    \n",
    "ents_df = pd.DataFrame({'text': texts, 'label': labels, 'chapter': chapters})\n",
    "ents_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_df.sort_values(by='chapter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be2314",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucy_mentions_df = ents_df[ents_df['text'] == 'Lucy']\n",
    "lucy_mentions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988198d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucy_mentions_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucy_mentions_df = lucy_mentions_df.drop(columns=['label']) \n",
    "lucy_mentions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34550113",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucy_mentions_df['chapter'].value_counts().plot(kind='line')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f9a180",
   "metadata": {},
   "source": [
    "**Question:** What don't we like about this graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa2d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lucy_mentions_df['chapter'].value_counts().sort_index().plot(kind='line')\n",
    "ax.set_title(\"Number of times Lucy is mentioned per chapter\")\n",
    "ax.set_xlabel(\"Chapter Number\")\n",
    "ax.set_xlabel(\"Number of Lucy mentions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1700ac7",
   "metadata": {},
   "source": [
    "**Question:** Does this figure make sense based on the novel?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e174ab",
   "metadata": {},
   "source": [
    "\n",
    "#### Plotting most common characters in Dracula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944981c0",
   "metadata": {},
   "source": [
    "**Question:** Who are the 50 most commonly mentioned characters in Dracula?\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<b>ents_df[ents_df['label'] == 'PERSON']['text'].value_counts().head(50)</b>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13351b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here to determine that based on entities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edf4594",
   "metadata": {},
   "source": [
    "Let's query the dataframe to find all rows that have been tagged as a PERSON and \n",
    "save the result from the query in `person_df`\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<b>ents_df[ents_df['label'] == 'PERSON']</b>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffad707",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df = ...\n",
    "person_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658201a2",
   "metadata": {},
   "source": [
    "Now lets determine how many times each person was mentioned in each chapter.\n",
    "\n",
    "We want to make a new dataframe where the indices are the chapters and the columns represent the counts of how many times a specific character was mentioned in the chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dd908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_table = pd.pivot_table(person_df, index=['chapter'],\n",
    "                    columns=['text'], aggfunc=len, fill_value=0)\n",
    "pv_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1587eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_table.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96c743c",
   "metadata": {},
   "source": [
    "Let's plot just the 10 most frequently mentioned characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b3aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df['text'].value_counts().head(10) # first find the 10 most frequently mentioned characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d42b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_freq_people = person_df['text'].value_counts().index[:10] # Lets get their names\n",
    "ten_freq_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_table['label'][ten_freq_people].plot(kind='line') # Query the pivot table and then plot the result "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec119c21",
   "metadata": {},
   "source": [
    "let's make subplots as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad942c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
