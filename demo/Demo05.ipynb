{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5407597c",
   "metadata": {},
   "source": [
    "# Demo 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a397e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e3987b",
   "metadata": {},
   "source": [
    "## Types vs Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b239405",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = \"We refuse to believe that there are insufficient funds in the great vaults \\\n",
    "of opportunity of this nation. And so we've come to cash this check, a check that \\\n",
    "will give us upon demand the riches of freedom and the security of justice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9363cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd1572",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.tokenize.word_tokenize(speech)\n",
    "\" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc7387",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"Number of tokens is {len(tokens)}, number of types is {len(set(tokens))}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f81e2f1",
   "metadata": {},
   "source": [
    "### Duplicate types?\n",
    "\n",
    "**Question:** Can you find any duplicate types in our vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffb1fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(tokens)\n",
    "\" \".join(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04972a7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Answer</summary>\n",
    "    <b>\"We\"</b> and <b>\"we\"</b>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3806f7ed",
   "metadata": {},
   "source": [
    "Do we want to treat these as different types?\n",
    "\n",
    "**Question:** What solution would you suggest? \n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<b>Lowercase</b>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e17011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution is below in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e519a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bbf690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e6abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307f66e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a4cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_tokens = nltk.tokenize.word_tokenize(speech.lower())\n",
    "f\"Number of lowered tokens is {len(lower_tokens)}, number of types is {len(set(lower_tokens))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0837b4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11d6d0ac",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "\n",
    "## Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79672a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"transformed\", \"v\") # The NLTK WordNet Lemmatizer needs to know the part of speech tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad46d3eb",
   "metadata": {},
   "source": [
    "#### Go, Goes, Went, Gone, Going\n",
    "\n",
    "**Question:** What do you think the lemma for these terms should be? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a91ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize(\"go\"), lemmatizer.lemmatize(\"goes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e225c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize(\"went\", \"v\"), lemmatizer.lemmatize(\"gone\", \"v\"), lemmatizer.lemmatize(\"going\", \"v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d5ef6f",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546dc934",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball_stemmer = nltk.stem.SnowballStemmer(\"english\") # Same of PorterStemmer\n",
    "snowball_stemmer.stem(\"babies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9e9a33",
   "metadata": {},
   "source": [
    "### constituional, constitutionality, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ee6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball_stemmer.stem(\"constitution\"), snowball_stemmer.stem(\"constitutions\"), snowball_stemmer.stem(\"constitutional\"), snowball_stemmer.stem(\"constitutionality\"), snowball_stemmer.stem(\"constitutionalism\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a514487",
   "metadata": {},
   "source": [
    "### Relat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball_stemmer.stem(\"relativity\"), snowball_stemmer.stem(\"relative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0bed64",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd929e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c062bb20",
   "metadata": {},
   "source": [
    "**Question:** What do we notice about these words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11506c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5aa993ba",
   "metadata": {},
   "source": [
    "(back to demo)\n",
    "## Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141e9abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e362fc0d",
   "metadata": {},
   "source": [
    "**Question:** What does this error mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30beaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a70af58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a3325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c964bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(speech))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf3f42",
   "metadata": {},
   "source": [
    "Let's look at another tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac672103",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(speech), tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a23124a",
   "metadata": {},
   "source": [
    "Tutorial 2.1 will further explore differences between these sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f1c717",
   "metadata": {},
   "source": [
    "### Tricky examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3985444",
   "metadata": {},
   "source": [
    "***time flies like an arrow***\n",
    "\n",
    "**Question:** What should the POS tags here be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f9f97c",
   "metadata": {},
   "source": [
    "- time: \n",
    "- flies:\n",
    "- like: \n",
    "- an:\n",
    "- arrow:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64053a15",
   "metadata": {},
   "source": [
    "Let's see what nltk tells us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac5121",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(\"time flies like an arrow\"), tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ed55e2",
   "metadata": {},
   "source": [
    "**Question:** Do we agree?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee0dc1",
   "metadata": {},
   "source": [
    "Tutorial 2.1 will focus on the difference between these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5514453e",
   "metadata": {},
   "source": [
    "(back to slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea03a17",
   "metadata": {},
   "source": [
    "## Dependency Parsing\n",
    "\n",
    "### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa5917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee144ca",
   "metadata": {},
   "source": [
    "You might need to run \n",
    "\n",
    "> !python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55513671",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(speech)\n",
    "doc, type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511de6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbab579",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(doc.sents)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e152c3c3",
   "metadata": {},
   "source": [
    "Tutorial 2.1 will go into details about the spacy `Doc` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0eb432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(list(doc.sents)[0], style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef0ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in list(doc.sents)[0]:\n",
    "    print(tok.text, tok.dep_.upper(), tok.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b56c18f",
   "metadata": {},
   "source": [
    "Spacy dependency parse labels are explained [here](https://github.com/clir/clearnlp-guidelines/blob/master/md/specifications/dependency_labels.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068b1c38",
   "metadata": {},
   "source": [
    "(back to slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca3d967",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e987762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_doc = nlp(\"Monday, October 30, Hillary Clinton will present her book in Chicago at the University of Chicago.\")\n",
    "example_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ab19d",
   "metadata": {},
   "source": [
    "**Question:** How do we get the entities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f409f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_ents = ...\n",
    "example_ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a4e06",
   "metadata": {},
   "source": [
    "**Question:** Let's get the text of the entities and the label of the entity\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<b>[(ent.text, ent.label_) for ent in example_doc.ents]</b>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4675cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620016ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4030eaa",
   "metadata": {},
   "source": [
    "### Entities in Dracula\n",
    "\n",
    "I downloaded Dracula from Project Gutenberg: https://www.gutenberg.org/ebooks/345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9452faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/Dracula.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ecadf0",
   "metadata": {},
   "source": [
    "The next line will take about 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0395863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "doc = nlp(open(\"data/Dracula.txt\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17dc170",
   "metadata": {},
   "source": [
    "I ran a [tool](https://github.com/JonathanReeve/chapterize) developed by Jonathan Reeve that splits novels from Project Gutenberg into files for each chapter.\n",
    "\n",
    "[Jonathan](https://jonreeve.com/) is a Computational literary analyst here at Columbia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564ada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/Dracula-chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ff447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "DRACULA_PATH = \"data/Dracula-chapters/\"\n",
    "\n",
    "chapter2doc = {}\n",
    "for file in tqdm(os.listdir(DRACULA_PATH)):\n",
    "    chapter_id = file.split(\".\")[0]\n",
    "    chapter2doc[chapter_id] = nlp(open(DRACULA_PATH + file).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter2doc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd7c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(chapter2doc['01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd8a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = [], []\n",
    "for ent in chapter2doc['01'].ents:\n",
    "    texts.append(ent.text)\n",
    "    labels.append(ent.label_)\n",
    "    \n",
    "ents_df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "ents_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6af0dfa",
   "metadata": {},
   "source": [
    "**Question:** What labels do we see the most in the first Chapter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0788b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc76dc",
   "metadata": {},
   "source": [
    "**Question:** What person is mentioned the most in the first chapter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e347f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_df[ents_df['label'] == 'PERSON'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f582c4d7",
   "metadata": {},
   "source": [
    "**Question:** Who is mentioned the most throughout the entire book?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea8e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters, texts, labels = [], [], []\n",
    "\n",
    "for chapter, doc in chapter2doc.items():\n",
    "    for ent in doc.ents:\n",
    "        texts.append(ent.text)\n",
    "        labels.append(ent.label_)\n",
    "        chapters.append(chapter)\n",
    "    \n",
    "ents_df = pd.DataFrame({'text': texts, 'label': labels, 'chapter': chapters})\n",
    "ents_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c242680",
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_df.sort_values(by='chapter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d6a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucy_mentions_df = ents_df[ents_df['text'] == 'Lucy']\n",
    "lucy_mentions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e5b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucy_mentions_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b03a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucy_mentions_df = lucy_mentions_df.drop(columns=['label']) \n",
    "lucy_mentions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e87b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucy_mentions_df['chapter'].value_counts().plot(kind='line')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b9e1a1",
   "metadata": {},
   "source": [
    "**Question:** What don't we like about this graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dc0998",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lucy_mentions_df['chapter'].value_counts().sort_index().plot(kind='line')\n",
    "ax.set_title(\"Number of times Lucy is mentioned per chapter\")\n",
    "ax.set_xlabel(\"Chapter Number\")\n",
    "ax.set_xlabel(\"Number of Lucy mentions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba48cdb",
   "metadata": {},
   "source": [
    "**Question:** Does this figure make sense based on the novel?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2679f1b4",
   "metadata": {},
   "source": [
    "\n",
    "#### Plotting most common characters in Dracula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f672367",
   "metadata": {},
   "source": [
    "**Question:** Who are the 50 most commonly mentioned characters in Dracula?\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<b>ents_df[ents_df['label'] == 'PERSON']['text'].value_counts().head(50)</b>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here to determine that based on entities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d46db89",
   "metadata": {},
   "source": [
    "Let's query the dataframe to find all rows that have been tagged as a PERSON and \n",
    "save the result from the query in `person_df`\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<b>ents_df[ents_df['label'] == 'PERSON']</b>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df = ...\n",
    "person_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0124d01d",
   "metadata": {},
   "source": [
    "Now lets determine how many times each person was mentioned in each chapter.\n",
    "\n",
    "We want to make a new dataframe where the indices are the chapters and the columns represent the counts of how many times a specific character was mentioned in the chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25975c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_table = pd.pivot_table(person_df, index=['chapter'],\n",
    "                    columns=['text'], aggfunc=len, fill_value=0)\n",
    "pv_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260395b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_table.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9e83c8",
   "metadata": {},
   "source": [
    "Let's plot just the 10 most frequently mentioned characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02fcc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df['text'].value_counts().head(10) # first find the 10 most frequently mentioned characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9064e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_freq_people = person_df['text'].value_counts().index[:10] # Lets get their names\n",
    "ten_freq_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da51ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_table['label'][ten_freq_people].plot(kind='line') # Query the pivot table and then plot the result "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10a92ae",
   "metadata": {},
   "source": [
    "let's make subplots as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf90df9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
