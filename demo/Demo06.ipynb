{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab51fdb1",
   "metadata": {},
   "source": [
    "# Demo 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e2ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5f0a47",
   "metadata": {},
   "source": [
    "## Word Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08db390b",
   "metadata": {},
   "source": [
    "### Words in the wild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfece040",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_df = pd.read_csv(\"data/norvig_count1w.txt\", sep=\"\\t\", header=None)\n",
    "word_counts_df = word_counts_df.rename(columns={0: \"type\", 1: \"count\"})\n",
    "word_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a9a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = word_counts_df.head(100).plot(kind=\"bar\", x='type', rot=45)\n",
    "ax.set_title(\"Zipf’s law from Google Web Trillion Word Corpus\")\n",
    "\n",
    "plt.xticks(np.arange(0, 100, step=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334b8a2",
   "metadata": {},
   "source": [
    "**Question:** What do we notice about these words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3870cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = word_counts_df.head(500).plot(kind=\"bar\", x='type', rot=45)\n",
    "ax.set_title(\"Zipf’s law from Google Web Trillion Word Corpus\")\n",
    "\n",
    "plt.xticks(np.arange(0, 500, step=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6eaf4b",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "\n",
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7fe460",
   "metadata": {},
   "source": [
    "Let's get the BoW for this sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.FreqDist(nltk.word_tokenize(\"Penny bought bright blue fishes on a bright blue sunny day\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965d758c",
   "metadata": {},
   "source": [
    "Let's now get BoWs for each of these sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94845a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Penny bought bright blue fishes.\",\n",
    "    \"Penny bought bright blue and orange fish.\",\n",
    "    \"The cat ate a fish at the store.\",\n",
    "    \"Penny went to the store. Penny ate a bug. Penny saw a fish.\",\n",
    "    \"It meowed once at the bug, it is still meowing at the bug and the fish\",\n",
    "    \"The cat is at the fish store. The cat is orange. The cat is meowing at the fish.\",\n",
    "    \"Penny is a fish\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864aa3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "[nltk.FreqDist(nltk.word_tokenize(sent)) for sent in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e6d777",
   "metadata": {},
   "source": [
    "What if we want to compare them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75354b00",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "\n",
    "## Document Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a627ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vector = pd.Series(nltk.word_tokenize(\"Penny bought bright blue fishes on a bright blue sunny day.\"))\n",
    "doc_vector.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c1681f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[pd.Series(nltk.word_tokenize(sent)).value_counts() for sent in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9cd968",
   "metadata": {},
   "source": [
    "## Document-Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([pd.Series(nltk.word_tokenize(sent)).value_counts() for sent in texts]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([pd.Series(nltk.word_tokenize(sent)).value_counts() for sent in texts]).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a132e78",
   "metadata": {},
   "source": [
    "(back to slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c613320",
   "metadata": {},
   "source": [
    "Sometimes we will transpose this matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f76ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([pd.Series(nltk.word_tokenize(sent)).value_counts() for sent in texts]).fillna(0).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be39acd4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17861f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d83be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = count_vectorizer.fit_transform(texts)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a578930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe29684",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c6c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc2e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(matrix.toarray(), columns= count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440c0123",
   "metadata": {},
   "source": [
    "I sometimes like to transpose this matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c273c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(matrix.toarray().T, index= count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc3517f",
   "metadata": {},
   "source": [
    "Let's put this into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631f63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_matrix(corpus):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    matrix = count_vectorizer.fit_transform(corpus)\n",
    "    return pd.DataFrame(matrix.toarray().T, index= count_vectorizer.get_feature_names())\n",
    "\n",
    "make_matrix(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54ee855",
   "metadata": {},
   "source": [
    "### Product Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79da72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import product_reviews_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340e69ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_reviews_1.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c151cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "canon_g3_reviews = [review.sents() for review in product_reviews_1.reviews('Canon_G3.txt')]\n",
    "canon_g3_reviews[0][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a81c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix(canon_g3_reviews).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddba987a",
   "metadata": {},
   "source": [
    "So we need to extract the text from the list of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb0dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_corpus = [\" \".join([\" \".join(sent) for sent in review]) for review in canon_g3_reviews]\n",
    "f\"There are {len(review_corpus)} amount of reviews.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150aa920",
   "metadata": {},
   "source": [
    "#### Exploring corpus\n",
    "\n",
    "Let's get a sense of these reviews. It is usually a good idea to get a sense of the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4e8422",
   "metadata": {},
   "source": [
    "**Question:** How big is the vocabulary of these reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094e449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.FreqDist(\" \".join(review_corpus).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5d37a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nltk.FreqDist(\" \".join(review_corpus).split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de306999",
   "metadata": {},
   "source": [
    "**Question:** How many tokens are in the corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15470fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(nltk.FreqDist(\" \".join(review_corpus).split()).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaee5e4",
   "metadata": {},
   "source": [
    "**Question:** What is the distribution of word types in the reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acb29e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.FreqDist(\" \".join(review_corpus).split()).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb2dc2a",
   "metadata": {},
   "source": [
    "**Question:** How long are these reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d30cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(review_corpus).rename(columns={0:\"text\"})['text'].map(lambda x: len(x.split())).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e10d6",
   "metadata": {},
   "source": [
    "#### Document Matrix of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_matrix(review_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bf222b",
   "metadata": {},
   "source": [
    "**Question:** What does each row represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0501c11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11b9817b",
   "metadata": {},
   "source": [
    "**Question:** What do we notice about these rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c925a07",
   "metadata": {},
   "source": [
    "**Question:** What do we think about the last few rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5338a5",
   "metadata": {},
   "source": [
    "#### Pre-processing document matrix\n",
    "\n",
    "##### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ab13e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_corpus = []\n",
    "for review in review_corpus:\n",
    "    clean_review = []\n",
    "    review_tokens = nltk.word_tokenize(review)\n",
    "    for word in review_tokens:\n",
    "        if word not in nltk.corpus.stopwords.words('english'):\n",
    "            clean_review.append(word)\n",
    "    cleaned_corpus.append(\" \".join(clean_review))\n",
    "make_matrix(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c970838",
   "metadata": {},
   "source": [
    "##### Stem tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c720a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.SnowballStemmer(language='english')\n",
    "stemmer.stem('zooming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_corpus = []\n",
    "for review in review_corpus:\n",
    "    clean_review = []\n",
    "    review_tokens = nltk.word_tokenize(review)\n",
    "    for word in review_tokens:\n",
    "        if word not in nltk.corpus.stopwords.words('english'):\n",
    "            clean_review.append(stemmer.stem(word))\n",
    "    cleaned_corpus.append(\" \".join(clean_review))\n",
    "make_matrix(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736b8dfd",
   "metadata": {},
   "source": [
    "##### Remove punctuation and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a137933a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "cleaned_corpus = []\n",
    "for review in review_corpus:\n",
    "    clean_review = []\n",
    "    review_tokens = nltk.word_tokenize(review)\n",
    "    for word in review_tokens:\n",
    "        if word not in nltk.corpus.stopwords.words('english') and word.isalpha():\n",
    "            clean_review.append(stemmer.stem(word))\n",
    "    cleaned_corpus.append(\" \".join(clean_review))\n",
    "    \n",
    "curr_matrix_df = make_matrix(cleaned_corpus)\n",
    "curr_matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75b1f19",
   "metadata": {},
   "source": [
    "**Question:** What do we think the most common value is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41843ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12500bca",
   "metadata": {},
   "source": [
    "Consequently, these vectors can be called **sparse vectors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965e8c10",
   "metadata": {},
   "source": [
    "Let's look at the first document\n",
    "\n",
    "**Question:** How can we get the first document from the matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d85b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_doc = curr_matrix_df[0]\n",
    "first_doc[first_doc != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c47ed8",
   "metadata": {},
   "source": [
    "It looks like a lot of words appear just once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc8e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = first_doc[first_doc != 0].value_counts().plot(kind='bar', rot=0)\n",
    "ax.set_title(\"Number of times each word appears in first Review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134300c",
   "metadata": {},
   "source": [
    "So let's look at just words that appear more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31648e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_doc[first_doc > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e056a7",
   "metadata": {},
   "source": [
    "**VALIDATE VALIDATE VALIDATE**\n",
    "\n",
    "**Question:** How well does this vector capture the review?\n",
    "\n",
    "(Run the next cell to see the original review and them compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02ddc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718f591f",
   "metadata": {},
   "source": [
    "#### Most common word in each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c08a33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_matrix_df.apply(lambda x: (x.idxmax(), x.max()), axis=0).rename({0:\"word\", 1:\"count\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10801db",
   "metadata": {},
   "source": [
    "We might think that document 0 focuses more on \"pictures\" than document 6\n",
    "\n",
    "**Question:** Is `pictur` actually much more prominent in review 0 than review 6? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44181e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_length_df = pd.DataFrame([(idx, len(review.split())) for idx, review in enumerate(cleaned_corpus)])\n",
    "review_length_df = review_length_df.rename(columns={0: 'review_id', 1: 'review_length'})\n",
    "review_length_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c103acc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_length_df[(review_length_df['review_id'] == 0)\n",
    "                |\n",
    "                (review_length_df['review_id'] == 6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bed0be1",
   "metadata": {},
   "source": [
    "### Convert counts to frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992114be",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_matrix_df[0] / sum(curr_matrix_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6624414",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df = curr_matrix_df.apply(lambda x: x/x.sum(), axis=0)\n",
    "freq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb7d15",
   "metadata": {},
   "source": [
    "The sum of each column should be one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f95507",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df.apply(lambda x: sum(x), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006a13d9",
   "metadata": {},
   "source": [
    "**Question:** What is the most frequent word in each review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87331ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df.apply(lambda x: (x.idxmax(), x.max()), axis=0).rename({0:\"word\", 1:\"freq\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f9692d",
   "metadata": {},
   "source": [
    "**Question:** Do we now think document 0 and document 6 equally discuss \"pictures\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b114e87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79b863b1",
   "metadata": {},
   "source": [
    "**Question:** Are these words actually interesting or unique to specific documents?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2af48b6",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "\n",
    "## Inverse Document Frequency\n",
    "\n",
    "Let's compute it manually\n",
    "\n",
    "idf of word w in Document D is log(Number of documents divided by number of documents that contain w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c21f462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dc7fdf7",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb8e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "matrix = count_vectorizer.fit_transform(cleaned_corpus)\n",
    "pd.DataFrame(matrix.toarray().T, index= count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b60de",
   "metadata": {},
   "source": [
    "### Let's apply this to all the product reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ebbed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_reviews_1.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce25cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_reviews_1.reviews('Nokia_6610.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d359588e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
