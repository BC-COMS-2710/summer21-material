{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b99923",
   "metadata": {},
   "source": [
    "# Demo 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89157ca",
   "metadata": {},
   "source": [
    "## Gensim\n",
    "\n",
    "[Gensim](https://radimrehurek.com/gensim/#) is a popular NLP library. We wil use it for word embeddings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df2c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d88e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90546147",
   "metadata": {},
   "source": [
    "Gensim has many trained models that we can use. The next cell will print out a list of models we can download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7173ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "list(gensim.downloader.info()['models'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d1c4ab",
   "metadata": {},
   "source": [
    "**Question:** What do the numbers at the end of the `word2vec` and `glove` models mean?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "    The dimension of the vectors. This is <i>k</i> from our slides\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f89b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b001eb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9783b421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71138f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56342dc3",
   "metadata": {},
   "source": [
    "We will look at glove vectors that were trained on Gigaword.\n",
    "\n",
    "*(First run the next cell then discuss this)*<br>\n",
    "In class we discussed Word2Vec but for this demo we will use Glove embeddings. Glove is a similar method that learns word embeddings based on a co-occurence matrix.\n",
    "\n",
    "See https://nlp.stanford.edu/projects/glove/ for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cce0928",
   "metadata": {},
   "source": [
    "### Download Glove model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6d5c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import gensim.downloader as api\n",
    "model = api.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d094e7",
   "metadata": {},
   "source": [
    "The line above created a new directory called `gensim-data` in your home directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e492925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ~/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03577e96",
   "metadata": {},
   "source": [
    "It also created a new directory called glove-wiki-gigaword-50 where it stored the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d08a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ~/gensim-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d146fd70",
   "metadata": {},
   "source": [
    "The next line prints out the size of the folder and its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d08479",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -h ~/gensim-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a352c66",
   "metadata": {},
   "source": [
    "We can see the model is 67MB. The other embeddings will be much larger because they have more dimensions and a larger vocabulary.\n",
    "\n",
    "Feel free to download the larger vectors on your own. They take longer to download so we are only using the small vectors during the class demo.\n",
    "\n",
    "*Note:* CUIT provision 5GB for each jupyterhub server so be careful when you download many embedding files. Some of the largest ones are about 2.5GB. If you run into an issue where you are out of memory, open up a terminal and use the `rm` command to delete some large files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b8e22",
   "metadata": {},
   "source": [
    "### Saved model as gensim KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9caeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501aad0",
   "metadata": {},
   "source": [
    "The WordVectors are stored as a gensim KeyVectors object.\n",
    "Here is the [documentation for KeyVectors in gensim](https://radimrehurek.com/gensim/models/keyedvectors.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2238079",
   "metadata": {},
   "source": [
    "We can see all vectors by running the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb43b91",
   "metadata": {},
   "source": [
    "**Question:** How do you think we can find the number of words in our vocabulary and the size of the vectors?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "    model.vectors.shape\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a21668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the code to see the size of the vocab and the vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3f86d5",
   "metadata": {},
   "source": [
    "### Access Embeddings for a word\n",
    "\n",
    "We can find the word embedding for a specific word type by running the next line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc89d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_vector('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c66f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model['queen']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b6afa",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "## Exploring word relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76e34de",
   "metadata": {},
   "source": [
    "### Most similar terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03689ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar('queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1cc97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['king', 'male'], negative=['queen'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b18587b",
   "metadata": {},
   "source": [
    "### Which word doesnt match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.doesnt_match([\"breakfast\", \"cereal\", \"dinner\", \"lunch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee756038",
   "metadata": {},
   "source": [
    "### Compute word similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0055a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyemd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8220bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_obama = 'Obama speaks to the media in Illinois'.lower().split()\n",
    "sentence_president = 'The president greets the press in Chicago'.lower().split()\n",
    "\n",
    "model.wmdistance(sentence_obama, sentence_president)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e89b9",
   "metadata": {},
   "source": [
    "### Even more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676e00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_word_analogies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5423823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.closer_than(\"queen\", \"king\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c694f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.closer_than(\"king\", \"queen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f5b07",
   "metadata": {},
   "source": [
    "### Visualization with dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4381eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7401a478",
   "metadata": {},
   "source": [
    "## Word Embeddings as Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243fc87f",
   "metadata": {},
   "source": [
    "We'll pick up on Thursday showing how we can train a classifier with word embeddings as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df27ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "moview_reviews = nltk.corpus.movie_reviews\n",
    "review_files = [(file_id, file_id.startswith(\"pos\")) for file_id in moview_reviews.fileids()]\n",
    "df = pd.DataFrame(review_files)\n",
    "df = df.rename(columns={0: \"file_name\", 1: \"gold-label\"})\n",
    "\n",
    "\n",
    "def read_mov_review(f_name):\n",
    "    return moview_reviews.open(f_name).read()\n",
    "\n",
    "df['review_text'] = df['file_name'].apply(read_mov_review)\n",
    "\n",
    "df = df.sample(df.shape[0])\n",
    "df.head(5)\n",
    "\n",
    "train_max_idx = int(df.shape[0] * .8)\n",
    "dev_max_idx = int((df.shape[0] * .1) + train_max_idx)\n",
    "\n",
    "\n",
    "train_max_idx, dev_max_idx\n",
    "\n",
    "train_df = df.iloc[:train_max_idx]\n",
    "dev_df = df.iloc[train_max_idx:dev_max_idx]\n",
    "test_df = df.iloc[dev_max_idx:]\n",
    "\n",
    "train_df.shape, dev_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4acea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(review):\n",
    "    return \" \".join([\" \".join(nltk.tokenize.word_tokenize(sent)) for sent in nltk.tokenize.sent_tokenize(train_df['review_text'].iloc[0])])\n",
    "\n",
    "train_df['clean_text'] = train_df['review_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b6dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
