{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43e192d2",
   "metadata": {},
   "source": [
    "# Demo 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e377ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca59c9e",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "### Dataset\n",
    "\n",
    "We will use data from [Victorian Era Authorship Attribution Data Set](https://archive.ics.uci.edu/ml/datasets/Victorian+Era+Authorship+Attribution#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439cea20",
   "metadata": {},
   "source": [
    "**Instructions:**\n",
    "\n",
    "- Open up a terminal\n",
    "- `cd` into `data/`\n",
    "- make a new directory for victorian author id\n",
    "- wget https://archive.ics.uci.edu/ml/machine-learning-databases/00454/dataset.zip\n",
    "- unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0316713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53678, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/victorian_author_id/dataset/Gungor_2018_VictorianAuthorAttribution_data-train.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797557cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'author'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f28d232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['author'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e473822",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     6914\n",
       "26    4441\n",
       "14    2696\n",
       "37    2387\n",
       "45    2312\n",
       "21    2307\n",
       "39    2266\n",
       "48    1825\n",
       "33    1742\n",
       "19    1543\n",
       "4     1483\n",
       "15    1460\n",
       "43    1266\n",
       "38    1163\n",
       "25    1159\n",
       "9     1108\n",
       "18    1078\n",
       "42    1022\n",
       "30     972\n",
       "50     914\n",
       "1      912\n",
       "41     911\n",
       "28     823\n",
       "10     755\n",
       "32     703\n",
       "36     693\n",
       "17     660\n",
       "35     659\n",
       "29     645\n",
       "12     627\n",
       "46     605\n",
       "20     587\n",
       "22     495\n",
       "13     485\n",
       "44     468\n",
       "23     455\n",
       "34     453\n",
       "40     430\n",
       "6      407\n",
       "11     383\n",
       "2      382\n",
       "24     380\n",
       "27     306\n",
       "3      213\n",
       "16     183\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6c5945",
   "metadata": {
    "tags": []
   },
   "source": [
    "Its a good idea to check if there are duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c8fd402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53678,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4155d1f8",
   "metadata": {},
   "source": [
    "Let's just look at the 5 most frequent authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c2b8e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([8, 26, 14, 37, 45], dtype='int64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top4_authors = df['author'].value_counts()[:5].index\n",
    "top4_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d60d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>t is only the railroad the arches of the railr...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>partially enveloped the seed ned the same kind...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>king s sake how gladly we repeat it sailing on...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>why is this we shall soon see we push through ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>bear don t cry so loud bony is not here she to...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50329</th>\n",
       "      <td>had touched the heart of the victim who lay on...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50330</th>\n",
       "      <td>to do these things as well as his confused and...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50331</th>\n",
       "      <td>he said let us go back towards it again they t...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50332</th>\n",
       "      <td>had rendered her progress a noiseless one so f...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50333</th>\n",
       "      <td>day e stone was warm and dry in contrast to th...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "3397   t is only the railroad the arches of the railr...       8\n",
       "3398   partially enveloped the seed ned the same kind...       8\n",
       "3399   king s sake how gladly we repeat it sailing on...       8\n",
       "3400   why is this we shall soon see we push through ...       8\n",
       "3401   bear don t cry so loud bony is not here she to...       8\n",
       "...                                                  ...     ...\n",
       "50329  had touched the heart of the victim who lay on...      45\n",
       "50330  to do these things as well as his confused and...      45\n",
       "50331  he said let us go back towards it again they t...      45\n",
       "50332  had rendered her progress a noiseless one so f...      45\n",
       "50333  day e stone was warm and dry in contrast to th...      45\n",
       "\n",
       "[18750 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['author'].map(lambda x: x in top4_authors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3818b4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18750, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['author'].map(lambda x: x in top4_authors)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "992a0bb0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t is only the railroad the arches of the railroad span the house the wires of the electric stretch over the confined scene of his daily life the engines fly past him on their errands and the birds and what can the man of prejudice and usage hope for but to be and flung into oblivion look to it gentlemen of precedent and custom household words during a fresh war the supposed prize was upon by england with another expedition four thousand men under sir david landed in s bay a little to the north of cape town presently fought a battle with the dutch defeated them and took the cape town by two days afterwards the whole colony was soon ab to the british and being confirmed t england by the peace of we have since had undisturbed possession the internal t of the cape colony after its first establishment was for a long time very simple the dutch increased and multiplied together with their flocks and herds a pasture farm requiring elbow room there were always many who preferred passing the bounds to live in country by their companions as the men and women multiplied outside they were included of course in the body of the colony and new were established in the succeeding generation the or were a soft material and suffered the to penetrate until they arrived eastward at the sunday l where they met with a hard in a fence of men most in their disposition these were the the had come from the to settle as far south as the great river nearly at the same time that the dutch came across the sea to plant their colony in table bay the whole country before time as far north as the and in some directions farther had been most probably by the whom the dutch led the area is a to the name of the tribe d by a chief named purchased of the natives their new ground l ow as the spread and multiplied the also spread passed the great fish river md reached sunday river where after many years of separate prosperity the and s came in contact with each other the are so called by who adopt an word meaning borrowed from of the z coast it is no native name and is applied by us to a l ce of the perhaps mixed of southern africa distinctly marked and separated from the the and the and races which with the of are all that are to southern africa these races differ from the other of africa by being lighter in complexion m d less decidedly negro in feature it is supposed that they have been altered by with an race a is a tall well and man the lower part of his face scarcely his eyes are keen and his features are not without intelligence he has not yet learned to from his hair thoroughly with red in a skin cloak which the his fine dark limbs show to and with a spear in his hand e by the an or resting on a club he would no bad model for the the are divided into independent each under its own chief the chiefs being all descendants of they are cattle feeding upon meat and milk like our old and like them they enjoy a and glory in the sport of cattle stealing awkward neighbours these for the fat herds of the dutch farmers or the s tranquillity was soon disturbed and his imagination similar to that of senior would be very slow in the peculiar race with which he had to deal then the and neighbours at the sandy river where the s occupied a tract of ground which they had bought of the o doubt the mouths of the when they saw the of the cattle which come and fetch us from adjacent fields but it appears that for some time they remained good and quiet the continued as they had hitherto done to extend their common boundary by supplying men who established themselves in farms beyond the limits s from a great bed were sent out which took root in a portion of the country these having grown sufficiently the i y was extended by the government and some of the who had not stirred from their own soil found themselves in the position of within the colony so at least the considered them o doubt the thought that good people who appropriated their land so were e and ought not to complain if in their turn they lost oxen perhaps it was want of imagination in the farmers but they did complain nay they became very much exasperated and it was here that the long series of mistakes began which have been since adding upon until we are at length presented in our own day with a formidable there is in the no inherent inability to assent to whatever is true and just but seeds of war were diligently sown we may sow peace now in the harvest time it is too late war must be the became exasperated and took to get the from their neighbourhood it is said that the people of one tribe the which they hated most were to a friendly conference and shot by while they were collecting beads and toys thrown down before them this s is told by le m d also by the rev l ir it is at least tain tha the words s with the black crown on the of the a ridge that seemed composed of many ribs and folds extended from tl is to the margin of the protecting cover ow the spider formed by nature for the ex purpose this peculiar of the seed by up its small black head and body on its p large red and laying its stout black limbs close together to form the ridge the umbrella like which '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['author'] == 8].iloc[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96555ae9",
   "metadata": {},
   "source": [
    "#### Partitioning dataset\n",
    "\n",
    "Let's make train, dev, and test splits that are 80:10:10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c2a822",
   "metadata": {},
   "source": [
    "First shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba6c23cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14250</th>\n",
       "      <td>of the disease but solely on its external if t...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48563</th>\n",
       "      <td>do not plain iy if she suits for ihe chosen to...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15743</th>\n",
       "      <td>up over our door since afore the heads went ou...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14403</th>\n",
       "      <td>might securely be drawn from the flowing of bl...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16329</th>\n",
       "      <td>no dear knowledge concerning the mother s brea...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49398</th>\n",
       "      <td>and example but though was the of that literat...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29730</th>\n",
       "      <td>nothing to me it would seem only a commercial ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16082</th>\n",
       "      <td>she has been under a disadvantage with such a ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40417</th>\n",
       "      <td>so many well meaning creatures must we not sup...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8014</th>\n",
       "      <td>for an answer to that question i venture to ta...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "14250  of the disease but solely on its external if t...      14\n",
       "48563  do not plain iy if she suits for ihe chosen to...      45\n",
       "15743  up over our door since afore the heads went ou...      14\n",
       "14403  might securely be drawn from the flowing of bl...      14\n",
       "16329  no dear knowledge concerning the mother s brea...      14\n",
       "...                                                  ...     ...\n",
       "49398  and example but though was the of that literat...      45\n",
       "29730  nothing to me it would seem only a commercial ...      26\n",
       "16082  she has been under a disadvantage with such a ...      14\n",
       "40417  so many well meaning creatures must we not sup...      37\n",
       "8014   for an answer to that question i venture to ta...       8\n",
       "\n",
       "[18750 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da7a44a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28303</th>\n",
       "      <td>an end to which both of them submitted without...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38722</th>\n",
       "      <td>out to join them before them roll the mists of...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3887</th>\n",
       "      <td>extent a man especially a man brought down as ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8395</th>\n",
       "      <td>the christmas at which communication and both ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3911</th>\n",
       "      <td>mysteries by making himself acquainted with ti...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "28303  an end to which both of them submitted without...      26\n",
       "38722  out to join them before them roll the mists of...      37\n",
       "3887   extent a man especially a man brought down as ...       8\n",
       "8395   the christmas at which communication and both ...       8\n",
       "3911   mysteries by making himself acquainted with ti...       8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088c05e5",
   "metadata": {},
   "source": [
    "Now split our data into appropriate partitions for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a277b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 16875)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_max_idx = int(df.shape[0] * .8)\n",
    "dev_max_idx = int((df.shape[0] * .1) + train_max_idx)\n",
    "\n",
    "\n",
    "train_max_idx, dev_max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a897fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 2), (1875, 2), (1875, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df.iloc[:train_max_idx]\n",
    "dev_df = df.iloc[train_max_idx:dev_max_idx]\n",
    "test_df = df.iloc[dev_max_idx:]\n",
    "\n",
    "train_df.shape, dev_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0c36d9",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8014318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "733cff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d6c755d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.81 s, sys: 107 ms, total: 8.92 s\n",
      "Wall time: 8.92 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer.fit(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac1b9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(train_df['text'])\n",
    "X_dev = vectorizer.transform(dev_df['text'])\n",
    "# X_test = vectorizer.transform(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07bec881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.4 ms, sys: 1.15 ms, total: 45.5 ms\n",
      "Wall time: 44.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "nb_model.fit(X_train, train_df['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77f1ac1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9465333333333333"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.score(X_train, train_df['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b39c1895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9376"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.score(X_dev, dev_df['author'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c585a",
   "metadata": {},
   "source": [
    "#### Let's modify the value for smoothing\n",
    "\n",
    "By default, Laplacian smoothing (add-one) is used. But lets change the value and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2b2a592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = MultinomialNB(alpha=10)\n",
    "nb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85ff14ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.4 ms, sys: 1.04 ms, total: 46.5 ms\n",
      "Wall time: 45.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "nb_model.fit(X_train, train_df['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cec75aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9424"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.score(X_train, train_df['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "378ee4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9349333333333333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.score(X_dev, dev_df['author'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf04844",
   "metadata": {},
   "source": [
    "**Question:** Was add-10 smoothing better than add-one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cfe126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88f319b3",
   "metadata": {},
   "source": [
    "Let's look at add-two smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd06bdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9456, 0.9376)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = MultinomialNB(alpha=2)\n",
    "nb_model.fit(X_train, train_df['author'])\n",
    "nb_model.score(X_train, train_df['author']), nb_model.score(X_dev, dev_df['author'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cb3775",
   "metadata": {},
   "source": [
    "Let's look at no smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "727bcf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9506666666666667, 0.9386666666666666)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = MultinomialNB(alpha=0)\n",
    "nb_model.fit(X_train, train_df['author'])\n",
    "nb_model.score(X_train, train_df['author']), nb_model.score(X_dev, dev_df['author'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc5a536",
   "metadata": {},
   "source": [
    "Let's loop through lots of values and see differences in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a576f5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/opt/conda/lib/python3.8/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "100%|██████████| 30/30 [00:02<00:00, 10.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "smoothing_values = np.arange(0,15, 0.5)\n",
    "train_accuracy, dev_accuracy = [], []\n",
    "\n",
    "for smoothing_value in tqdm(smoothing_values):\n",
    "    nb_model = MultinomialNB(alpha=smoothing_value)\n",
    "    nb_model.fit(X_train, train_df['author'])\n",
    "    train_accuracy.append(nb_model.score(X_train, train_df['author']))\n",
    "    dev_accuracy.append(nb_model.score(X_dev, dev_df['author']))\n",
    "    \n",
    "results_df = pd.DataFrame({'alpha': smoothing_values, \n",
    "              'train_accuracy': train_accuracy,\n",
    "             'dev_accuracy': dev_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb327124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,\n",
       "        5.5,  6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. , 10.5,\n",
       "       11. , 11.5, 12. , 12.5, 13. , 13.5, 14. , 14.5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a736197a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>dev_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.950667</td>\n",
       "      <td>0.938667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.947200</td>\n",
       "      <td>0.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.946533</td>\n",
       "      <td>0.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.946067</td>\n",
       "      <td>0.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.945600</td>\n",
       "      <td>0.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.5</td>\n",
       "      <td>0.945400</td>\n",
       "      <td>0.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.5</td>\n",
       "      <td>0.944867</td>\n",
       "      <td>0.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.944733</td>\n",
       "      <td>0.938133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.5</td>\n",
       "      <td>0.944200</td>\n",
       "      <td>0.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.944133</td>\n",
       "      <td>0.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.944133</td>\n",
       "      <td>0.936533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.944067</td>\n",
       "      <td>0.936533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.943733</td>\n",
       "      <td>0.936533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.943600</td>\n",
       "      <td>0.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.943600</td>\n",
       "      <td>0.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.943200</td>\n",
       "      <td>0.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.943133</td>\n",
       "      <td>0.935467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.942733</td>\n",
       "      <td>0.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.5</td>\n",
       "      <td>0.942667</td>\n",
       "      <td>0.935467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.942400</td>\n",
       "      <td>0.934933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.5</td>\n",
       "      <td>0.941867</td>\n",
       "      <td>0.934933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.941733</td>\n",
       "      <td>0.934933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11.5</td>\n",
       "      <td>0.941600</td>\n",
       "      <td>0.934933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.941000</td>\n",
       "      <td>0.934933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.5</td>\n",
       "      <td>0.940533</td>\n",
       "      <td>0.934933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.939933</td>\n",
       "      <td>0.934933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13.5</td>\n",
       "      <td>0.939600</td>\n",
       "      <td>0.933867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.939667</td>\n",
       "      <td>0.932267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14.5</td>\n",
       "      <td>0.939267</td>\n",
       "      <td>0.931733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha  train_accuracy  dev_accuracy\n",
       "0     0.0        0.950667      0.938667\n",
       "1     0.5        0.947200      0.937600\n",
       "2     1.0        0.946533      0.937600\n",
       "3     1.5        0.946067      0.937600\n",
       "4     2.0        0.945600      0.937600\n",
       "5     2.5        0.945400      0.937600\n",
       "6     3.0        0.945000      0.937600\n",
       "7     3.5        0.944867      0.937600\n",
       "8     4.0        0.944733      0.938133\n",
       "9     4.5        0.944200      0.937600\n",
       "10    5.0        0.944133      0.937600\n",
       "11    5.5        0.944133      0.936533\n",
       "12    6.0        0.944067      0.936533\n",
       "13    6.5        0.943733      0.936533\n",
       "14    7.0        0.943600      0.936000\n",
       "15    7.5        0.943600      0.936000\n",
       "16    8.0        0.943200      0.936000\n",
       "17    8.5        0.943133      0.935467\n",
       "18    9.0        0.942733      0.936000\n",
       "19    9.5        0.942667      0.935467\n",
       "20   10.0        0.942400      0.934933\n",
       "21   10.5        0.941867      0.934933\n",
       "22   11.0        0.941733      0.934933\n",
       "23   11.5        0.941600      0.934933\n",
       "24   12.0        0.941000      0.934933\n",
       "25   12.5        0.940533      0.934933\n",
       "26   13.0        0.939933      0.934933\n",
       "27   13.5        0.939600      0.933867\n",
       "28   14.0        0.939667      0.932267\n",
       "29   14.5        0.939267      0.931733"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f682dfad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='alpha'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df.plot(kind='line', x='alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5921a98",
   "metadata": {},
   "source": [
    "**Question:** From the above, which value of smoothing seemd to work the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "190851dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['dev_accuracy'].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ae710",
   "metadata": {},
   "source": [
    "So now we will use that value for the model we apply to our held-out test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9781d3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alpha = results_df.loc[results_df['dev_accuracy'].argmax()]['alpha']\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc00018f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9466666666666667"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = MultinomialNB(alpha=best_alpha)\n",
    "nb_model.fit(X_train, train_df['author'])\n",
    "\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "\n",
    "nb_model.score(X_test, test_df['author'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940641a3",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "\n",
    "## Metrics beyond accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51e2a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "moview_reviews = nltk.corpus.movie_reviews\n",
    "review_files = [(file_id, file_id.startswith(\"pos\")) for file_id in moview_reviews.fileids()]\n",
    "\n",
    "df = pd.DataFrame(review_files)\n",
    "df = df.rename(columns={0: \"file_name\", 1: \"gold-label\"})\n",
    "\n",
    "def read_mov_review(f_name):\n",
    "    return moview_reviews.open(f_name).read()\n",
    "\n",
    "df['review_text'] = df['file_name'].apply(read_mov_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27cb46ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2684f1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['gold-label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99b9b311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1000\n",
       "True     1000\n",
       "Name: gold-label, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gold-label'].map(lambda x: \"True\" if x else \"False\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fed3f797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([735, 670,  44, 559, 778, 693,  30, 431, 289, 779,\n",
       "            ...\n",
       "            848, 796, 703, 885, 950, 728, 966, 173, 294, 736],\n",
       "           dtype='int64', length=850)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['gold-label'] == False].sample(1000 - 150).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2bac933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>gold-label</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg/cv002_17424.txt</td>\n",
       "      <td>False</td>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>neg/cv012_29411.txt</td>\n",
       "      <td>False</td>\n",
       "      <td>and now the high-flying hong kong style of fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>neg/cv016_4348.txt</td>\n",
       "      <td>False</td>\n",
       "      <td>i'm really starting to wonder about alicia sil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>neg/cv017_23487.txt</td>\n",
       "      <td>False</td>\n",
       "      <td>so what do you get when you mix together plot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>neg/cv020_9234.txt</td>\n",
       "      <td>False</td>\n",
       "      <td>\" spawn \" features good guys , bad guys , lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>pos/cv995_21821.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>wow ! what a movie . \\nit's everything a movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>pos/cv996_11592.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>richard gere can be a commanding actor , but h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>pos/cv997_5046.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>glory--starring matthew broderick , denzel was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>pos/cv998_14111.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>steven spielberg's second epic film on world w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>pos/cv999_13106.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>truman ( \" true-man \" ) burbank is the perfect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                file_name  gold-label  \\\n",
       "2     neg/cv002_17424.txt       False   \n",
       "12    neg/cv012_29411.txt       False   \n",
       "16     neg/cv016_4348.txt       False   \n",
       "17    neg/cv017_23487.txt       False   \n",
       "20     neg/cv020_9234.txt       False   \n",
       "...                   ...         ...   \n",
       "1995  pos/cv995_21821.txt        True   \n",
       "1996  pos/cv996_11592.txt        True   \n",
       "1997   pos/cv997_5046.txt        True   \n",
       "1998  pos/cv998_14111.txt        True   \n",
       "1999  pos/cv999_13106.txt        True   \n",
       "\n",
       "                                            review_text  \n",
       "2     it is movies like these that make a jaded movi...  \n",
       "12    and now the high-flying hong kong style of fil...  \n",
       "16    i'm really starting to wonder about alicia sil...  \n",
       "17    so what do you get when you mix together plot ...  \n",
       "20     \" spawn \" features good guys , bad guys , lot...  \n",
       "...                                                 ...  \n",
       "1995  wow ! what a movie . \\nit's everything a movie...  \n",
       "1996  richard gere can be a commanding actor , but h...  \n",
       "1997  glory--starring matthew broderick , denzel was...  \n",
       "1998  steven spielberg's second epic film on world w...  \n",
       "1999  truman ( \" true-man \" ) burbank is the perfect...  \n",
       "\n",
       "[1150 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(index= df[df['gold-label'] == False].sample(1000 - 150).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5691ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df.drop(index= df[df['gold-label'] == False].sample(1000 - 150).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ce390c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = tmp_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab542e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1000\n",
       "False     150\n",
       "Name: gold-label, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df['gold-label'].value_counts()#normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c462d118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.869565\n",
       "False    0.130435\n",
       "Name: gold-label, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df['gold-label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ae589f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((920, 3), (115, 3), (115, 3))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_max_idx = int(tmp_df.shape[0] * .8)\n",
    "dev_max_idx = int((tmp_df.shape[0] * .1) + train_max_idx)\n",
    "\n",
    "\n",
    "train_max_idx, dev_max_idx\n",
    "\n",
    "train_df = tmp_df.iloc[:train_max_idx]\n",
    "dev_df = tmp_df.iloc[train_max_idx:dev_max_idx]\n",
    "test_df = tmp_df.iloc[dev_max_idx:]\n",
    "\n",
    "train_df.shape, dev_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99ed8baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=10)\n",
    "vectorizer.fit(train_df['review_text'])\n",
    "\n",
    "X_train = vectorizer.transform(train_df['review_text'])\n",
    "X_dev = vectorizer.transform(dev_df['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f8657ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8956521739130435)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = LogisticRegression(max_iter=1e3, C=100)\n",
    "#clf = MultinomialNB()\n",
    "#clf = MLPClassifier(hidden_layer_sizes=10)\n",
    "clf.fit(X_train, train_df['gold-label'])\n",
    "\n",
    "clf.score(X_train, train_df['gold-label']), clf.score(X_dev, dev_df['gold-label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd095d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.872826\n",
       "False    0.127174\n",
       "Name: gold-label, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['gold-label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd63ed04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.852174\n",
       "False    0.147826\n",
       "Name: gold-label, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df['gold-label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c3fab1",
   "metadata": {},
   "source": [
    "**Question:** What might be misleading about the dev accuracy?\n",
    "\n",
    "<details>\n",
    "<summary>Hint</summary>\n",
    "    Think about value_counts from above\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f18229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e7cd63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f16bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df['gold-label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b57482b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True, False, False,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True, False, False,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62660dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     102\n",
       "False     13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(clf.predict(X_dev)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d37ef6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = dev_df.assign(prediction = clf.predict(X_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "883bf240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>gold-label</th>\n",
       "      <th>review_text</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>pos/cv650_14340.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>james cmaeron's breakthrough feature was the f...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>pos/cv263_19259.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>american pie acknowledges a cold , hard fact t...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>pos/cv508_16006.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>maybe the most important thing about this movi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>pos/cv540_3421.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>i am starting to write this review before goin...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>pos/cv608_23231.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>magnolia left me relling from the theatre , st...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>pos/cv551_10565.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>after the simple looking little spacecraft lan...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>pos/cv938_10220.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>the idea at the center of the devil's advocate...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>pos/cv581_19381.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>eyes wide shut isn't the masterpiece many were...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>pos/cv378_20629.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>oliver stone's latest feature is the last one ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>pos/cv688_7368.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>time bandits , from director terry gilliam , i...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                file_name  gold-label  \\\n",
       "1650  pos/cv650_14340.txt        True   \n",
       "1263  pos/cv263_19259.txt        True   \n",
       "1508  pos/cv508_16006.txt        True   \n",
       "1540   pos/cv540_3421.txt        True   \n",
       "1608  pos/cv608_23231.txt        True   \n",
       "...                   ...         ...   \n",
       "1551  pos/cv551_10565.txt        True   \n",
       "1938  pos/cv938_10220.txt        True   \n",
       "1581  pos/cv581_19381.txt        True   \n",
       "1378  pos/cv378_20629.txt        True   \n",
       "1688   pos/cv688_7368.txt        True   \n",
       "\n",
       "                                            review_text  prediction  \n",
       "1650  james cmaeron's breakthrough feature was the f...        True  \n",
       "1263  american pie acknowledges a cold , hard fact t...        True  \n",
       "1508  maybe the most important thing about this movi...        True  \n",
       "1540  i am starting to write this review before goin...        True  \n",
       "1608  magnolia left me relling from the theatre , st...        True  \n",
       "...                                                 ...         ...  \n",
       "1551  after the simple looking little spacecraft lan...        True  \n",
       "1938  the idea at the center of the devil's advocate...        True  \n",
       "1581  eyes wide shut isn't the masterpiece many were...        True  \n",
       "1378  oliver stone's latest feature is the last one ...        True  \n",
       "1688  time bandits , from director terry gilliam , i...        True  \n",
       "\n",
       "[94 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df[(dev_df['prediction'] == True) & (dev_df['gold-label'] == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ab19c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>gold-label</th>\n",
       "      <th>review_text</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>pos/cv650_14340.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>james cmaeron's breakthrough feature was the f...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>pos/cv263_19259.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>american pie acknowledges a cold , hard fact t...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>pos/cv508_16006.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>maybe the most important thing about this movi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>pos/cv540_3421.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>i am starting to write this review before goin...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>neg/cv654_19345.txt</td>\n",
       "      <td>False</td>\n",
       "      <td>you think that these people only exist in the ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>pos/cv938_10220.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>the idea at the center of the devil's advocate...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>pos/cv581_19381.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>eyes wide shut isn't the masterpiece many were...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>neg/cv514_12173.txt</td>\n",
       "      <td>False</td>\n",
       "      <td>i didn't hate the big hit , even though it is ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>pos/cv378_20629.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>oliver stone's latest feature is the last one ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>pos/cv688_7368.txt</td>\n",
       "      <td>True</td>\n",
       "      <td>time bandits , from director terry gilliam , i...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                file_name  gold-label  \\\n",
       "1650  pos/cv650_14340.txt        True   \n",
       "1263  pos/cv263_19259.txt        True   \n",
       "1508  pos/cv508_16006.txt        True   \n",
       "1540   pos/cv540_3421.txt        True   \n",
       "654   neg/cv654_19345.txt       False   \n",
       "...                   ...         ...   \n",
       "1938  pos/cv938_10220.txt        True   \n",
       "1581  pos/cv581_19381.txt        True   \n",
       "514   neg/cv514_12173.txt       False   \n",
       "1378  pos/cv378_20629.txt        True   \n",
       "1688   pos/cv688_7368.txt        True   \n",
       "\n",
       "                                            review_text  prediction  \n",
       "1650  james cmaeron's breakthrough feature was the f...        True  \n",
       "1263  american pie acknowledges a cold , hard fact t...        True  \n",
       "1508  maybe the most important thing about this movi...        True  \n",
       "1540  i am starting to write this review before goin...        True  \n",
       "654   you think that these people only exist in the ...        True  \n",
       "...                                                 ...         ...  \n",
       "1938  the idea at the center of the devil's advocate...        True  \n",
       "1581  eyes wide shut isn't the masterpiece many were...        True  \n",
       "514   i didn't hate the big hit , even though it is ...        True  \n",
       "1378  oliver stone's latest feature is the last one ...        True  \n",
       "1688  time bandits , from director terry gilliam , i...        True  \n",
       "\n",
       "[115 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bf3b16cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  4],\n",
       "       [ 8, 94]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(dev_df['prediction'], dev_df['gold-label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b813628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69230769, 0.30769231],\n",
       "       [0.07843137, 0.92156863]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(dev_df['prediction'], dev_df['gold-label'], normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "16a7afc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591836734693877"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(dev_df['prediction'], dev_df['gold-label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0b805c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9215686274509803"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.recall_score(dev_df['prediction'], dev_df['gold-label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "345585ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9400000000000001"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.f1_score(dev_df['prediction'], dev_df['gold-label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce3d71f",
   "metadata": {},
   "source": [
    "(back to slides)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4616063d",
   "metadata": {},
   "source": [
    "## K-Means walkthrough\n",
    "\n",
    "Example comes from https://stackoverflow.com/questions/65449241/plotting-the-kmeans-cluster-centers-for-every-iteration-in-python.\n",
    "\n",
    "I'd recommend going through this [blog post](https://towardsdatascience.com/k-means-clustering-with-scikit-learn-6b47a369a83c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e88d70",
   "metadata": {},
   "source": [
    "## Dataset - Obits from HW02\n",
    "\n",
    "Now lets look at using kmeans to cluster documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fba041c",
   "metadata": {},
   "source": [
    "Load in data. This takes a little while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d93899bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364, 35049)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/tfidf_hw02.csv.gz\", compression=\"gzip\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "39c79dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=364, step=1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "afe3022f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>aachen</th>\n",
       "      <th>aahs</th>\n",
       "      <th>aarau</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaugh</th>\n",
       "      <th>ab</th>\n",
       "      <th>ababa</th>\n",
       "      <th>aback</th>\n",
       "      <th>abaco</th>\n",
       "      <th>...</th>\n",
       "      <th>zrathustra</th>\n",
       "      <th>zuber</th>\n",
       "      <th>zuker</th>\n",
       "      <th>zukor</th>\n",
       "      <th>zukors</th>\n",
       "      <th>zula</th>\n",
       "      <th>zululand</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zvai</th>\n",
       "      <th>zwilich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Randolph</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Swope</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ulanova</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sousa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject  aachen  aahs  aarau     aaron  aaugh   ab  ababa  aback  abaco  \\\n",
       "0  Randolph     0.0   0.0    0.0  0.000000    0.0  0.0    0.0    0.0    0.0   \n",
       "1     Basie     0.0   0.0    0.0  0.012317    0.0  0.0    0.0    0.0    0.0   \n",
       "2     Swope     0.0   0.0    0.0  0.000000    0.0  0.0    0.0    0.0    0.0   \n",
       "3   Ulanova     0.0   0.0    0.0  0.000000    0.0  0.0    0.0    0.0    0.0   \n",
       "4     Sousa     0.0   0.0    0.0  0.000000    0.0  0.0    0.0    0.0    0.0   \n",
       "\n",
       "   ...  zrathustra  zuber  zuker  zukor  zukors  zula  zululand  zurich  zvai  \\\n",
       "0  ...         0.0    0.0    0.0    0.0     0.0   0.0       0.0     0.0   0.0   \n",
       "1  ...         0.0    0.0    0.0    0.0     0.0   0.0       0.0     0.0   0.0   \n",
       "2  ...         0.0    0.0    0.0    0.0     0.0   0.0       0.0     0.0   0.0   \n",
       "3  ...         0.0    0.0    0.0    0.0     0.0   0.0       0.0     0.0   0.0   \n",
       "4  ...         0.0    0.0    0.0    0.0     0.0   0.0       0.0     0.0   0.0   \n",
       "\n",
       "   zwilich  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "\n",
       "[5 rows x 35049 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aee034d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>aachen</th>\n",
       "      <th>aahs</th>\n",
       "      <th>aarau</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaugh</th>\n",
       "      <th>ab</th>\n",
       "      <th>ababa</th>\n",
       "      <th>aback</th>\n",
       "      <th>abaco</th>\n",
       "      <th>...</th>\n",
       "      <th>zrathustra</th>\n",
       "      <th>zuber</th>\n",
       "      <th>zuker</th>\n",
       "      <th>zukor</th>\n",
       "      <th>zukors</th>\n",
       "      <th>zula</th>\n",
       "      <th>zululand</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zvai</th>\n",
       "      <th>zwilich</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Randolph</th>\n",
       "      <td>Randolph</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Basie</th>\n",
       "      <td>Basie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swope</th>\n",
       "      <td>Swope</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ulanova</th>\n",
       "      <td>Ulanova</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sousa</th>\n",
       "      <td>Sousa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss Balch</th>\n",
       "      <td>Miss Balch</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cage</th>\n",
       "      <td>Cage</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grant</th>\n",
       "      <td>Grant</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gorky</th>\n",
       "      <td>Gorky</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tandy</th>\n",
       "      <td>Tandy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 35049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               subject  aachen  aahs  aarau     aaron  aaugh   ab  ababa  \\\n",
       "subject                                                                    \n",
       "Randolph      Randolph     0.0   0.0    0.0  0.000000    0.0  0.0    0.0   \n",
       "Basie            Basie     0.0   0.0    0.0  0.012317    0.0  0.0    0.0   \n",
       "Swope            Swope     0.0   0.0    0.0  0.000000    0.0  0.0    0.0   \n",
       "Ulanova        Ulanova     0.0   0.0    0.0  0.000000    0.0  0.0    0.0   \n",
       "Sousa            Sousa     0.0   0.0    0.0  0.000000    0.0  0.0    0.0   \n",
       "...                ...     ...   ...    ...       ...    ...  ...    ...   \n",
       "Miss Balch  Miss Balch     0.0   0.0    0.0  0.000000    0.0  0.0    0.0   \n",
       "Cage              Cage     0.0   0.0    0.0  0.000000    0.0  0.0    0.0   \n",
       "Grant            Grant     0.0   0.0    0.0  0.000000    0.0  0.0    0.0   \n",
       "Gorky            Gorky     0.0   0.0    0.0  0.000000    0.0  0.0    0.0   \n",
       "Tandy            Tandy     0.0   0.0    0.0  0.000000    0.0  0.0    0.0   \n",
       "\n",
       "               aback  abaco  ...  zrathustra  zuber  zuker  zukor  zukors  \\\n",
       "subject                      ...                                            \n",
       "Randolph    0.000000    0.0  ...         0.0    0.0    0.0    0.0     0.0   \n",
       "Basie       0.000000    0.0  ...         0.0    0.0    0.0    0.0     0.0   \n",
       "Swope       0.000000    0.0  ...         0.0    0.0    0.0    0.0     0.0   \n",
       "Ulanova     0.000000    0.0  ...         0.0    0.0    0.0    0.0     0.0   \n",
       "Sousa       0.000000    0.0  ...         0.0    0.0    0.0    0.0     0.0   \n",
       "...              ...    ...  ...         ...    ...    ...    ...     ...   \n",
       "Miss Balch  0.000000    0.0  ...         0.0    0.0    0.0    0.0     0.0   \n",
       "Cage        0.000000    0.0  ...         0.0    0.0    0.0    0.0     0.0   \n",
       "Grant       0.003402    0.0  ...         0.0    0.0    0.0    0.0     0.0   \n",
       "Gorky       0.000000    0.0  ...         0.0    0.0    0.0    0.0     0.0   \n",
       "Tandy       0.000000    0.0  ...         0.0    0.0    0.0    0.0     0.0   \n",
       "\n",
       "            zula  zululand  zurich  zvai  zwilich  \n",
       "subject                                            \n",
       "Randolph     0.0       0.0     0.0   0.0      0.0  \n",
       "Basie        0.0       0.0     0.0   0.0      0.0  \n",
       "Swope        0.0       0.0     0.0   0.0      0.0  \n",
       "Ulanova      0.0       0.0     0.0   0.0      0.0  \n",
       "Sousa        0.0       0.0     0.0   0.0      0.0  \n",
       "...          ...       ...     ...   ...      ...  \n",
       "Miss Balch   0.0       0.0     0.0   0.0      0.0  \n",
       "Cage         0.0       0.0     0.0   0.0      0.0  \n",
       "Grant        0.0       0.0     0.0   0.0      0.0  \n",
       "Gorky        0.0       0.0     0.0   0.0      0.0  \n",
       "Tandy        0.0       0.0     0.0   0.0      0.0  \n",
       "\n",
       "[364 rows x 35049 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index = df['subject']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e45a57e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aachen</th>\n",
       "      <th>aahs</th>\n",
       "      <th>aarau</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaugh</th>\n",
       "      <th>ab</th>\n",
       "      <th>ababa</th>\n",
       "      <th>aback</th>\n",
       "      <th>abaco</th>\n",
       "      <th>abandon</th>\n",
       "      <th>...</th>\n",
       "      <th>zrathustra</th>\n",
       "      <th>zuber</th>\n",
       "      <th>zuker</th>\n",
       "      <th>zukor</th>\n",
       "      <th>zukors</th>\n",
       "      <th>zula</th>\n",
       "      <th>zululand</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zvai</th>\n",
       "      <th>zwilich</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Randolph</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Basie</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swope</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ulanova</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sousa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss Balch</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cage</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grant</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gorky</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tandy</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 35048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aachen  aahs  aarau     aaron  aaugh   ab  ababa     aback  abaco  \\\n",
       "subject                                                                         \n",
       "Randolph       0.0   0.0    0.0  0.000000    0.0  0.0    0.0  0.000000    0.0   \n",
       "Basie          0.0   0.0    0.0  0.012317    0.0  0.0    0.0  0.000000    0.0   \n",
       "Swope          0.0   0.0    0.0  0.000000    0.0  0.0    0.0  0.000000    0.0   \n",
       "Ulanova        0.0   0.0    0.0  0.000000    0.0  0.0    0.0  0.000000    0.0   \n",
       "Sousa          0.0   0.0    0.0  0.000000    0.0  0.0    0.0  0.000000    0.0   \n",
       "...            ...   ...    ...       ...    ...  ...    ...       ...    ...   \n",
       "Miss Balch     0.0   0.0    0.0  0.000000    0.0  0.0    0.0  0.000000    0.0   \n",
       "Cage           0.0   0.0    0.0  0.000000    0.0  0.0    0.0  0.000000    0.0   \n",
       "Grant          0.0   0.0    0.0  0.000000    0.0  0.0    0.0  0.003402    0.0   \n",
       "Gorky          0.0   0.0    0.0  0.000000    0.0  0.0    0.0  0.000000    0.0   \n",
       "Tandy          0.0   0.0    0.0  0.000000    0.0  0.0    0.0  0.000000    0.0   \n",
       "\n",
       "             abandon  ...  zrathustra  zuber  zuker  zukor  zukors  zula  \\\n",
       "subject               ...                                                  \n",
       "Randolph    0.000000  ...         0.0    0.0    0.0    0.0     0.0   0.0   \n",
       "Basie       0.010460  ...         0.0    0.0    0.0    0.0     0.0   0.0   \n",
       "Swope       0.000000  ...         0.0    0.0    0.0    0.0     0.0   0.0   \n",
       "Ulanova     0.000000  ...         0.0    0.0    0.0    0.0     0.0   0.0   \n",
       "Sousa       0.000000  ...         0.0    0.0    0.0    0.0     0.0   0.0   \n",
       "...              ...  ...         ...    ...    ...    ...     ...   ...   \n",
       "Miss Balch  0.000000  ...         0.0    0.0    0.0    0.0     0.0   0.0   \n",
       "Cage        0.011006  ...         0.0    0.0    0.0    0.0     0.0   0.0   \n",
       "Grant       0.007226  ...         0.0    0.0    0.0    0.0     0.0   0.0   \n",
       "Gorky       0.000000  ...         0.0    0.0    0.0    0.0     0.0   0.0   \n",
       "Tandy       0.000000  ...         0.0    0.0    0.0    0.0     0.0   0.0   \n",
       "\n",
       "            zululand  zurich  zvai  zwilich  \n",
       "subject                                      \n",
       "Randolph         0.0     0.0   0.0      0.0  \n",
       "Basie            0.0     0.0   0.0      0.0  \n",
       "Swope            0.0     0.0   0.0      0.0  \n",
       "Ulanova          0.0     0.0   0.0      0.0  \n",
       "Sousa            0.0     0.0   0.0      0.0  \n",
       "...              ...     ...   ...      ...  \n",
       "Miss Balch       0.0     0.0   0.0      0.0  \n",
       "Cage             0.0     0.0   0.0      0.0  \n",
       "Grant            0.0     0.0   0.0      0.0  \n",
       "Gorky            0.0     0.0   0.0      0.0  \n",
       "Tandy            0.0     0.0   0.0      0.0  \n",
       "\n",
       "[364 rows x 35048 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['subject'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36361f6a",
   "metadata": {},
   "source": [
    "Let's store the dataframe in a new numpy array called X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "55c3607e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364, 35048)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.to_numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e0f14df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., ..., 0., 0., 0.]), 'Tandy')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1], df.index[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528dcb5c",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8acd6",
   "metadata": {},
   "source": [
    "Different clustering methods implemented in sklearn:\n",
    "https://scikit-learn.org/stable/modules/clustering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6f5fc370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a7781a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6d2cac",
   "metadata": {},
   "source": [
    "### Train Kmeans model\n",
    "\n",
    "**Question:** What function do we think we can use to train the model?\n",
    "\n",
    "<details>\n",
    "<summary>Hint</summary>\n",
    "    What function did we use yesterday to train the Naive Bayes and Logistic Regression classifiers\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "    .fit()\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ce5af5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.1 s, sys: 11.3 s, total: 30.4 s\n",
      "Wall time: 15.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=10)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "kmeans_model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57258565",
   "metadata": {},
   "source": [
    "#### Properties of the kmeans_model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce15d30",
   "metadata": {},
   "source": [
    "##### Labels (cluster ID) for each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "befacc0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 8, 4, 0, 5, 0, 0, 1, 7, 3, 7, 6, 1, 4, 1, 1, 7, 7, 8, 2, 4,\n",
       "       4, 8, 3, 7, 7, 4, 8, 1, 7, 7, 7, 7, 7, 7, 8, 1, 1, 4, 7, 4, 1, 7,\n",
       "       1, 1, 6, 7, 1, 4, 2, 1, 5, 1, 1, 1, 1, 3, 3, 3, 2, 2, 2, 6, 7, 7,\n",
       "       6, 1, 1, 2, 1, 3, 3, 8, 2, 8, 3, 2, 4, 1, 4, 3, 3, 3, 3, 4, 1, 4,\n",
       "       5, 1, 7, 1, 1, 1, 0, 1, 2, 7, 0, 7, 1, 4, 1, 1, 5, 3, 7, 1, 7, 6,\n",
       "       1, 3, 3, 3, 6, 6, 7, 7, 7, 7, 3, 2, 2, 4, 9, 0, 3, 2, 6, 1, 1, 1,\n",
       "       6, 1, 1, 8, 7, 0, 2, 1, 0, 7, 4, 1, 7, 2, 4, 2, 8, 1, 5, 1, 7, 5,\n",
       "       1, 8, 1, 1, 5, 7, 7, 4, 9, 6, 0, 3, 1, 4, 6, 5, 7, 1, 2, 2, 5, 1,\n",
       "       1, 4, 5, 5, 5, 1, 1, 2, 3, 1, 6, 8, 4, 6, 5, 1, 0, 4, 7, 5, 8, 1,\n",
       "       1, 1, 5, 1, 8, 1, 7, 4, 4, 2, 5, 7, 2, 4, 7, 1, 7, 3, 7, 7, 8, 1,\n",
       "       0, 2, 1, 3, 3, 6, 0, 7, 4, 7, 5, 1, 7, 4, 5, 1, 9, 3, 3, 8, 8, 3,\n",
       "       8, 1, 5, 7, 7, 4, 1, 9, 3, 8, 6, 7, 3, 5, 8, 5, 4, 2, 4, 6, 9, 1,\n",
       "       5, 2, 1, 4, 7, 3, 4, 6, 1, 7, 2, 1, 3, 1, 4, 1, 9, 1, 7, 7, 7, 7,\n",
       "       0, 1, 5, 9, 2, 0, 4, 7, 8, 1, 2, 2, 7, 1, 7, 2, 7, 7, 3, 8, 0, 9,\n",
       "       1, 5, 3, 3, 7, 3, 6, 5, 7, 1, 1, 1, 1, 1, 2, 5, 4, 7, 4, 3, 6, 1,\n",
       "       1, 4, 7, 1, 7, 5, 7, 2, 7, 4, 1, 7, 3, 4, 7, 9, 0, 1, 2, 1, 4, 7,\n",
       "       4, 3, 3, 8, 4, 6, 8, 4, 0, 1, 1, 3], dtype=int32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "21de247f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.labels_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cdb943",
   "metadata": {},
   "source": [
    "We can see how many documents were assigned to each of the 10 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "022d0d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    109\n",
       "1     77\n",
       "0     50\n",
       "4     30\n",
       "9     25\n",
       "7     18\n",
       "6     15\n",
       "8     15\n",
       "5     13\n",
       "3     12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(kmeans_model.labels_).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e87fb6",
   "metadata": {},
   "source": [
    "##### Center for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "acf34d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.13151629e-20,  4.06575815e-20, -2.71050543e-20, ...,\n",
       "        -6.50521303e-19,  2.03287907e-20,  2.01241847e-04],\n",
       "       [ 1.35525272e-19,  4.06575815e-20, -5.42101086e-20, ...,\n",
       "         5.91764335e-04,  2.52508550e-04, -3.38813179e-21],\n",
       "       [ 5.31265089e-04, -2.71050543e-20,  2.50664728e-04, ...,\n",
       "         3.46751869e-03,  4.74338450e-20,  1.69406589e-20],\n",
       "       ...,\n",
       "       [ 0.00000000e+00,  1.35525272e-20,  1.35525272e-20, ...,\n",
       "         9.43100189e-04, -6.77626358e-21,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  2.71050543e-20, ...,\n",
       "         7.68128114e-04, -1.35525272e-20, -1.01643954e-20],\n",
       "       [ 5.42101086e-20,  0.00000000e+00, -1.35525272e-20, ...,\n",
       "         2.16840434e-19, -2.03287907e-20, -1.35525272e-20]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ebc9d6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 35048)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4ea8d57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.13151629e-20,  4.06575815e-20, -2.71050543e-20, ...,\n",
       "       -6.50521303e-19,  2.03287907e-20,  2.01241847e-04])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.cluster_centers_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45358955",
   "metadata": {},
   "source": [
    "**Question** What do these numbers represent?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "    First digit is the number of clusters, second is the dimensions of the center each cluster. 35408 because that is the size of our vocab\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7262b8",
   "metadata": {},
   "source": [
    "#### Determining the cluster for new examples\n",
    "\n",
    "\n",
    "**Question:** What function do we think we can use to use the model to assign clusters to new examples?\n",
    "\n",
    "<details>\n",
    "<summary>Hint</summary>\n",
    "    What function did we use yesterday to test the Naive Bayes and Logistic Regression classifiers\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "    .predict()\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6c9e9189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(kmeans_model.predict(X) == kmeans_model.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c52ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d275468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0e26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee32e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2618fb56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['cluster_id'] = kmeans_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aec3590d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364, 10)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.transform(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d754c67",
   "metadata": {},
   "source": [
    "##### What about transform?\n",
    "\n",
    "\n",
    "Read the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans.transform) and explain what transform does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "771c1dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.01446227, 0.968998  , 0.99437804, ..., 1.01871023, 1.0215985 ,\n",
       "        1.0086711 ],\n",
       "       [1.0162811 , 1.01652489, 1.00574323, ..., 1.03434498, 1.03978371,\n",
       "        1.03477189],\n",
       "       [1.01503917, 1.00060395, 0.99610477, ..., 0.9493088 , 1.02322583,\n",
       "        1.01922157],\n",
       "       ...,\n",
       "       [0.98440418, 0.91760795, 0.95490618, ..., 0.98073109, 1.00096634,\n",
       "        0.95254019],\n",
       "       [1.01120257, 0.99552327, 0.9733883 , ..., 1.02438889, 1.02848637,\n",
       "        1.01180711],\n",
       "       [0.92953461, 1.00070941, 0.98285307, ..., 1.02434561, 1.02970153,\n",
       "        1.01844441]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4239eb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.01446227, 0.968998  , 0.99437804, 1.06468053, 1.0225684 ,\n",
       "       1.0776569 , 1.04485796, 1.01871023, 1.0215985 , 1.0086711 ])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.transform(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9f499568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9689980004973636"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.transform(X)[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "806895d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.transform(X)[0].argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20adb674",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model.transform(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "47af9bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = kmeans_model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f4c3b853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364, 10)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a3bcd5",
   "metadata": {},
   "source": [
    "Let's store the distances in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b6fac938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Randolph</th>\n",
       "      <td>1.050255</td>\n",
       "      <td>0.992309</td>\n",
       "      <td>0.971988</td>\n",
       "      <td>1.018549</td>\n",
       "      <td>1.014761</td>\n",
       "      <td>1.004823</td>\n",
       "      <td>1.025963</td>\n",
       "      <td>0.994651</td>\n",
       "      <td>1.003367</td>\n",
       "      <td>1.041087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Basie</th>\n",
       "      <td>0.905006</td>\n",
       "      <td>1.006532</td>\n",
       "      <td>1.028485</td>\n",
       "      <td>1.021943</td>\n",
       "      <td>1.016609</td>\n",
       "      <td>1.038347</td>\n",
       "      <td>1.030619</td>\n",
       "      <td>1.008315</td>\n",
       "      <td>1.041754</td>\n",
       "      <td>1.068328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swope</th>\n",
       "      <td>1.050978</td>\n",
       "      <td>0.991744</td>\n",
       "      <td>1.016054</td>\n",
       "      <td>1.018812</td>\n",
       "      <td>1.014992</td>\n",
       "      <td>1.017120</td>\n",
       "      <td>1.028645</td>\n",
       "      <td>1.000075</td>\n",
       "      <td>0.979838</td>\n",
       "      <td>1.058061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ulanova</th>\n",
       "      <td>1.049449</td>\n",
       "      <td>1.001388</td>\n",
       "      <td>1.013119</td>\n",
       "      <td>1.008266</td>\n",
       "      <td>0.969042</td>\n",
       "      <td>1.025802</td>\n",
       "      <td>1.036466</td>\n",
       "      <td>1.004284</td>\n",
       "      <td>1.041503</td>\n",
       "      <td>1.061876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sousa</th>\n",
       "      <td>0.917280</td>\n",
       "      <td>0.989117</td>\n",
       "      <td>1.012279</td>\n",
       "      <td>1.012312</td>\n",
       "      <td>1.006967</td>\n",
       "      <td>1.018918</td>\n",
       "      <td>1.025716</td>\n",
       "      <td>0.995399</td>\n",
       "      <td>1.024326</td>\n",
       "      <td>1.042313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss Balch</th>\n",
       "      <td>1.057678</td>\n",
       "      <td>0.996871</td>\n",
       "      <td>1.010870</td>\n",
       "      <td>1.019528</td>\n",
       "      <td>0.954573</td>\n",
       "      <td>1.019678</td>\n",
       "      <td>1.031452</td>\n",
       "      <td>1.002777</td>\n",
       "      <td>1.028669</td>\n",
       "      <td>1.056504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cage</th>\n",
       "      <td>0.954502</td>\n",
       "      <td>0.996745</td>\n",
       "      <td>1.023684</td>\n",
       "      <td>1.011762</td>\n",
       "      <td>1.013191</td>\n",
       "      <td>1.031838</td>\n",
       "      <td>1.031074</td>\n",
       "      <td>0.995110</td>\n",
       "      <td>1.038936</td>\n",
       "      <td>1.067098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grant</th>\n",
       "      <td>1.028280</td>\n",
       "      <td>0.930461</td>\n",
       "      <td>0.964230</td>\n",
       "      <td>0.987903</td>\n",
       "      <td>0.981996</td>\n",
       "      <td>0.943112</td>\n",
       "      <td>1.001914</td>\n",
       "      <td>0.965232</td>\n",
       "      <td>0.956246</td>\n",
       "      <td>1.010986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gorky</th>\n",
       "      <td>1.049887</td>\n",
       "      <td>0.977396</td>\n",
       "      <td>0.999059</td>\n",
       "      <td>1.009530</td>\n",
       "      <td>1.012441</td>\n",
       "      <td>1.011111</td>\n",
       "      <td>1.030489</td>\n",
       "      <td>0.988552</td>\n",
       "      <td>1.031389</td>\n",
       "      <td>1.056955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tandy</th>\n",
       "      <td>1.035551</td>\n",
       "      <td>0.988181</td>\n",
       "      <td>1.013628</td>\n",
       "      <td>0.925911</td>\n",
       "      <td>0.964089</td>\n",
       "      <td>1.020531</td>\n",
       "      <td>1.018067</td>\n",
       "      <td>0.985936</td>\n",
       "      <td>1.029401</td>\n",
       "      <td>1.052152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4         5  \\\n",
       "subject                                                                  \n",
       "Randolph    1.050255  0.992309  0.971988  1.018549  1.014761  1.004823   \n",
       "Basie       0.905006  1.006532  1.028485  1.021943  1.016609  1.038347   \n",
       "Swope       1.050978  0.991744  1.016054  1.018812  1.014992  1.017120   \n",
       "Ulanova     1.049449  1.001388  1.013119  1.008266  0.969042  1.025802   \n",
       "Sousa       0.917280  0.989117  1.012279  1.012312  1.006967  1.018918   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "Miss Balch  1.057678  0.996871  1.010870  1.019528  0.954573  1.019678   \n",
       "Cage        0.954502  0.996745  1.023684  1.011762  1.013191  1.031838   \n",
       "Grant       1.028280  0.930461  0.964230  0.987903  0.981996  0.943112   \n",
       "Gorky       1.049887  0.977396  0.999059  1.009530  1.012441  1.011111   \n",
       "Tandy       1.035551  0.988181  1.013628  0.925911  0.964089  1.020531   \n",
       "\n",
       "                   6         7         8         9  \n",
       "subject                                             \n",
       "Randolph    1.025963  0.994651  1.003367  1.041087  \n",
       "Basie       1.030619  1.008315  1.041754  1.068328  \n",
       "Swope       1.028645  1.000075  0.979838  1.058061  \n",
       "Ulanova     1.036466  1.004284  1.041503  1.061876  \n",
       "Sousa       1.025716  0.995399  1.024326  1.042313  \n",
       "...              ...       ...       ...       ...  \n",
       "Miss Balch  1.031452  1.002777  1.028669  1.056504  \n",
       "Cage        1.031074  0.995110  1.038936  1.067098  \n",
       "Grant       1.001914  0.965232  0.956246  1.010986  \n",
       "Gorky       1.030489  0.988552  1.031389  1.056955  \n",
       "Tandy       1.018067  0.985936  1.029401  1.052152  \n",
       "\n",
       "[364 rows x 10 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_df = pd.DataFrame(distances)\n",
    "distances_df.index = df.index\n",
    "distances_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b3625",
   "metadata": {},
   "source": [
    "### Analyze the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9617e242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.n_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b81503",
   "metadata": {},
   "source": [
    "#### Print out all people in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fb5e0353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Index(['Basie', 'Sousa', 'Kern', 'Hawkins', 'Hines', 'Monk', 'Kenton',\n",
      "       'Waters', 'Sinatra', 'Bernstein', 'Fiedler', 'Goodman', 'Armstrong',\n",
      "       'Davis_1', 'Gillespie', 'Bartok', 'Ravel', 'Cage'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "1 Index(['Salk', 'Jung', 'Rockne', 'Capone', 'Pauling', 'Holmes', 'Lardner',\n",
      "       'Douglass', 'Max Ernst', 'Darwin', 'Frost', 'Schweitzer',\n",
      "       'Abbott McNeil Whistler', 'Carnegie', 'Patton', 'Lindbergh',\n",
      "       'Cleveland', 'Barnum', 'Sabin', 'Dempster', 'Klemperer',\n",
      "       'Henry Huddleston Rogers', 'McCormick', 'Martin', 'Kroc', 'Rawlings',\n",
      "       'O'Neill', 'Rickenbacker', 'Catton', 'Stevenson', 'Sanger',\n",
      "       'Elizabeth Cochrane Seaman', 'Bell', 'Muir', 'Nietzsche', 'Warren',\n",
      "       'C. J. Walker', 'Darrow', 'Pincus', 'Ochs', 'Arthur', 'Edgard Degas',\n",
      "       'Einstein', 'Millay', 'AP)--Frida Kahlo', 'Mahan', 'Maison Dior',\n",
      "       'Picasso', 'Cather', 'McKinley', 'Hill', 'Friendly', 'Roosevelt',\n",
      "       'Shaw', 'Luce_1', 'Henri Matisse', 'La Guardia', 'Sinclair', 'Sloan',\n",
      "       'Tinbergen', 'Edison', 'Fermi', 'Ernie Pyle', 'Geronimo', 'Paul VI',\n",
      "       'Moses', 'Forrest', 'Rockefeller', 'Holland', 'Roosevelt_1_2',\n",
      "       'Tolstoy', 'Brinker', 'Thorpe', 'Rogers', 'Emma Lazarus', 'Pulitzer',\n",
      "       'Daley', 'Ford', 'Conrad', 'Murrow', 'Planck', 'Getty', 'Kellogg',\n",
      "       'Lee', 'Erikson', 'Grant', 'Gorky'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "2 Index(['Randolph', 'Reuther', 'Stone', 'Schultz', 'Rabin', 'Deng', 'Buber',\n",
      "       'Gandhi', 'Weizmann', 'Daladier', 'Earl', 'Abzug', 'Benedict XV',\n",
      "       'Bunche', 'Levi', 'Stalin', 'Hassan', 'Chavez', 'Brezhnev', 'Trudeau',\n",
      "       'Gagarin', 'Meir', 'Gandhi_1', 'Sadat', 'Hitler', 'Eden', 'Hussein',\n",
      "       'Churchill', 'Begin', 'Vargas', 'Senora Peron', 'Sakharov'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "3 Index(['Merrill', 'Wayne', 'Cohan', 'Peggy Ashcroft', 'Capra', 'Porter',\n",
      "       'Stewart', 'Bergman', 'Zukor', 'Eisenstein', 'Fellini', 'Miss Booth',\n",
      "       'Shepard', 'Ball', 'Hitchcock', 'O'Sullivan', 'Chaplin', 'Strasberg',\n",
      "       'Garbo', 'Houseman', 'Dietrich', 'Burton', 'Cagney', 'Abbott', 'Welles',\n",
      "       'Kelly', 'Weissmuller', 'Davis', 'Barrymore', 'Gutenberg',\n",
      "       'Stanislavsky', 'Huston', 'Rodgers', 'Selznick', 'Astaire', 'De Mille',\n",
      "       'Keaton', 'Harrison_1_2', 'Tandy'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "4 Index(['Ulanova', 'Segovia', 'Sullivan', 'Jackson', 'Miss Rankin', 'Hayworth',\n",
      "       'Garland', 'Rubinstein', 'Miss Hellman', 'Macy', 'Tarbell',\n",
      "       'Miss Holiday', 'Graham', 'Anthony', 'Blanchfield', 'Crawford',\n",
      "       'Horowitz', 'Miss Barrymore', 'Miss Smith', 'Jackson_1', 'Stanton',\n",
      "       'Stein', 'Addams', 'Brice', 'Merman', 'Alcott', 'Mitford',\n",
      "       'Miss Cratty', 'Keller', 'Miss Freud', 'Bruce', 'O'Keeffe', 'Cornell',\n",
      "       'Carson', 'Mitchell', 'Coco', 'Monroe', 'Callas', 'Ziegfeld', 'Henie',\n",
      "       'Jewett', 'Miss Balch'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "5 Index(['Franco', 'Nixon', 'Dulles', 'Mao', 'McClung', 'Eisenhower', 'Ho',\n",
      "       'Dirksen', 'Nimitz', 'Harrison', 'Chiang', 'DuBois', 'Hammarskjold',\n",
      "       'Johnson', 'de Gaulle', 'Vinson', 'Watson_1', 'Roosevelt_1', 'Truman',\n",
      "       'Stevenson_1', 'Roosevelt_1_2', 'Acheson', 'MacArthur', 'Dewey',\n",
      "       'Gromyko', 'Dewey_1', 'Khrushchev'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "6 Index(['Ruth', 'Zaharias', 'Ruth_1', 'Robinson', 'Paige', 'Maris', 'Jones',\n",
      "       'Durocher', 'Ashe', 'Louis', 'Handy', 'Tiffany', 'Clemente', 'Montoya',\n",
      "       'Young', 'L'Amour', 'Dempsey', 'Rickey', 'Wills', 'Busch'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "7 Index(['Shawn', 'Stowe', 'Hughes', 'Sagan', 'Grandma Moses', 'McAuliffe',\n",
      "       'Piaget', 'Borges', 'Shockley', 'Beckett', 'Wright', 'Wright_1',\n",
      "       'Kennedy_1', 'Haley', 'Watson', 'Woolf', 'Geisel', 'Spock', 'Malamud',\n",
      "       'Joyce', 'Luce', 'Sartre', 'Pasternak', 'Remarque', 'Carver',\n",
      "       'Fitzgerald', 'Ginsberg', 'Post', 'Crane', 'Taylor', 'Washington',\n",
      "       'Faulkner', 'White', 'Schulz', 'Harrison_1', 'Owens', 'Evans', 'Asimov',\n",
      "       'Leary', 'Bailey', 'London', 'Murdoch', 'Hemingway', 'Lowell',\n",
      "       'White_1', 'Disney', 'Eisenstaedt', 'Adams', 'O'Casey', 'Hale',\n",
      "       'Wharton', 'Carnegie_1', 'Monod', 'Mann', 'Yeats', 'Muhammad',\n",
      "       'Art Deco', 'Mies', 'Capote', 'Baldwin', 'Mead', 'Marcos', 'William',\n",
      "       'Stravinsky', 'Kane', 'Sylvia Plath', 'James'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "8 Index(['Swope', 'Pepper', 'Oppenheimer', 'Kennedy', 'Smith', 'Taft', 'Landon',\n",
      "       'Marshall', 'Harding', 'Warren_1', 'Kennedy_1_2', 'Coolidge', 'Black',\n",
      "       'Sperry', 'O'Neill_1', 'Richardson', 'Johnson_1', 'Hoover', 'Heisman',\n",
      "       'Roosevelt_1_2', 'Hoover_1', 'Rayburn', 'Stimson'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "9 Index(['King', 'Elizabeth', 'Edward', 'Haile Selassie', 'Hirohito', 'Carter',\n",
      "       'Abernathy', 'Nightingale', 'Spaulding'],\n",
      "      dtype='object', name='subject')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cluster_id in range(kmeans_model.n_clusters):\n",
    "    print(cluster_id, df[df['cluster_id'] == cluster_id].index)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25562dee",
   "metadata": {},
   "source": [
    "#### Print out all people in each cluster sorted by distance to cluster's center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a5ac0257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a3cf317e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Smith', 'Nixon', 'Woolf', 'Cleveland', 'Landon', 'Dulles', 'Luce',\n",
       "       'Stevenson', 'Abzug', 'Harding', 'Eisenhower', 'Dirksen', 'McKinley',\n",
       "       'Kennedy_1_2', 'Hammarskjold', 'Luce_1', 'Tinbergen', 'O'Neill_1',\n",
       "       'Stevenson_1', 'Dewey', 'Gromyko', 'Daley', 'Dewey_1', 'Murrow',\n",
       "       'Khrushchev'],\n",
       "      dtype='object', name='subject')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = df[df['cluster_id'] == cluster_id].index\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8db0a9c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Smith</th>\n",
       "      <td>1.009219</td>\n",
       "      <td>0.963055</td>\n",
       "      <td>0.988701</td>\n",
       "      <td>1.063514</td>\n",
       "      <td>1.003986</td>\n",
       "      <td>1.068457</td>\n",
       "      <td>1.041842</td>\n",
       "      <td>1.009109</td>\n",
       "      <td>1.022630</td>\n",
       "      <td>0.925062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nixon</th>\n",
       "      <td>0.994998</td>\n",
       "      <td>0.954814</td>\n",
       "      <td>0.977727</td>\n",
       "      <td>1.051279</td>\n",
       "      <td>1.008888</td>\n",
       "      <td>1.069255</td>\n",
       "      <td>1.031609</td>\n",
       "      <td>1.005071</td>\n",
       "      <td>1.019440</td>\n",
       "      <td>0.911635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Woolf</th>\n",
       "      <td>1.022845</td>\n",
       "      <td>1.016385</td>\n",
       "      <td>1.001092</td>\n",
       "      <td>1.079640</td>\n",
       "      <td>1.033227</td>\n",
       "      <td>1.088379</td>\n",
       "      <td>1.052241</td>\n",
       "      <td>1.035068</td>\n",
       "      <td>1.038992</td>\n",
       "      <td>0.995939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cleveland</th>\n",
       "      <td>1.005757</td>\n",
       "      <td>0.970239</td>\n",
       "      <td>0.979300</td>\n",
       "      <td>1.035559</td>\n",
       "      <td>1.013347</td>\n",
       "      <td>1.072457</td>\n",
       "      <td>1.036547</td>\n",
       "      <td>1.000285</td>\n",
       "      <td>1.022154</td>\n",
       "      <td>0.940417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Landon</th>\n",
       "      <td>1.017640</td>\n",
       "      <td>0.989580</td>\n",
       "      <td>0.999656</td>\n",
       "      <td>1.069814</td>\n",
       "      <td>1.029375</td>\n",
       "      <td>1.082712</td>\n",
       "      <td>1.049168</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>1.031637</td>\n",
       "      <td>0.954601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dulles</th>\n",
       "      <td>1.014629</td>\n",
       "      <td>0.973348</td>\n",
       "      <td>0.991451</td>\n",
       "      <td>1.070367</td>\n",
       "      <td>1.022485</td>\n",
       "      <td>1.080489</td>\n",
       "      <td>1.042957</td>\n",
       "      <td>1.016207</td>\n",
       "      <td>1.027031</td>\n",
       "      <td>0.945722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luce</th>\n",
       "      <td>1.000619</td>\n",
       "      <td>0.988616</td>\n",
       "      <td>0.984775</td>\n",
       "      <td>1.065702</td>\n",
       "      <td>1.012757</td>\n",
       "      <td>1.075659</td>\n",
       "      <td>1.039224</td>\n",
       "      <td>1.021201</td>\n",
       "      <td>1.028792</td>\n",
       "      <td>0.935030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stevenson</th>\n",
       "      <td>1.006485</td>\n",
       "      <td>0.997860</td>\n",
       "      <td>0.977892</td>\n",
       "      <td>1.067421</td>\n",
       "      <td>1.016133</td>\n",
       "      <td>1.072652</td>\n",
       "      <td>1.035092</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.027302</td>\n",
       "      <td>0.959201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abzug</th>\n",
       "      <td>1.015207</td>\n",
       "      <td>0.994696</td>\n",
       "      <td>0.997320</td>\n",
       "      <td>1.072530</td>\n",
       "      <td>1.023554</td>\n",
       "      <td>1.080453</td>\n",
       "      <td>1.046063</td>\n",
       "      <td>1.027098</td>\n",
       "      <td>1.033965</td>\n",
       "      <td>0.965336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harding</th>\n",
       "      <td>1.010777</td>\n",
       "      <td>0.968729</td>\n",
       "      <td>0.988865</td>\n",
       "      <td>1.059173</td>\n",
       "      <td>1.018356</td>\n",
       "      <td>1.076933</td>\n",
       "      <td>1.043025</td>\n",
       "      <td>1.012750</td>\n",
       "      <td>1.026690</td>\n",
       "      <td>0.932964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eisenhower</th>\n",
       "      <td>1.003403</td>\n",
       "      <td>0.937358</td>\n",
       "      <td>0.978637</td>\n",
       "      <td>1.056060</td>\n",
       "      <td>1.010164</td>\n",
       "      <td>1.071569</td>\n",
       "      <td>1.035080</td>\n",
       "      <td>1.002095</td>\n",
       "      <td>1.016443</td>\n",
       "      <td>0.892555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dirksen</th>\n",
       "      <td>1.011379</td>\n",
       "      <td>0.980115</td>\n",
       "      <td>0.992115</td>\n",
       "      <td>1.063703</td>\n",
       "      <td>1.020343</td>\n",
       "      <td>1.078090</td>\n",
       "      <td>1.043764</td>\n",
       "      <td>1.019518</td>\n",
       "      <td>1.028181</td>\n",
       "      <td>0.947491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>McKinley</th>\n",
       "      <td>1.007799</td>\n",
       "      <td>0.971613</td>\n",
       "      <td>0.986464</td>\n",
       "      <td>1.061201</td>\n",
       "      <td>1.011275</td>\n",
       "      <td>1.074259</td>\n",
       "      <td>1.039398</td>\n",
       "      <td>1.010909</td>\n",
       "      <td>1.023227</td>\n",
       "      <td>0.951368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy_1_2</th>\n",
       "      <td>0.998504</td>\n",
       "      <td>0.959098</td>\n",
       "      <td>0.978913</td>\n",
       "      <td>1.052503</td>\n",
       "      <td>1.010721</td>\n",
       "      <td>1.069266</td>\n",
       "      <td>1.037965</td>\n",
       "      <td>1.009631</td>\n",
       "      <td>1.021202</td>\n",
       "      <td>0.926736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hammarskjold</th>\n",
       "      <td>1.014971</td>\n",
       "      <td>0.977051</td>\n",
       "      <td>0.991395</td>\n",
       "      <td>1.070441</td>\n",
       "      <td>1.023340</td>\n",
       "      <td>1.080351</td>\n",
       "      <td>1.042075</td>\n",
       "      <td>1.017764</td>\n",
       "      <td>1.026544</td>\n",
       "      <td>0.957458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luce_1</th>\n",
       "      <td>1.011131</td>\n",
       "      <td>1.001138</td>\n",
       "      <td>0.988719</td>\n",
       "      <td>1.066854</td>\n",
       "      <td>1.023052</td>\n",
       "      <td>1.080260</td>\n",
       "      <td>1.043614</td>\n",
       "      <td>1.019885</td>\n",
       "      <td>1.030823</td>\n",
       "      <td>0.950416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tinbergen</th>\n",
       "      <td>1.021190</td>\n",
       "      <td>1.000904</td>\n",
       "      <td>0.998958</td>\n",
       "      <td>1.074167</td>\n",
       "      <td>1.030352</td>\n",
       "      <td>1.086171</td>\n",
       "      <td>1.048747</td>\n",
       "      <td>1.022684</td>\n",
       "      <td>1.020452</td>\n",
       "      <td>0.979912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O'Neill_1</th>\n",
       "      <td>0.998019</td>\n",
       "      <td>0.953227</td>\n",
       "      <td>0.976662</td>\n",
       "      <td>1.049696</td>\n",
       "      <td>1.005341</td>\n",
       "      <td>1.067904</td>\n",
       "      <td>1.034595</td>\n",
       "      <td>1.004557</td>\n",
       "      <td>1.017619</td>\n",
       "      <td>0.921700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stevenson_1</th>\n",
       "      <td>1.008978</td>\n",
       "      <td>0.968454</td>\n",
       "      <td>0.987584</td>\n",
       "      <td>1.064105</td>\n",
       "      <td>1.018899</td>\n",
       "      <td>1.076244</td>\n",
       "      <td>1.041585</td>\n",
       "      <td>1.014176</td>\n",
       "      <td>1.023549</td>\n",
       "      <td>0.896690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dewey</th>\n",
       "      <td>1.006511</td>\n",
       "      <td>0.976902</td>\n",
       "      <td>0.976363</td>\n",
       "      <td>1.063121</td>\n",
       "      <td>1.009748</td>\n",
       "      <td>1.072824</td>\n",
       "      <td>1.033005</td>\n",
       "      <td>1.010072</td>\n",
       "      <td>1.003782</td>\n",
       "      <td>0.937513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gromyko</th>\n",
       "      <td>1.018806</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.994993</td>\n",
       "      <td>1.074109</td>\n",
       "      <td>1.028071</td>\n",
       "      <td>1.082705</td>\n",
       "      <td>1.045773</td>\n",
       "      <td>1.025397</td>\n",
       "      <td>1.031741</td>\n",
       "      <td>0.956800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daley</th>\n",
       "      <td>1.015086</td>\n",
       "      <td>0.991188</td>\n",
       "      <td>0.997211</td>\n",
       "      <td>1.067176</td>\n",
       "      <td>1.028631</td>\n",
       "      <td>1.078758</td>\n",
       "      <td>1.044628</td>\n",
       "      <td>1.023725</td>\n",
       "      <td>1.031540</td>\n",
       "      <td>0.956765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dewey_1</th>\n",
       "      <td>1.019558</td>\n",
       "      <td>1.006885</td>\n",
       "      <td>0.997097</td>\n",
       "      <td>1.065284</td>\n",
       "      <td>1.028132</td>\n",
       "      <td>1.079040</td>\n",
       "      <td>1.045403</td>\n",
       "      <td>1.021658</td>\n",
       "      <td>1.028547</td>\n",
       "      <td>0.969059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Murrow</th>\n",
       "      <td>0.998684</td>\n",
       "      <td>0.995964</td>\n",
       "      <td>0.991547</td>\n",
       "      <td>1.069339</td>\n",
       "      <td>1.022601</td>\n",
       "      <td>1.078651</td>\n",
       "      <td>1.041852</td>\n",
       "      <td>1.019353</td>\n",
       "      <td>1.029080</td>\n",
       "      <td>0.973068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Khrushchev</th>\n",
       "      <td>1.011766</td>\n",
       "      <td>0.963498</td>\n",
       "      <td>0.985546</td>\n",
       "      <td>1.070168</td>\n",
       "      <td>1.019560</td>\n",
       "      <td>1.077567</td>\n",
       "      <td>1.040459</td>\n",
       "      <td>1.016896</td>\n",
       "      <td>1.024749</td>\n",
       "      <td>0.939315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4         5  \\\n",
       "subject                                                                    \n",
       "Smith         1.009219  0.963055  0.988701  1.063514  1.003986  1.068457   \n",
       "Nixon         0.994998  0.954814  0.977727  1.051279  1.008888  1.069255   \n",
       "Woolf         1.022845  1.016385  1.001092  1.079640  1.033227  1.088379   \n",
       "Cleveland     1.005757  0.970239  0.979300  1.035559  1.013347  1.072457   \n",
       "Landon        1.017640  0.989580  0.999656  1.069814  1.029375  1.082712   \n",
       "Dulles        1.014629  0.973348  0.991451  1.070367  1.022485  1.080489   \n",
       "Luce          1.000619  0.988616  0.984775  1.065702  1.012757  1.075659   \n",
       "Stevenson     1.006485  0.997860  0.977892  1.067421  1.016133  1.072652   \n",
       "Abzug         1.015207  0.994696  0.997320  1.072530  1.023554  1.080453   \n",
       "Harding       1.010777  0.968729  0.988865  1.059173  1.018356  1.076933   \n",
       "Eisenhower    1.003403  0.937358  0.978637  1.056060  1.010164  1.071569   \n",
       "Dirksen       1.011379  0.980115  0.992115  1.063703  1.020343  1.078090   \n",
       "McKinley      1.007799  0.971613  0.986464  1.061201  1.011275  1.074259   \n",
       "Kennedy_1_2   0.998504  0.959098  0.978913  1.052503  1.010721  1.069266   \n",
       "Hammarskjold  1.014971  0.977051  0.991395  1.070441  1.023340  1.080351   \n",
       "Luce_1        1.011131  1.001138  0.988719  1.066854  1.023052  1.080260   \n",
       "Tinbergen     1.021190  1.000904  0.998958  1.074167  1.030352  1.086171   \n",
       "O'Neill_1     0.998019  0.953227  0.976662  1.049696  1.005341  1.067904   \n",
       "Stevenson_1   1.008978  0.968454  0.987584  1.064105  1.018899  1.076244   \n",
       "Dewey         1.006511  0.976902  0.976363  1.063121  1.009748  1.072824   \n",
       "Gromyko       1.018806  0.979798  0.994993  1.074109  1.028071  1.082705   \n",
       "Daley         1.015086  0.991188  0.997211  1.067176  1.028631  1.078758   \n",
       "Dewey_1       1.019558  1.006885  0.997097  1.065284  1.028132  1.079040   \n",
       "Murrow        0.998684  0.995964  0.991547  1.069339  1.022601  1.078651   \n",
       "Khrushchev    1.011766  0.963498  0.985546  1.070168  1.019560  1.077567   \n",
       "\n",
       "                     6         7         8         9  \n",
       "subject                                               \n",
       "Smith         1.041842  1.009109  1.022630  0.925062  \n",
       "Nixon         1.031609  1.005071  1.019440  0.911635  \n",
       "Woolf         1.052241  1.035068  1.038992  0.995939  \n",
       "Cleveland     1.036547  1.000285  1.022154  0.940417  \n",
       "Landon        1.049168  1.022606  1.031637  0.954601  \n",
       "Dulles        1.042957  1.016207  1.027031  0.945722  \n",
       "Luce          1.039224  1.021201  1.028792  0.935030  \n",
       "Stevenson     1.035092  1.021045  1.027302  0.959201  \n",
       "Abzug         1.046063  1.027098  1.033965  0.965336  \n",
       "Harding       1.043025  1.012750  1.026690  0.932964  \n",
       "Eisenhower    1.035080  1.002095  1.016443  0.892555  \n",
       "Dirksen       1.043764  1.019518  1.028181  0.947491  \n",
       "McKinley      1.039398  1.010909  1.023227  0.951368  \n",
       "Kennedy_1_2   1.037965  1.009631  1.021202  0.926736  \n",
       "Hammarskjold  1.042075  1.017764  1.026544  0.957458  \n",
       "Luce_1        1.043614  1.019885  1.030823  0.950416  \n",
       "Tinbergen     1.048747  1.022684  1.020452  0.979912  \n",
       "O'Neill_1     1.034595  1.004557  1.017619  0.921700  \n",
       "Stevenson_1   1.041585  1.014176  1.023549  0.896690  \n",
       "Dewey         1.033005  1.010072  1.003782  0.937513  \n",
       "Gromyko       1.045773  1.025397  1.031741  0.956800  \n",
       "Daley         1.044628  1.023725  1.031540  0.956765  \n",
       "Dewey_1       1.045403  1.021658  1.028547  0.969059  \n",
       "Murrow        1.041852  1.019353  1.029080  0.973068  \n",
       "Khrushchev    1.040459  1.016896  1.024749  0.939315  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_df[distances_df.index.isin(names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6b24a4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Eisenhower</th>\n",
       "      <td>1.003403</td>\n",
       "      <td>0.937358</td>\n",
       "      <td>0.978637</td>\n",
       "      <td>1.056060</td>\n",
       "      <td>1.010164</td>\n",
       "      <td>1.071569</td>\n",
       "      <td>1.035080</td>\n",
       "      <td>1.002095</td>\n",
       "      <td>1.016443</td>\n",
       "      <td>0.892555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stevenson_1</th>\n",
       "      <td>1.008978</td>\n",
       "      <td>0.968454</td>\n",
       "      <td>0.987584</td>\n",
       "      <td>1.064105</td>\n",
       "      <td>1.018899</td>\n",
       "      <td>1.076244</td>\n",
       "      <td>1.041585</td>\n",
       "      <td>1.014176</td>\n",
       "      <td>1.023549</td>\n",
       "      <td>0.896690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nixon</th>\n",
       "      <td>0.994998</td>\n",
       "      <td>0.954814</td>\n",
       "      <td>0.977727</td>\n",
       "      <td>1.051279</td>\n",
       "      <td>1.008888</td>\n",
       "      <td>1.069255</td>\n",
       "      <td>1.031609</td>\n",
       "      <td>1.005071</td>\n",
       "      <td>1.019440</td>\n",
       "      <td>0.911635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O'Neill_1</th>\n",
       "      <td>0.998019</td>\n",
       "      <td>0.953227</td>\n",
       "      <td>0.976662</td>\n",
       "      <td>1.049696</td>\n",
       "      <td>1.005341</td>\n",
       "      <td>1.067904</td>\n",
       "      <td>1.034595</td>\n",
       "      <td>1.004557</td>\n",
       "      <td>1.017619</td>\n",
       "      <td>0.921700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smith</th>\n",
       "      <td>1.009219</td>\n",
       "      <td>0.963055</td>\n",
       "      <td>0.988701</td>\n",
       "      <td>1.063514</td>\n",
       "      <td>1.003986</td>\n",
       "      <td>1.068457</td>\n",
       "      <td>1.041842</td>\n",
       "      <td>1.009109</td>\n",
       "      <td>1.022630</td>\n",
       "      <td>0.925062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kennedy_1_2</th>\n",
       "      <td>0.998504</td>\n",
       "      <td>0.959098</td>\n",
       "      <td>0.978913</td>\n",
       "      <td>1.052503</td>\n",
       "      <td>1.010721</td>\n",
       "      <td>1.069266</td>\n",
       "      <td>1.037965</td>\n",
       "      <td>1.009631</td>\n",
       "      <td>1.021202</td>\n",
       "      <td>0.926736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harding</th>\n",
       "      <td>1.010777</td>\n",
       "      <td>0.968729</td>\n",
       "      <td>0.988865</td>\n",
       "      <td>1.059173</td>\n",
       "      <td>1.018356</td>\n",
       "      <td>1.076933</td>\n",
       "      <td>1.043025</td>\n",
       "      <td>1.012750</td>\n",
       "      <td>1.026690</td>\n",
       "      <td>0.932964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luce</th>\n",
       "      <td>1.000619</td>\n",
       "      <td>0.988616</td>\n",
       "      <td>0.984775</td>\n",
       "      <td>1.065702</td>\n",
       "      <td>1.012757</td>\n",
       "      <td>1.075659</td>\n",
       "      <td>1.039224</td>\n",
       "      <td>1.021201</td>\n",
       "      <td>1.028792</td>\n",
       "      <td>0.935030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dewey</th>\n",
       "      <td>1.006511</td>\n",
       "      <td>0.976902</td>\n",
       "      <td>0.976363</td>\n",
       "      <td>1.063121</td>\n",
       "      <td>1.009748</td>\n",
       "      <td>1.072824</td>\n",
       "      <td>1.033005</td>\n",
       "      <td>1.010072</td>\n",
       "      <td>1.003782</td>\n",
       "      <td>0.937513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Khrushchev</th>\n",
       "      <td>1.011766</td>\n",
       "      <td>0.963498</td>\n",
       "      <td>0.985546</td>\n",
       "      <td>1.070168</td>\n",
       "      <td>1.019560</td>\n",
       "      <td>1.077567</td>\n",
       "      <td>1.040459</td>\n",
       "      <td>1.016896</td>\n",
       "      <td>1.024749</td>\n",
       "      <td>0.939315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cleveland</th>\n",
       "      <td>1.005757</td>\n",
       "      <td>0.970239</td>\n",
       "      <td>0.979300</td>\n",
       "      <td>1.035559</td>\n",
       "      <td>1.013347</td>\n",
       "      <td>1.072457</td>\n",
       "      <td>1.036547</td>\n",
       "      <td>1.000285</td>\n",
       "      <td>1.022154</td>\n",
       "      <td>0.940417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dulles</th>\n",
       "      <td>1.014629</td>\n",
       "      <td>0.973348</td>\n",
       "      <td>0.991451</td>\n",
       "      <td>1.070367</td>\n",
       "      <td>1.022485</td>\n",
       "      <td>1.080489</td>\n",
       "      <td>1.042957</td>\n",
       "      <td>1.016207</td>\n",
       "      <td>1.027031</td>\n",
       "      <td>0.945722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dirksen</th>\n",
       "      <td>1.011379</td>\n",
       "      <td>0.980115</td>\n",
       "      <td>0.992115</td>\n",
       "      <td>1.063703</td>\n",
       "      <td>1.020343</td>\n",
       "      <td>1.078090</td>\n",
       "      <td>1.043764</td>\n",
       "      <td>1.019518</td>\n",
       "      <td>1.028181</td>\n",
       "      <td>0.947491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luce_1</th>\n",
       "      <td>1.011131</td>\n",
       "      <td>1.001138</td>\n",
       "      <td>0.988719</td>\n",
       "      <td>1.066854</td>\n",
       "      <td>1.023052</td>\n",
       "      <td>1.080260</td>\n",
       "      <td>1.043614</td>\n",
       "      <td>1.019885</td>\n",
       "      <td>1.030823</td>\n",
       "      <td>0.950416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>McKinley</th>\n",
       "      <td>1.007799</td>\n",
       "      <td>0.971613</td>\n",
       "      <td>0.986464</td>\n",
       "      <td>1.061201</td>\n",
       "      <td>1.011275</td>\n",
       "      <td>1.074259</td>\n",
       "      <td>1.039398</td>\n",
       "      <td>1.010909</td>\n",
       "      <td>1.023227</td>\n",
       "      <td>0.951368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Landon</th>\n",
       "      <td>1.017640</td>\n",
       "      <td>0.989580</td>\n",
       "      <td>0.999656</td>\n",
       "      <td>1.069814</td>\n",
       "      <td>1.029375</td>\n",
       "      <td>1.082712</td>\n",
       "      <td>1.049168</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>1.031637</td>\n",
       "      <td>0.954601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daley</th>\n",
       "      <td>1.015086</td>\n",
       "      <td>0.991188</td>\n",
       "      <td>0.997211</td>\n",
       "      <td>1.067176</td>\n",
       "      <td>1.028631</td>\n",
       "      <td>1.078758</td>\n",
       "      <td>1.044628</td>\n",
       "      <td>1.023725</td>\n",
       "      <td>1.031540</td>\n",
       "      <td>0.956765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gromyko</th>\n",
       "      <td>1.018806</td>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.994993</td>\n",
       "      <td>1.074109</td>\n",
       "      <td>1.028071</td>\n",
       "      <td>1.082705</td>\n",
       "      <td>1.045773</td>\n",
       "      <td>1.025397</td>\n",
       "      <td>1.031741</td>\n",
       "      <td>0.956800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hammarskjold</th>\n",
       "      <td>1.014971</td>\n",
       "      <td>0.977051</td>\n",
       "      <td>0.991395</td>\n",
       "      <td>1.070441</td>\n",
       "      <td>1.023340</td>\n",
       "      <td>1.080351</td>\n",
       "      <td>1.042075</td>\n",
       "      <td>1.017764</td>\n",
       "      <td>1.026544</td>\n",
       "      <td>0.957458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stevenson</th>\n",
       "      <td>1.006485</td>\n",
       "      <td>0.997860</td>\n",
       "      <td>0.977892</td>\n",
       "      <td>1.067421</td>\n",
       "      <td>1.016133</td>\n",
       "      <td>1.072652</td>\n",
       "      <td>1.035092</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.027302</td>\n",
       "      <td>0.959201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abzug</th>\n",
       "      <td>1.015207</td>\n",
       "      <td>0.994696</td>\n",
       "      <td>0.997320</td>\n",
       "      <td>1.072530</td>\n",
       "      <td>1.023554</td>\n",
       "      <td>1.080453</td>\n",
       "      <td>1.046063</td>\n",
       "      <td>1.027098</td>\n",
       "      <td>1.033965</td>\n",
       "      <td>0.965336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dewey_1</th>\n",
       "      <td>1.019558</td>\n",
       "      <td>1.006885</td>\n",
       "      <td>0.997097</td>\n",
       "      <td>1.065284</td>\n",
       "      <td>1.028132</td>\n",
       "      <td>1.079040</td>\n",
       "      <td>1.045403</td>\n",
       "      <td>1.021658</td>\n",
       "      <td>1.028547</td>\n",
       "      <td>0.969059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Murrow</th>\n",
       "      <td>0.998684</td>\n",
       "      <td>0.995964</td>\n",
       "      <td>0.991547</td>\n",
       "      <td>1.069339</td>\n",
       "      <td>1.022601</td>\n",
       "      <td>1.078651</td>\n",
       "      <td>1.041852</td>\n",
       "      <td>1.019353</td>\n",
       "      <td>1.029080</td>\n",
       "      <td>0.973068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tinbergen</th>\n",
       "      <td>1.021190</td>\n",
       "      <td>1.000904</td>\n",
       "      <td>0.998958</td>\n",
       "      <td>1.074167</td>\n",
       "      <td>1.030352</td>\n",
       "      <td>1.086171</td>\n",
       "      <td>1.048747</td>\n",
       "      <td>1.022684</td>\n",
       "      <td>1.020452</td>\n",
       "      <td>0.979912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Woolf</th>\n",
       "      <td>1.022845</td>\n",
       "      <td>1.016385</td>\n",
       "      <td>1.001092</td>\n",
       "      <td>1.079640</td>\n",
       "      <td>1.033227</td>\n",
       "      <td>1.088379</td>\n",
       "      <td>1.052241</td>\n",
       "      <td>1.035068</td>\n",
       "      <td>1.038992</td>\n",
       "      <td>0.995939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4         5  \\\n",
       "subject                                                                    \n",
       "Eisenhower    1.003403  0.937358  0.978637  1.056060  1.010164  1.071569   \n",
       "Stevenson_1   1.008978  0.968454  0.987584  1.064105  1.018899  1.076244   \n",
       "Nixon         0.994998  0.954814  0.977727  1.051279  1.008888  1.069255   \n",
       "O'Neill_1     0.998019  0.953227  0.976662  1.049696  1.005341  1.067904   \n",
       "Smith         1.009219  0.963055  0.988701  1.063514  1.003986  1.068457   \n",
       "Kennedy_1_2   0.998504  0.959098  0.978913  1.052503  1.010721  1.069266   \n",
       "Harding       1.010777  0.968729  0.988865  1.059173  1.018356  1.076933   \n",
       "Luce          1.000619  0.988616  0.984775  1.065702  1.012757  1.075659   \n",
       "Dewey         1.006511  0.976902  0.976363  1.063121  1.009748  1.072824   \n",
       "Khrushchev    1.011766  0.963498  0.985546  1.070168  1.019560  1.077567   \n",
       "Cleveland     1.005757  0.970239  0.979300  1.035559  1.013347  1.072457   \n",
       "Dulles        1.014629  0.973348  0.991451  1.070367  1.022485  1.080489   \n",
       "Dirksen       1.011379  0.980115  0.992115  1.063703  1.020343  1.078090   \n",
       "Luce_1        1.011131  1.001138  0.988719  1.066854  1.023052  1.080260   \n",
       "McKinley      1.007799  0.971613  0.986464  1.061201  1.011275  1.074259   \n",
       "Landon        1.017640  0.989580  0.999656  1.069814  1.029375  1.082712   \n",
       "Daley         1.015086  0.991188  0.997211  1.067176  1.028631  1.078758   \n",
       "Gromyko       1.018806  0.979798  0.994993  1.074109  1.028071  1.082705   \n",
       "Hammarskjold  1.014971  0.977051  0.991395  1.070441  1.023340  1.080351   \n",
       "Stevenson     1.006485  0.997860  0.977892  1.067421  1.016133  1.072652   \n",
       "Abzug         1.015207  0.994696  0.997320  1.072530  1.023554  1.080453   \n",
       "Dewey_1       1.019558  1.006885  0.997097  1.065284  1.028132  1.079040   \n",
       "Murrow        0.998684  0.995964  0.991547  1.069339  1.022601  1.078651   \n",
       "Tinbergen     1.021190  1.000904  0.998958  1.074167  1.030352  1.086171   \n",
       "Woolf         1.022845  1.016385  1.001092  1.079640  1.033227  1.088379   \n",
       "\n",
       "                     6         7         8         9  \n",
       "subject                                               \n",
       "Eisenhower    1.035080  1.002095  1.016443  0.892555  \n",
       "Stevenson_1   1.041585  1.014176  1.023549  0.896690  \n",
       "Nixon         1.031609  1.005071  1.019440  0.911635  \n",
       "O'Neill_1     1.034595  1.004557  1.017619  0.921700  \n",
       "Smith         1.041842  1.009109  1.022630  0.925062  \n",
       "Kennedy_1_2   1.037965  1.009631  1.021202  0.926736  \n",
       "Harding       1.043025  1.012750  1.026690  0.932964  \n",
       "Luce          1.039224  1.021201  1.028792  0.935030  \n",
       "Dewey         1.033005  1.010072  1.003782  0.937513  \n",
       "Khrushchev    1.040459  1.016896  1.024749  0.939315  \n",
       "Cleveland     1.036547  1.000285  1.022154  0.940417  \n",
       "Dulles        1.042957  1.016207  1.027031  0.945722  \n",
       "Dirksen       1.043764  1.019518  1.028181  0.947491  \n",
       "Luce_1        1.043614  1.019885  1.030823  0.950416  \n",
       "McKinley      1.039398  1.010909  1.023227  0.951368  \n",
       "Landon        1.049168  1.022606  1.031637  0.954601  \n",
       "Daley         1.044628  1.023725  1.031540  0.956765  \n",
       "Gromyko       1.045773  1.025397  1.031741  0.956800  \n",
       "Hammarskjold  1.042075  1.017764  1.026544  0.957458  \n",
       "Stevenson     1.035092  1.021045  1.027302  0.959201  \n",
       "Abzug         1.046063  1.027098  1.033965  0.965336  \n",
       "Dewey_1       1.045403  1.021658  1.028547  0.969059  \n",
       "Murrow        1.041852  1.019353  1.029080  0.973068  \n",
       "Tinbergen     1.048747  1.022684  1.020452  0.979912  \n",
       "Woolf         1.052241  1.035068  1.038992  0.995939  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_df[distances_df.index.isin(names)].sort_values(by=cluster_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b8660e",
   "metadata": {},
   "source": [
    "Let's put it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a1d138df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Index(['Hines', 'Goodman', 'Davis_1', 'Gillespie', 'Armstrong', 'Basie',\n",
      "       'Kenton', 'Hawkins', 'Monk', 'Sousa'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "1 Index(['Grant', 'Pulitzer', 'O'Neill', 'Holmes', 'Cleveland', 'Einstein',\n",
      "       'Hill', 'Rockefeller', 'Carnegie', 'Ochs'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "2 Index(['Meir', 'Begin', 'Gandhi_1', 'Rabin', 'Sadat', 'Weizmann', 'Hassan',\n",
      "       'Churchill', 'Hussein', 'Hitler'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "3 Index(['Tandy', 'Stewart', 'Astaire', 'Huston', 'Bergman', 'Welles',\n",
      "       'Peggy Ashcroft', 'Harrison_1_2', 'Cagney', 'Ball'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "4 Index(['O'Keeffe', 'Keller', 'Anthony', 'Jackson_1', 'Miss Holiday', 'Jackson',\n",
      "       'Miss Smith', 'Addams', 'Callas', 'Garland'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "5 Index(['Truman', 'Eisenhower', 'Roosevelt_1', 'Acheson', 'Vinson', 'Nixon',\n",
      "       'Khrushchev', 'Stevenson_1', 'Johnson', 'Dulles'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "6 Index(['Ruth_1', 'Robinson', 'Young', 'Rickey', 'Maris', 'Paige', 'Durocher',\n",
      "       'Jones', 'Louis', 'Zaharias'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "7 Index(['White', 'Wharton', 'Wright_1', 'Kennedy_1', 'Washington', 'O'Casey',\n",
      "       'Beckett', 'James', 'Stowe', 'Capote'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "8 Index(['O'Neill_1', 'Coolidge', 'Black', 'Roosevelt_1_2', 'Hoover', 'Smith',\n",
      "       'Hoover_1', 'Kennedy', 'Kennedy_1_2', 'Taft'],\n",
      "      dtype='object', name='subject')\n",
      "\n",
      "9 Index(['Elizabeth', 'Edward', 'King', 'Abernathy', 'Hirohito',\n",
      "       'Haile Selassie', 'Nightingale', 'Carter', 'Spaulding'],\n",
      "      dtype='object', name='subject')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cluster_id in range(kmeans_model.n_clusters):\n",
    "    names = df[df['cluster_id'] == cluster_id].index\n",
    "    print(cluster_id, distances_df[distances_df.index.isin(names)].sort_values(by=cluster_id).index[:10])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32053198",
   "metadata": {},
   "source": [
    "Let's look at the lists above and let's see what we find"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b67a556",
   "metadata": {},
   "source": [
    "(stop here)\n",
    "\n",
    "### AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "40976695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgglomerativeClustering(compute_distances=True, n_clusters=5)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "agg_model = AgglomerativeClustering(n_clusters=5, compute_distances=True)\n",
    "agg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b63499af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.35 s, sys: 29.4 ms, total: 2.38 s\n",
      "Wall time: 2.38 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgglomerativeClustering(compute_distances=True, n_clusters=5)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "agg_model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8689f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_model.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c91169",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(agg_model.labels_).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b22f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_model.children_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af8e65",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7ab9e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_,\n",
    "                                      counts]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6978b522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "# plot the top three levels of the dendrogram\n",
    "plot_dendrogram(agg_model, truncate_mode='level', p=3)\n",
    "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f57992",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "# plot the top three levels of the dendrogram\n",
    "plot_dendrogram(agg_model, truncate_mode='level', p=5)\n",
    "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef0364c",
   "metadata": {},
   "source": [
    "(next week)\n",
    "\n",
    "\n",
    "## Matrix Factorization / Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a2b748",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a851bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "\n",
    "k = 10\n",
    "svd = TruncatedSVD(n_components=k) \n",
    "U = svd.fit_transform(df)\n",
    "S = svd.singular_values_\n",
    "V = svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d255a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12de1571",
   "metadata": {},
   "outputs": [],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae8a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62a26ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c514599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ca0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "V.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46737dc",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=k, init='nndsvd', random_state=0) \n",
    "W = nmf.fit_transform(df)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066b644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63ecbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d05ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
