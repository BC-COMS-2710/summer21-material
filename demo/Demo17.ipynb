{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb949e6",
   "metadata": {},
   "source": [
    "# Demo 17 - Naive Bayes and Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0212875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a98d3a",
   "metadata": {},
   "source": [
    "## Multiplying Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686bb13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand() * np.random.rand() * np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec17baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_number = np.random.rand() \n",
    "for i in range(10):\n",
    "    rand_number *= np.random.rand() \n",
    "rand_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ff3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_number = np.random.rand() \n",
    "for i in range(100):\n",
    "    rand_number *= np.random.rand() \n",
    "rand_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6de7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_number = np.random.rand() \n",
    "for i in range(500):\n",
    "    rand_number *= np.random.rand() \n",
    "rand_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42c9746",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_number = np.random.rand() \n",
    "for i in range(600):\n",
    "    rand_number *= np.random.rand() \n",
    "rand_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c68fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_number = np.random.rand() \n",
    "for i in range(1000):\n",
    "    rand_number *= np.random.rand() \n",
    "rand_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa0bd9c",
   "metadata": {},
   "source": [
    "(back to slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b0f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a15e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b26f276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0972a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f247d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0c1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18311db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0f51df5",
   "metadata": {},
   "source": [
    "#### Logs to the rescue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc61515",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_number = np.log(np.random.rand())\n",
    "for i in range(1000):\n",
    "    rand_number += np.log(np.random.rand()) \n",
    "rand_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f93006",
   "metadata": {},
   "source": [
    "## Sklearn\n",
    "\n",
    "### Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "moview_reviews = nltk.corpus.movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b3f7bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "review_files = [(file_id, file_id.startswith(\"pos\")) for file_id in moview_reviews.fileids()]\n",
    "\n",
    "len(neg_review), len(pos_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3189853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(review_files)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71c045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={0: \"file_name\", 1: \"gold-label\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd6bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mov_review(f_name):\n",
    "    return moview_reviews.open(f_name).read()\n",
    "\n",
    "df['review_text'] = df['file_name'].apply(read_mov_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea1d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff1f55",
   "metadata": {},
   "source": [
    "#### Make train/dev/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59797828",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(df.shape[0])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74152bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5b9a55",
   "metadata": {},
   "source": [
    "Let's make 80:10:10 split of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bffa90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max_idx = int(df.shape[0] * .8)\n",
    "dev_max_idx = int((df.shape[0] * .1) + train_max_idx)\n",
    "\n",
    "\n",
    "train_max_idx, dev_max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a03730",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[:train_max_idx]\n",
    "dev_df = df.iloc[train_max_idx:dev_max_idx]\n",
    "test_df = df.iloc[dev_max_idx:]\n",
    "\n",
    "train_df.shape, dev_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ae8b5e",
   "metadata": {},
   "source": [
    "We will train models on `train_df`, change different hyper-parameters based on `dev_df`, and then evaluate the model on `test_df` once we are done changing our different hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07657075",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125e484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b9538",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.fit(train_df['review_text'], train_df['gold-label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dff28f8",
   "metadata": {},
   "source": [
    "**Question:** What happened?\n",
    "\n",
    "Solution: We need to convert the text to numbers, actually features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8079c73",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "\n",
    "#### Feature Engineering\n",
    "\n",
    "We need to convert each document into features. \n",
    "\n",
    "**Question:** What should our features be?\n",
    "\n",
    "*Hint*: What's the most basic approach we've taken so far in this class?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "    Bag of words\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232903b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip next bunch of empty cells, answer below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5645629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec588a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e1c4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff5278d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e0a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248496c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cb4325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f470874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98106f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit_transform(train_df['review_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ae1a0",
   "metadata": {},
   "source": [
    "**Question:** What do these numbers that were printed out mean?\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "Number of examples, size of vocabulary\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a37354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77995dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(train_df['review_text'])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d498c",
   "metadata": {},
   "source": [
    "Let's look at the contenxtual help to print out what X is.\n",
    "\n",
    "**Question:** What do we think *(0, 8284) <tab>  2* in *X* means?\n",
    "    \n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "    The value of the 8284 feature for the 0-th example. In our setting this means how many times that word appeared in the first document\n",
    "\n",
    "        \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91b2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d1a2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245fbe39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23c897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda3f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()[8284]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3301af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['review_text'].iloc[0].count('notoriety')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c90e22",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae09a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.fit(X, train_df['gold-label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd6c10",
   "metadata": {},
   "source": [
    "#### How well does the model perform on the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd0dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.score(X, train_df['gold-label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a87435",
   "metadata": {},
   "source": [
    "If the model just guessed True or False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c7f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['gold-label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce48a27",
   "metadata": {},
   "source": [
    "#### Evaluate the model on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.predict(dev_df['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014db0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = vectorizer.transform(dev_df['review_text'])\n",
    "X_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.predict(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b27777",
   "metadata": {},
   "source": [
    "**Let's store the predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0504afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = dev_df.assign(nb_predictions = nb_model.predict(X_dev))\n",
    "dev_df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d0c424",
   "metadata": {},
   "source": [
    "**Let's compute accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df['nb_predictions'] == dev_df['gold-label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a5a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(dev_df['nb_predictions'] == dev_df['gold-label']) / dev_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668250eb",
   "metadata": {},
   "source": [
    "#### Interpreting the model\n",
    "\n",
    "In computational text analysis, we don't necessarily care just about building a classifier that does well. We want to use the classifier to gain insight about our text.\n",
    "\n",
    "**Question:** From the Naive Bayes equation, what do you think can give us the most insight about our text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec36685",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.feature_log_prob_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.feature_log_prob_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb7c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.feature_log_prob_[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a83e770",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()[nb_model.feature_log_prob_[0].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a51cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.feature_log_prob_[0].max(), nb_model.feature_log_prob_[0][nb_model.feature_log_prob_[0].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://stackoverflow.com/questions/50526898/how-to-get-feature-importance-in-naive-bayes\n",
    "\n",
    "neg_class_prob_sorted = nb_model.feature_log_prob_[0, :].argsort()[::-1]\n",
    "pos_class_prob_sorted = nb_model.feature_log_prob_[1, :].argsort()[::-1]\n",
    "\n",
    "print(np.take(vectorizer.get_feature_names(), neg_class_prob_sorted[:10]))\n",
    "print(np.take(vectorizer.get_feature_names(), pos_class_prob_sorted[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cd6829",
   "metadata": {},
   "source": [
    "The above is telling us what is the probability of a word given a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a35b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_class_prob_sorted = nb_model.feature_log_prob_[0, :].argsort()[::-1]\n",
    "pos_class_prob_sorted = nb_model.feature_log_prob_[1, :].argsort()[::-1]\n",
    "\n",
    "top_100_negative = set(np.take(vectorizer.get_feature_names(), neg_class_prob_sorted[:200]))\n",
    "top_100_positive = set(np.take(vectorizer.get_feature_names(), pos_class_prob_sorted[:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d1d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_negative - top_100_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada8fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_positive - top_100_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a33998",
   "metadata": {},
   "source": [
    "#### Fine-tuning hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea8bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.alpha = 5\n",
    "nb_model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4917599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB(alpha=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a80942",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f172abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.fit(X, train_df['gold-label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36165dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.score(X, train_df['gold-label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e2a826",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f1b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.score(X_dev, dev_df['gold-label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f4495b",
   "metadata": {},
   "source": [
    "**How does this compare to the result on dev before?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe11792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fd56f0a",
   "metadata": {},
   "source": [
    "This was an example of hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43a0c4a",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d3fa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = sklearn.linear_model.LogisticRegression(max_iter = 1e4)\n",
    "lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7884f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea726ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.fit(df['review_text'], df['gold-label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c7ebdf",
   "metadata": {},
   "source": [
    "**Question:** What happened?\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "We need to convert the text to features\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d21707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9053405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(df['review_text'])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c99390c",
   "metadata": {},
   "source": [
    "**Question:** What is 2000 and what is 15452?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3eb750",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.fit(X, df['gold-label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f5af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prediction'] = lr_model.predict(X)\n",
    "df['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45feac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['prediction'] == df['gold-label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03f4f55",
   "metadata": {},
   "source": [
    "#### Finding coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51671319",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c1c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ed8f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3275a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.coef_.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74ed3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.coef_[0][lr_model.coef_.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f257a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()[lr_model.coef_.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.coef_.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173f3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.coef_[0][lr_model.coef_.argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb66eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()[lr_model.coef_.argmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5abad6",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed5539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b79f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737e6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(df.shape[0])\n",
    "train_df = df.head(1800)\n",
    "test_df = df.tail(200)\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29d12c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=4)\n",
    "vectorizer.fit(train_df['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38392d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(train_df)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd5e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = sklearn.linear_model.LogisticRegression(max_iter = 1e4)\n",
    "lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175d34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.fit(X_train, train_df['gold-label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9195d694",
   "metadata": {},
   "source": [
    "#### n-grams\n",
    "\n",
    "Look at ngram_range in https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a3e893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "381da89c",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "### More classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed5292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf = SVC(gamma=2, C=1)\n",
    "clf = DecisionTreeClassifier(max_depth=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
