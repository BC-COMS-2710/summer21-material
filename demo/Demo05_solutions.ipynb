{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29ef2f02",
   "metadata": {},
   "source": [
    "# Demo 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd81cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d52a821",
   "metadata": {},
   "source": [
    "## Types vs Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d42faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = \"We refuse to believe that there are insufficient funds in the great vaults \\\n",
    "of opportunity of this nation. And so we've come to cash this check, a check that \\\n",
    "will give us upon demand the riches of freedom and the security of justice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f6fd906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We refuse to believe that there are insufficient funds in the great vaults of opportunity of this nation. And so we've come to cash this check, a check that will give us upon demand the riches of freedom and the security of justice\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902bc905",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edf0076c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We refuse to believe that there are insufficient funds in the great vaults of opportunity of this nation . And so we 've come to cash this check , a check that will give us upon demand the riches of freedom and the security of justice\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.tokenize.word_tokenize(speech)\n",
    "\" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc1aa346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of tokens is 46, number of types is 37'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Number of tokens is {len(tokens)}, number of types is {len(set(tokens))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9faedc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We refuse to believe that there are insufficient funds in the great vaults of opportunity of this nation.',\n",
       " \"And so we've come to cash this check, a check that will give us upon demand the riches of freedom and the security of justice\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.tokenize.sent_tokenize(speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca272fe",
   "metadata": {},
   "source": [
    "### Duplicate types?\n",
    "\n",
    "**Question:** Can you find any duplicate types in our vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "797b7b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"security And we insufficient vaults give justice believe cash come to refuse and freedom We this us riches in upon great the that a so are funds . of check opportunity , will nation 've there demand\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set(tokens)\n",
    "\" \".join(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92411788",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Answer</summary>\n",
    "    <b>\"We\"</b> and <b>\"we\"</b>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e115a15",
   "metadata": {},
   "source": [
    "Do we want to treat these as different types?\n",
    "\n",
    "**Question:** What solution would you suggest? \n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<b>Lowercase</b>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution is below in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7f9f85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we',\n",
       " 'refuse',\n",
       " 'to',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'there',\n",
       " 'are',\n",
       " 'insufficient',\n",
       " 'funds',\n",
       " 'in',\n",
       " 'the',\n",
       " 'great',\n",
       " 'vaults',\n",
       " 'of',\n",
       " 'opportunity',\n",
       " 'of',\n",
       " 'this',\n",
       " 'nation',\n",
       " '.',\n",
       " 'and',\n",
       " 'so',\n",
       " 'we',\n",
       " \"'ve\",\n",
       " 'come',\n",
       " 'to',\n",
       " 'cash',\n",
       " 'this',\n",
       " 'check',\n",
       " ',',\n",
       " 'a',\n",
       " 'check',\n",
       " 'that',\n",
       " 'will',\n",
       " 'give',\n",
       " 'us',\n",
       " 'upon',\n",
       " 'demand',\n",
       " 'the',\n",
       " 'riches',\n",
       " 'of',\n",
       " 'freedom',\n",
       " 'and',\n",
       " 'the',\n",
       " 'security',\n",
       " 'of',\n",
       " 'justice']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.tokenize.word_tokenize(speech.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec86b088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be3852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6c2d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ae5da66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of lowered tokens is 46, number of types is 35'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_tokens = nltk.tokenize.word_tokenize(speech.lower())\n",
    "f\"Number of lowered tokens is {len(lower_tokens)}, number of types is {len(set(lower_tokens))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6570abb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'of': 4, 'the': 3, 'we': 2, 'to': 2, 'that': 2, 'this': 2, 'and': 2, 'check': 2, 'refuse': 1, 'believe': 1, ...})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqdist = nltk.FreqDist(lower_tokens)\n",
    "freqdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4ba9cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 4), ('the', 3)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqdist.most_common(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f359452f",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "\n",
    "## Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e84f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ee830ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transform'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"transformed\", \"v\") # The NLTK WordNet Lemmatizer needs to know the part of speech tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9ac9e1",
   "metadata": {},
   "source": [
    "#### Go, Goes, Went, Gone, Going\n",
    "\n",
    "**Question:** What do you think the lemma for these terms should be? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6afa919c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('go', 'go')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"go\"), lemmatizer.lemmatize(\"goes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9578954c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('go', 'go', 'go')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"went\", \"v\"), lemmatizer.lemmatize(\"gone\", \"v\"), lemmatizer.lemmatize(\"going\", \"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a31830eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'leaf'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"leaves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de78cea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'leave'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"leaves\", \"v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c26eb96",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a00f440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'babi'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer = nltk.stem.SnowballStemmer(\"english\") # Same of PorterStemmer\n",
    "snowball_stemmer.stem(\"babies\")\n",
    "\n",
    "# \"y\" -> \"i\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be75bbd9",
   "metadata": {},
   "source": [
    "### constituional, constitutionality, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d8a4bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('constitut', 'constitut', 'constitut', 'constitut', 'constitut')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer.stem(\"constitution\"), snowball_stemmer.stem(\"constitutions\"), snowball_stemmer.stem(\"constitutional\"), snowball_stemmer.stem(\"constitutionality\"), snowball_stemmer.stem(\"constitutionalism\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d78739",
   "metadata": {},
   "source": [
    "### Relat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a324c24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('relat', 'relat')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer.stem(\"relativity\"), snowball_stemmer.stem(\"relative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "819678cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('constitut', 'constitution')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer.stem(\"constitution\"), lemmatizer.lemmatize(\"constitution\", \"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4cad68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('babi', 'baby')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer.stem(\"babies\"), lemmatizer.lemmatize(\"babies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac5a889",
   "metadata": {},
   "source": [
    "(back to slides)\n",
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bd49392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i me my myself we our ours ourselves you you're you've you'll you'd your yours yourself yourselves he him his himself she she's her hers herself it it's its itself they them their theirs themselves what which who whom this that that'll these those am is are was were be been being have has had having do does did doing a an the and but if or because as until while of at by for with about against between into through during before after above below to from up down in out on off over under again further then once here there when where why how all any both each few more most other some such no nor not only own same so than too very s t can will just don don't should should've now d ll m o re ve y ain aren aren't couldn couldn't didn didn't doesn doesn't hadn hadn't hasn hasn't haven haven't isn isn't ma mightn mightn't mustn mustn't needn needn't shan shan't shouldn shouldn't wasn wasn't weren weren't won won't wouldn wouldn't\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b288fb",
   "metadata": {},
   "source": [
    "**Question:** What do we notice about these words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "949cee29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'la',\n",
       " 'que',\n",
       " 'el',\n",
       " 'en',\n",
       " 'y',\n",
       " 'a',\n",
       " 'los',\n",
       " 'del',\n",
       " 'se',\n",
       " 'las',\n",
       " 'por',\n",
       " 'un',\n",
       " 'para',\n",
       " 'con',\n",
       " 'no',\n",
       " 'una',\n",
       " 'su',\n",
       " 'al',\n",
       " 'lo',\n",
       " 'como',\n",
       " 'más',\n",
       " 'pero',\n",
       " 'sus',\n",
       " 'le',\n",
       " 'ya',\n",
       " 'o',\n",
       " 'este',\n",
       " 'sí',\n",
       " 'porque',\n",
       " 'esta',\n",
       " 'entre',\n",
       " 'cuando',\n",
       " 'muy',\n",
       " 'sin',\n",
       " 'sobre',\n",
       " 'también',\n",
       " 'me',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'donde',\n",
       " 'quien',\n",
       " 'desde',\n",
       " 'todo',\n",
       " 'nos',\n",
       " 'durante',\n",
       " 'todos',\n",
       " 'uno',\n",
       " 'les',\n",
       " 'ni',\n",
       " 'contra',\n",
       " 'otros',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'ante',\n",
       " 'ellos',\n",
       " 'e',\n",
       " 'esto',\n",
       " 'mí',\n",
       " 'antes',\n",
       " 'algunos',\n",
       " 'qué',\n",
       " 'unos',\n",
       " 'yo',\n",
       " 'otro',\n",
       " 'otras',\n",
       " 'otra',\n",
       " 'él',\n",
       " 'tanto',\n",
       " 'esa',\n",
       " 'estos',\n",
       " 'mucho',\n",
       " 'quienes',\n",
       " 'nada',\n",
       " 'muchos',\n",
       " 'cual',\n",
       " 'poco',\n",
       " 'ella',\n",
       " 'estar',\n",
       " 'estas',\n",
       " 'algunas',\n",
       " 'algo',\n",
       " 'nosotros',\n",
       " 'mi',\n",
       " 'mis',\n",
       " 'tú',\n",
       " 'te',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'ellas',\n",
       " 'nosotras',\n",
       " 'vosotros',\n",
       " 'vosotras',\n",
       " 'os',\n",
       " 'mío',\n",
       " 'mía',\n",
       " 'míos',\n",
       " 'mías',\n",
       " 'tuyo',\n",
       " 'tuya',\n",
       " 'tuyos',\n",
       " 'tuyas',\n",
       " 'suyo',\n",
       " 'suya',\n",
       " 'suyos',\n",
       " 'suyas',\n",
       " 'nuestro',\n",
       " 'nuestra',\n",
       " 'nuestros',\n",
       " 'nuestras',\n",
       " 'vuestro',\n",
       " 'vuestra',\n",
       " 'vuestros',\n",
       " 'vuestras',\n",
       " 'esos',\n",
       " 'esas',\n",
       " 'estoy',\n",
       " 'estás',\n",
       " 'está',\n",
       " 'estamos',\n",
       " 'estáis',\n",
       " 'están',\n",
       " 'esté',\n",
       " 'estés',\n",
       " 'estemos',\n",
       " 'estéis',\n",
       " 'estén',\n",
       " 'estaré',\n",
       " 'estarás',\n",
       " 'estará',\n",
       " 'estaremos',\n",
       " 'estaréis',\n",
       " 'estarán',\n",
       " 'estaría',\n",
       " 'estarías',\n",
       " 'estaríamos',\n",
       " 'estaríais',\n",
       " 'estarían',\n",
       " 'estaba',\n",
       " 'estabas',\n",
       " 'estábamos',\n",
       " 'estabais',\n",
       " 'estaban',\n",
       " 'estuve',\n",
       " 'estuviste',\n",
       " 'estuvo',\n",
       " 'estuvimos',\n",
       " 'estuvisteis',\n",
       " 'estuvieron',\n",
       " 'estuviera',\n",
       " 'estuvieras',\n",
       " 'estuviéramos',\n",
       " 'estuvierais',\n",
       " 'estuvieran',\n",
       " 'estuviese',\n",
       " 'estuvieses',\n",
       " 'estuviésemos',\n",
       " 'estuvieseis',\n",
       " 'estuviesen',\n",
       " 'estando',\n",
       " 'estado',\n",
       " 'estada',\n",
       " 'estados',\n",
       " 'estadas',\n",
       " 'estad',\n",
       " 'he',\n",
       " 'has',\n",
       " 'ha',\n",
       " 'hemos',\n",
       " 'habéis',\n",
       " 'han',\n",
       " 'haya',\n",
       " 'hayas',\n",
       " 'hayamos',\n",
       " 'hayáis',\n",
       " 'hayan',\n",
       " 'habré',\n",
       " 'habrás',\n",
       " 'habrá',\n",
       " 'habremos',\n",
       " 'habréis',\n",
       " 'habrán',\n",
       " 'habría',\n",
       " 'habrías',\n",
       " 'habríamos',\n",
       " 'habríais',\n",
       " 'habrían',\n",
       " 'había',\n",
       " 'habías',\n",
       " 'habíamos',\n",
       " 'habíais',\n",
       " 'habían',\n",
       " 'hube',\n",
       " 'hubiste',\n",
       " 'hubo',\n",
       " 'hubimos',\n",
       " 'hubisteis',\n",
       " 'hubieron',\n",
       " 'hubiera',\n",
       " 'hubieras',\n",
       " 'hubiéramos',\n",
       " 'hubierais',\n",
       " 'hubieran',\n",
       " 'hubiese',\n",
       " 'hubieses',\n",
       " 'hubiésemos',\n",
       " 'hubieseis',\n",
       " 'hubiesen',\n",
       " 'habiendo',\n",
       " 'habido',\n",
       " 'habida',\n",
       " 'habidos',\n",
       " 'habidas',\n",
       " 'soy',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'somos',\n",
       " 'sois',\n",
       " 'son',\n",
       " 'sea',\n",
       " 'seas',\n",
       " 'seamos',\n",
       " 'seáis',\n",
       " 'sean',\n",
       " 'seré',\n",
       " 'serás',\n",
       " 'será',\n",
       " 'seremos',\n",
       " 'seréis',\n",
       " 'serán',\n",
       " 'sería',\n",
       " 'serías',\n",
       " 'seríamos',\n",
       " 'seríais',\n",
       " 'serían',\n",
       " 'era',\n",
       " 'eras',\n",
       " 'éramos',\n",
       " 'erais',\n",
       " 'eran',\n",
       " 'fui',\n",
       " 'fuiste',\n",
       " 'fue',\n",
       " 'fuimos',\n",
       " 'fuisteis',\n",
       " 'fueron',\n",
       " 'fuera',\n",
       " 'fueras',\n",
       " 'fuéramos',\n",
       " 'fuerais',\n",
       " 'fueran',\n",
       " 'fuese',\n",
       " 'fueses',\n",
       " 'fuésemos',\n",
       " 'fueseis',\n",
       " 'fuesen',\n",
       " 'sintiendo',\n",
       " 'sentido',\n",
       " 'sentida',\n",
       " 'sentidos',\n",
       " 'sentidas',\n",
       " 'siente',\n",
       " 'sentid',\n",
       " 'tengo',\n",
       " 'tienes',\n",
       " 'tiene',\n",
       " 'tenemos',\n",
       " 'tenéis',\n",
       " 'tienen',\n",
       " 'tenga',\n",
       " 'tengas',\n",
       " 'tengamos',\n",
       " 'tengáis',\n",
       " 'tengan',\n",
       " 'tendré',\n",
       " 'tendrás',\n",
       " 'tendrá',\n",
       " 'tendremos',\n",
       " 'tendréis',\n",
       " 'tendrán',\n",
       " 'tendría',\n",
       " 'tendrías',\n",
       " 'tendríamos',\n",
       " 'tendríais',\n",
       " 'tendrían',\n",
       " 'tenía',\n",
       " 'tenías',\n",
       " 'teníamos',\n",
       " 'teníais',\n",
       " 'tenían',\n",
       " 'tuve',\n",
       " 'tuviste',\n",
       " 'tuvo',\n",
       " 'tuvimos',\n",
       " 'tuvisteis',\n",
       " 'tuvieron',\n",
       " 'tuviera',\n",
       " 'tuvieras',\n",
       " 'tuviéramos',\n",
       " 'tuvierais',\n",
       " 'tuvieran',\n",
       " 'tuviese',\n",
       " 'tuvieses',\n",
       " 'tuviésemos',\n",
       " 'tuvieseis',\n",
       " 'tuviesen',\n",
       " 'teniendo',\n",
       " 'tenido',\n",
       " 'tenida',\n",
       " 'tenidos',\n",
       " 'tenidas',\n",
       " 'tened']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64d260e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We refuse to believe that there are insufficient funds in the great vaults of opportunity of this nation . And so we 've come to cash this check , a check that will give us upon demand the riches of freedom and the security of justice\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"refuse believe insufficient funds great vaults opportunity nation . 've come cash check , check give us upon demand riches freedom security justice\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_en_stop_words = nltk.corpus.stopwords.words('english')\n",
    "print(\" \".join(tokens))\n",
    "\" \".join([word for word in tokens if word.lower() not in nltk_en_stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63728c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all([stopword.islower() for stopword in nltk_en_stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72331396",
   "metadata": {},
   "source": [
    "(back to demo)\n",
    "## Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "047cd420",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tokens: expected a list of strings, got a string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-866da697e007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \"\"\"\n\u001b[1;32m    164\u001b[0m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_pos_tag\u001b[0;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# Throws Error if tokens is of string type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokens: expected a list of strings, got a string'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tokens: expected a list of strings, got a string"
     ]
    }
   ],
   "source": [
    "nltk.pos_tag(speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5531bce0",
   "metadata": {},
   "source": [
    "**Question:** What does this error mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0eec8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_tokenized = [word for word in tokens if word.lower() not in nltk_en_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd98a8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('refuse', 'NN'),\n",
       " ('believe', 'VBP'),\n",
       " ('insufficient', 'NN'),\n",
       " ('funds', 'NNS'),\n",
       " ('great', 'JJ'),\n",
       " ('vaults', 'NNS'),\n",
       " ('opportunity', 'NN'),\n",
       " ('nation', 'NN'),\n",
       " ('.', '.'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('come', 'VBN'),\n",
       " ('cash', 'NN'),\n",
       " ('check', 'NN'),\n",
       " (',', ','),\n",
       " ('check', 'VB'),\n",
       " ('give', 'VBP'),\n",
       " ('us', 'PRP'),\n",
       " ('upon', 'IN'),\n",
       " ('demand', 'NN'),\n",
       " ('riches', 'NNS'),\n",
       " ('freedom', 'VBP'),\n",
       " ('security', 'NN'),\n",
       " ('justice', 'NN')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(speech_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e9a996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf356542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79c0787d",
   "metadata": {},
   "source": [
    "Let's look at another tagset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "133abb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('refuse', 'NOUN'),\n",
       " ('believe', 'VERB'),\n",
       " ('insufficient', 'NOUN'),\n",
       " ('funds', 'NOUN'),\n",
       " ('great', 'ADJ'),\n",
       " ('vaults', 'NOUN'),\n",
       " ('opportunity', 'NOUN'),\n",
       " ('nation', 'NOUN'),\n",
       " ('.', '.'),\n",
       " (\"'ve\", 'VERB'),\n",
       " ('come', 'VERB'),\n",
       " ('cash', 'NOUN'),\n",
       " ('check', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('check', 'VERB'),\n",
       " ('give', 'VERB'),\n",
       " ('us', 'PRON'),\n",
       " ('upon', 'ADP'),\n",
       " ('demand', 'NOUN'),\n",
       " ('riches', 'NOUN'),\n",
       " ('freedom', 'VERB'),\n",
       " ('security', 'NOUN'),\n",
       " ('justice', 'NOUN')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(speech_tokenized, tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c37a87",
   "metadata": {},
   "source": [
    "Tutorial 2.1 will further explore differences between these sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3507d21f",
   "metadata": {},
   "source": [
    "### Tricky examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fd0ab",
   "metadata": {},
   "source": [
    "***time flies like an arrow***\n",
    "\n",
    "**Question:** What should the POS tags here be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd1619",
   "metadata": {},
   "source": [
    "- time: \n",
    "- flies:\n",
    "- like: \n",
    "- an:\n",
    "- arrow:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12881ec5",
   "metadata": {},
   "source": [
    "Let's see what nltk tells us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57d9f1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time', 'NOUN'),\n",
       " ('flies', 'NOUN'),\n",
       " ('like', 'ADP'),\n",
       " ('an', 'DET'),\n",
       " ('arrow', 'NOUN')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(\"time flies like an arrow\"), tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bad7fc0",
   "metadata": {},
   "source": [
    "**Question:** Do we agree?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e323b",
   "metadata": {},
   "source": [
    "Tutorial 2.1 will focus on the difference between these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c37374",
   "metadata": {},
   "source": [
    "(back to slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae51329f",
   "metadata": {},
   "source": [
    "## Dependency Parsing\n",
    "\n",
    "### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bff7c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b199cf8",
   "metadata": {},
   "source": [
    "You might need to run \n",
    "\n",
    "> !python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d54db051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(We refuse to believe that there are insufficient funds in the great vaults of opportunity of this nation. And so we've come to cash this check, a check that will give us upon demand the riches of freedom and the security of justice,\n",
       " spacy.tokens.doc.Doc)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(speech)\n",
    "doc, type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf10af56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b4bdeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "We refuse to believe that there are insufficient funds in the great vaults of opportunity of this nation."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.sents)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a01b4f4",
   "metadata": {},
   "source": [
    "Tutorial 2.1 will go into details about the spacy `Doc` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05dab960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c6cb11bb88964787b5b00e3e51cb2d10-0\" class=\"displacy\" width=\"3200\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">We</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">refuse</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">believe</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">that</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">there</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">are</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">insufficient</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">funds</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">great</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">vaults</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">opportunity</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">this</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">nation.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-1\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-2\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,266.5 L578.0,254.5 562.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">expl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-5\" stroke-width=\"2px\" d=\"M595,264.5 C595,2.0 1100.0,2.0 1100.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,266.5 L1108.0,254.5 1092.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-7\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,89.5 1445.0,89.5 1445.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1445.0,266.5 L1453.0,254.5 1437.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-8\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1615.0,266.5 L1623.0,254.5 1607.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-9\" stroke-width=\"2px\" d=\"M1820,264.5 C1820,89.5 2145.0,89.5 2145.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,266.5 L1812,254.5 1828,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-10\" stroke-width=\"2px\" d=\"M1995,264.5 C1995,177.0 2140.0,177.0 2140.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1995,266.5 L1987,254.5 2003,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-11\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,2.0 2150.0,2.0 2150.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2150.0,266.5 L2158.0,254.5 2142.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-12\" stroke-width=\"2px\" d=\"M2170,264.5 C2170,177.0 2315.0,177.0 2315.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2315.0,266.5 L2323.0,254.5 2307.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-13\" stroke-width=\"2px\" d=\"M2345,264.5 C2345,177.0 2490.0,177.0 2490.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2490.0,266.5 L2498.0,254.5 2482.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-14\" stroke-width=\"2px\" d=\"M2520,264.5 C2520,177.0 2665.0,177.0 2665.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2665.0,266.5 L2673.0,254.5 2657.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-15\" stroke-width=\"2px\" d=\"M2870,264.5 C2870,177.0 3015.0,177.0 3015.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2870,266.5 L2862,254.5 2878,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-16\" stroke-width=\"2px\" d=\"M2695,264.5 C2695,89.5 3020.0,89.5 3020.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c6cb11bb88964787b5b00e3e51cb2d10-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3020.0,266.5 L3028.0,254.5 3012.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(list(doc.sents)[0], style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d659ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We NSUBJ refuse\n",
      "refuse ROOT refuse\n",
      "to AUX believe\n",
      "believe XCOMP refuse\n",
      "that MARK are\n",
      "there EXPL are\n",
      "are CCOMP believe\n",
      "insufficient AMOD funds\n",
      "funds ATTR are\n",
      "in PREP funds\n",
      "the DET vaults\n",
      "great AMOD vaults\n",
      "vaults POBJ in\n",
      "of PREP vaults\n",
      "opportunity POBJ of\n",
      "of PREP opportunity\n",
      "this DET nation\n",
      "nation POBJ of\n",
      ". PUNCT refuse\n"
     ]
    }
   ],
   "source": [
    "for tok in list(doc.sents)[0]:\n",
    "    print(tok.text, tok.dep_.upper(), tok.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a9bdb2",
   "metadata": {},
   "source": [
    "Spacy dependency parse labels are explained [here](https://github.com/clir/clearnlp-guidelines/blob/master/md/specifications/dependency_labels.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c45b8a4",
   "metadata": {},
   "source": [
    "(back to slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c1160b",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b55ae775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monday, October 30, Hillary Clinton will present her book in Chicago at the University of Chicago."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_doc = nlp(\"Monday, October 30, Hillary Clinton will present her book in Chicago at the University of Chicago.\")\n",
    "example_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380b8367",
   "metadata": {},
   "source": [
    "**Question:** How do we get the entities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c447adef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Monday, October 30, Hillary Clinton, Chicago, the University of Chicago)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_ents = example_doc.ents\n",
    "example_ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7db596",
   "metadata": {},
   "source": [
    "**Question:** Let's get the text of the entities and the label of the entity\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<b>[(ent.text, ent.label_) for ent in example_doc.ents]</b>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa9d4fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "428cc363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(example_ents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cdde7f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE Monday, October 30\n",
      "PERSON Hillary Clinton\n",
      "GPE Chicago\n",
      "ORG the University of Chicago\n"
     ]
    }
   ],
   "source": [
    "for ent in example_ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb50353a",
   "metadata": {},
   "source": [
    "### Entities in Dracula\n",
    "\n",
    "I downloaded Dracula from Project Gutenberg: https://www.gutenberg.org/ebooks/345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644ae62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/Dracula.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e555d415",
   "metadata": {},
   "source": [
    "The next line will take about 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13404a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "doc = nlp(open(\"data/Dracula.txt\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c4393d",
   "metadata": {},
   "source": [
    "I ran a [tool](https://github.com/JonathanReeve/chapterize) developed by Jonathan Reeve that splits novels from Project Gutenberg into files for each chapter.\n",
    "\n",
    "[Jonathan](https://jonreeve.com/) is a Computational literary analyst here at Columbia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6986bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/Dracula-chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e7a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "DRACULA_PATH = \"data/Dracula-chapters/\"\n",
    "\n",
    "chapter2doc = {}\n",
    "for file in tqdm(os.listdir(DRACULA_PATH)):\n",
    "    chapter_id = file.split(\".\")[0]\n",
    "    chapter2doc[chapter_id] = nlp(open(DRACULA_PATH + file).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29dab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter2doc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09008d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(chapter2doc['01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a530b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = [], []\n",
    "for ent in chapter2doc['01'].ents:\n",
    "    texts.append(ent.text)\n",
    "    labels.append(ent.label_)\n",
    "    \n",
    "ents_df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "ents_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7157d4e8",
   "metadata": {},
   "source": [
    "**Question:** What labels do we see the most in the first Chapter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ac6dc",
   "metadata": {},
   "source": [
    "**Question:** What person is mentioned the most in the first chapter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d747e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_df[ents_df['label'] == 'PERSON'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccaa8df",
   "metadata": {},
   "source": [
    "**Question:** Who is mentioned the most throughout the entire book?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c09fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters, texts, labels = [], [], []\n",
    "\n",
    "for chapter, doc in chapter2doc.items():\n",
    "    for ent in doc.ents:\n",
    "        texts.append(ent.text)\n",
    "        labels.append(ent.label_)\n",
    "        chapters.append(chapter)\n",
    "    \n",
    "ents_df = pd.DataFrame({'text': texts, 'label': labels, 'chapter': chapters})\n",
    "ents_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b462fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ents_df.sort_values(by='chapter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37af256",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucy_mentions_df = ents_df[ents_df['text'] == 'Lucy']\n",
    "lucy_mentions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae6024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucy_mentions_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5590e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucy_mentions_df = lucy_mentions_df.drop(columns=['label']) \n",
    "lucy_mentions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc4111",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucy_mentions_df['chapter'].value_counts().plot(kind='line')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d42ba1",
   "metadata": {},
   "source": [
    "**Question:** What don't we like about this graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8b688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = lucy_mentions_df['chapter'].value_counts().sort_index().plot(kind='line')\n",
    "ax.set_title(\"Number of times Lucy is mentioned per chapter\")\n",
    "ax.set_xlabel(\"Chapter Number\")\n",
    "ax.set_xlabel(\"Number of Lucy mentions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff068d9d",
   "metadata": {},
   "source": [
    "**Question:** Does this figure make sense based on the novel?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088aaa74",
   "metadata": {},
   "source": [
    "\n",
    "#### Plotting most common characters in Dracula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1de59c",
   "metadata": {},
   "source": [
    "**Question:** Who are the 50 most commonly mentioned characters in Dracula?\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<b>ents_df[ents_df['label'] == 'PERSON']['text'].value_counts().head(50)</b>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1edbfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here to determine that based on entities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb96651",
   "metadata": {},
   "source": [
    "Let's query the dataframe to find all rows that have been tagged as a PERSON and \n",
    "save the result from the query in `person_df`\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<b>ents_df[ents_df['label'] == 'PERSON']</b>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b0cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df = ...\n",
    "person_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4cccab",
   "metadata": {},
   "source": [
    "Now lets determine how many times each person was mentioned in each chapter.\n",
    "\n",
    "We want to make a new dataframe where the indices are the chapters and the columns represent the counts of how many times a specific character was mentioned in the chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6bc0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_table = pd.pivot_table(person_df, index=['chapter'],\n",
    "                    columns=['text'], aggfunc=len, fill_value=0)\n",
    "pv_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276dc3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_table.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf9229",
   "metadata": {},
   "source": [
    "Let's plot just the 10 most frequently mentioned characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ac370",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df['text'].value_counts().head(10) # first find the 10 most frequently mentioned characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f050ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_freq_people = person_df['text'].value_counts().index[:10] # Lets get their names\n",
    "ten_freq_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ee152",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_table['label'][ten_freq_people].plot(kind='line') # Query the pivot table and then plot the result "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5085a8",
   "metadata": {},
   "source": [
    "let's make subplots as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c0d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
