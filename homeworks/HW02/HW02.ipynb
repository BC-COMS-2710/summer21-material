{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d5e776",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"HW02.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7f59c8",
   "metadata": {},
   "source": [
    "# Homework 02 - Exploring Obituaries\n",
    "\n",
    "In this homework we are going to use Term Frequency Inverse Document Frequency to explore Obituaries from the NYTimes. This assignment is based on [Matthew J. Lavin's](https://matthew-lavin.com/) (Professor at Denison University) [lesson](https://programminghistorian.org/en/lessons/analyzing-documents-with-tfidf) on TF-IDF.\n",
    "\n",
    "\n",
    "Let's begin by running the next cell that will import some python packages relevant for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8d4182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a95ef",
   "metadata": {},
   "source": [
    "## 1. Explore and Load Data (13 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9733ee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1.1\n",
    "manual: False\n",
    "points: \n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "-->\n",
    "\n",
    "We have stored 364 obituatries from the New York Times. The obituaries are in text files stored in `/data/obits_txt/'\n",
    "\n",
    "**Question 1.1: (3 points)** Load the obituaries into a single dataframe named **obits_df**. The dataframe should have the following columns named: **File_Name** and **Obit**, the former indicates the name of the file (do not include the path), and the latter should be the text of the obituary stored as a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a76af564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OBITS_PATH = \"data/obits_txt/\"\n",
    "\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "obits_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908e273a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c72e96",
   "metadata": {},
   "source": [
    "### Applying Spacy to the obituaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d1795d",
   "metadata": {},
   "source": [
    "The 'Obit' column contains the original uncleaned text. For the first part of this assignment we are going to apply the Spacy text processing pipeline that we covered in Tutorial 2.1. Run the next line to load the Spacy `en_core_web_sm` model into memory and store it in the variable named `nlp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ddb1acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "type(nlp), nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34179570",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1.2\n",
    "manual: False\n",
    "points: \n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "-->\n",
    "\n",
    "In Tutorial 2.1, we saw how to apply this trained Spacy model to text. \n",
    "\n",
    "**Question 1.2 (3 points)**: In the next line, apply the spacy model to every obituatry and store each spacy doc in a new column in `obits_df`. The new column's name should be `spacy_doc`.  \n",
    "\n",
    "*If you are applying the model correctly, the next cell will take about 2 minutes to run*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7df0dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "obits_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5429bc25",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5280ed",
   "metadata": {},
   "source": [
    "**Saving the `obits_df` dataframe**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0faf73",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Applying the Spacy nlp pipeline to the 364 obituaries takes a while to run. Often times we will work a bit, take a break, and then come back to continue working. We do not want to have to reprocess our data every time we come back to work on project. If we are analyzing even more amount of texts, applying the spacy pipeline will take even longer, and this will become pretty annoying everytime we come back to work on our project.\n",
    "\n",
    "It is a common practice to save our data after processing our data, e.g. deploying a sentiment model, tokenizing text, etc.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1.3\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 1.3 (1 point):** In the next cell, save the dataframe to a csv file named `tmp_obits.csv.` Make sure to use `index=None` when saving the csv file. This will prevent the index column from being saved to the csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d356088",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65daaaab",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1.4\n",
    "manual: False\n",
    "points: \n",
    "    - 1\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 1.4 (1 point):** In the next cell, load the file you just saved to a new dataframe called `tmp_obits_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f4486da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_obits_df = ...\n",
    "tmp_obits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ad6fe8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f63a2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1.5\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "\n",
    "**Question: 1.5 (1 point):** In the next cell, write some code to detect what is different between `obits_df` and `tmp_obits_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c3d01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527fe7e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1.6\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 1.6 (1 point):** In the next cell, briefly describe what is different between the two dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea609f4",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0148897a",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "When we want to save python objects to a file, a better approach is to save the data as a pickle file.  \n",
    "\n",
    "> The pickle module implements binary protocols for serializing and de-serializing a Python object structure. “Pickling” is the process whereby a Python object hierarchy is converted into a byte stream, and “unpickling” is the inverse operation, whereby a byte stream (from a binary file or bytes-like object) is converted back into an object hierarchy. Pickling (and unpickling) is alternatively known as “serialization”, “marshalling,” 1 or “flattening”; however, to avoid confusion, the terms used here are “pickling” and “unpickling”. - https://docs.python.org/3/library/pickle.html\n",
    "\n",
    "In simple terms, pickle is a way to save python objects to a file without losing any information.\n",
    "We can ***dump*** python objects to a pickle file and we can ***load*** python objects directly from a pickle file. This [python webpage](https://wiki.python.org/moin/UsingPickle) is a great reference on how to dump and load pickle files - this is the go to website I look at when needing to dump and load pickle files.\n",
    "\n",
    "\n",
    "Pandas has a built in Dataframe function, [*.to_pickle()*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html) that will pickle the dataframe to a file. The next line will store the dataframe, including the processed spacy documents to a pickle file called `obits_df.pkl`. Run the next line to save the DataFrame as a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cd7796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obits_df.to_pickle('data/obits_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afdb066",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1.7\n",
    "manual: True\n",
    "points: 0.5\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 1.7 (0.5 point):** In the next line, write a bash command to see the size of the pickle file you just dumped. \n",
    "\n",
    "*Note:* Make sure to change the cell from a Markdown cell to a code cell.\n",
    "\n",
    "*Hint:* If you are stuck, look at the [bash commands page on the course website](http://coms2710.barnard.edu/bash-commands.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2aa4a5",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef3f569",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "When dumping DataFrames to pickle files, we can dump the data into a compressed file. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1.8\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 1.8 (1 point):** In the next cell, dump the dataframe to a compressed pickle file. You can choose any of the compression methods, e.g. zip, gzip, etc.\n",
    "\n",
    "*Hint:* You might want to look at the [*to_pickle()* documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html).\n",
    "\n",
    "*Note:* Make sure to use the naming convention (last part of the file name) that corresponds to the type of compression you are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f00017be",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e588b814",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1.9\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 1.9 (0.5 point):** In the next cell, write a bash command to see the size of the compressed pickle file.\n",
    "\n",
    "*Note:* Make sure to change the cell from a Markdown cell to a code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e19d1d",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30491b03",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1.10\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 1.10 (1 point):** What is the difference in size between the different compressed versions of the pickle files and what is your takeaway from these questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98f43d0",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f74050f",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    " When coming back to this assignment, you can just run the next cell which will load the pickled dataframe that you have generated so far in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c8a477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obits_df = pd.read_pickle('data/obits_df.pkl')\n",
    "obits_df.keys(), obits_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216e02aa",
   "metadata": {},
   "source": [
    "## 2. Who is each obituary about (14.5 points)?\n",
    "\n",
    "Unfortunately we did not apply any labels to the obituaries. Ideally it would be great if the name of each file indicated who the obit was about or if we provided metadata that mapped the file names to name of each obituatry's subject. When working with real word data, this is often the case.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ffb84c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.1\n",
    "manual: True\n",
    "points: 4\n",
    "-->\n",
    "\n",
    "**Question 2.1 (4 points):** In the next cell, write out an algorithm or an approach you could take to determine who the obituary is about. Justify why you think this approach will generally work. It is okay if the approach is not 100% accurate but it should work most of the time.\n",
    "\n",
    "It might be helpful to spend some time sampling about 10 of the obituaries.\n",
    "    \n",
    "*Hint:* Leveraging the named entities from the spacy document object might be helpful. Look at the last section of Demo 5 for how to extract named entities and their labels from spacy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e29030b",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8fae8f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.2\n",
    "manual: False\n",
    "points: \n",
    "    - 0.5\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.2 (6.5 points):** In the next cell, apply the approach you just described to determine who is the subject of each obituary. In the `obits_df` dataframe, create a new column called `subject`. Each row's `subject` cell should indicate the subject of the obituary and the values can be a string of the subject's/person's name. \n",
    "\n",
    "*Note:* There is no need to reformat the name. For example, it is ok if the subject for JFK's obituary is *Kennedy*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd8ea782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb10f23",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633b95bd",
   "metadata": {},
   "source": [
    "### Pareto principle (80-20 rule)\n",
    "\n",
    "It is very likely there are edge cases where your method fails or produces results that are not accurate. This is okay and will often happen in research. An important question to constantly ask yourself is how much fine-tuning your methods is necessary and how much are small mistakes tolerable. \n",
    "\n",
    "The goal in this assignment is to understand obituaries using tf-idf. We could spend lots of time developing a fool-proof heurstic that correctly and perfectly extracts all the subjects from all of our obituatires. However, that probably would be a waste of time.\n",
    "\n",
    "**Pareto Principle**\n",
    "\n",
    "> The Pareto principle states that for many outcomes, roughly 80% of consequences come from 20% of the causes (the “vital few”).[1] Other names for this principle are the 80/20 rule, the law of the vital few, or the principle of factor sparsity. - https://en.wikipedia.org/wiki/Pareto_principle\n",
    "\n",
    "For our purposes, we apply the Pareto Principle to mean that we want a 20% effort solution that covers 80% of our data. Spending time for the remaining 20% edge cases often might not be worth it. In most Computer Science classes your code and solutions are evaluated by how well they cover edge cases. However, for our purposes here, the edge cases don't necessarily matter and arent always worthwhile. It is important to remember the goal and keep our eyes on the prize.\n",
    "\n",
    "With that said, it is important to sample our data to see whether our 20% effort approach covers 80% of the examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d60abc",
   "metadata": {},
   "source": [
    "The next cell will randomly sample 20 extracted subjects and their corresponding file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8f5f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "for row_id, row in obits_df.sample(20).iterrows():\n",
    "    print(row.subject, row.File_Name)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ecd2f0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.3\n",
    "manual: True\n",
    "points: 4\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.3 (4 poitns):**  After looking at those samples, briefly discuss how accurate your approach is and cases where it might have failed. Do you see any instances or patterns where your approach failed?\n",
    "\n",
    "If your approach resulted in atleast 16 matches of the randomly sampled 20 examples, thats a signal that your approach is good enough. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6587553e",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0993af9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 3. Cleaning text (3 points)\n",
    "\n",
    "Before we compute TF-IDF values, lets create cleaned versions of our text. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.1\n",
    "manual: False\n",
    "points: \n",
    "    - 1\n",
    "    - 1\n",
    "    - 1 \n",
    "-->\n",
    "\n",
    "\n",
    "**Question 3.1** In the next cell, create two cleaned versions of each obituary, and store the two cleaned versions in the following columns in `obits_df`:\n",
    "\n",
    "- `clean_text_one` will have no stop words, no punctuation, lowercase, numbers removed,\n",
    "- `clean_text_two` will have no stop words, no punctuation, lowercase, numbers removed, lemmas\n",
    "\n",
    "*Note:* The values in both columns should be strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "571609ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "obits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e843cd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d13890f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 4. TF-IDF (5 points)\n",
    "\n",
    "In Demo07, we learned how to use the `TfidfVectorizer` class from SKLearn. Here, we will use the default settings for the class.\n",
    "\n",
    "We will use the function called `make_tfidf_matrix` to create TF-IDF matrices for our obituaries.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4.1\n",
    "manual: False\n",
    "points: \n",
    "    - 0\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 4.1: (0 points)** Complete the function based on the doc string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81390696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tfidf_matrix(df, text_column):\n",
    "    \"\"\"\n",
    "    Given a dataframe and a name of the column, return a TF-IDF matrix as a dataframe.\n",
    "    Make sure the indices of the dataframe are the name of the subject of the obituary and\n",
    "    the name of the columns indicates the specfic words.\n",
    "    \"\"\"\n",
    "    tfidf_vectorizer = TfidfVectorizer() \n",
    "\n",
    "    tf_idf_sparse_matrix = ...\n",
    "    tfidf_df = pd.DataFrame(tf_idf_sparse_matrix.toarray())\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e38cf8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4.2\n",
    "manual: False\n",
    "points: \n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 4.2 (4 points):** Now use the function to create two TF-IDF matrices, one named `tfidf_cleaned_one`, `tfidf_cleaned_two`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8183988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_cleaned_one = ...\n",
    "tfidf_cleaned_two = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5cd881",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958ace14",
   "metadata": {},
   "source": [
    "## 5. Top-Terms (16 points)\n",
    "\n",
    "Now that we have computed TF-IDF terms, we can begin to analyze the obituaries and answer the following questions.\n",
    "\n",
    "For Section 5, just use `tfidf_cleaned_one`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a0a2e2",
   "metadata": {},
   "source": [
    "### 5.1 Top single term (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d7b926",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5.1.1\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 5.1.1 (2 points):** In the next cell, determine the word with the highest tfidf score for each obituary based on`tfidf_cleaned_one`. Store the result in the variable named `top_1_word`.\n",
    "\n",
    "*Hint:* This can be done with a single pandas DataFrame function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf475488",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1_word = ...\n",
    "top_1_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f4cedf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5.1.2\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 5.1.2 (2 points):** What trend do you notice about the top word for each of these obituaries?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f28bec",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b603932",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### 5.2 Top 15 terms (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fed64db",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5.2.1\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "\n",
    "\n",
    "**Question 5.2.1 (2 points):** In the next cell, determine the top 15 words with the highest tfidf score for each obituary. Store the result in the variable named `top_15_words` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f193ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_15_words = ...\n",
    "top_15_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8961b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5.2.2\n",
    "manual: True\n",
    "points: 10\n",
    "-->\n",
    "\n",
    "\n",
    "\n",
    "**Question 5.2.2 (10 points):** In the next cell, randomly sample 5 obituaries from `obits_df`. Read the 5 obituaries and briefly note whether the top 15-terms based on tf-idf capture the person based on the obituary. \n",
    "\n",
    "Make sure to print out the top-15 terms for that person as well. It might be a good idea to create one code cell and then one markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d655f46a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e12759a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691ed6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2db6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b620e9b0",
   "metadata": {},
   "source": [
    "## 6. Finding Similar Obituaries (22 points)\n",
    "\n",
    "In class we discussed how we can use cosine similarities to rank documents based on their similarities.\n",
    "\n",
    "**Question 6.1 (0 points):** In the next cell, complete the function `make_similarities_matrix()` based on the doc string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e4999e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def make_similarities_matrix(df):\n",
    "    \"\"\"\n",
    "    Given a tfidf-matrix as a dataframe, return a square (n by n) matrix where the cells indicate the cosine similarity\n",
    "    between the corresponding row and column. \n",
    "    Make sure the indices and the colum names are the name of the subject of the obituary\n",
    "    \"\"\"\n",
    "    ...\n",
    "    return similarities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bdbeec",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6.2\n",
    "manual: False\n",
    "points: \n",
    "    - 2\n",
    "    - 2\n",
    "    \n",
    "-->\n",
    "\n",
    "\n",
    "**Question 6.2 (4 points):** Now use the function to create two similarity matrices, one named `sim_df_one`, `sim_df_two`. The former should be based on `tfidf_cleaned_one` and the latter should be based on `tfidf_cleaned_two`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d1733f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df_one = ...\n",
    "sim_df_two = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f399490b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac72db01",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 6.3 Most Similar Queries (18 points)\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6.3.1\n",
    "manual: True\n",
    "points: \n",
    "    - 2\n",
    "    - 6\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 6.3.1 (8 points):** In the next cell, create a new dataframe called `most_similar_obits_df`.\n",
    "The indices should be the same as `sim_df_one` and `sim_df_two`. Create a column called `clean_text_one` where each value should indicate the obituary that is most similary (based on `sim_df_one`) to the corresponding index.\n",
    " Create a column called `clean_text_two` where each value should indicate the obituary that is most similary (based on `sim_df_two`) to the corresponding index.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bd1969f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "most_similar_obits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11fc3b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6.3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b6d237",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "In this assignment we use two different pre-processing approaches. For one approach we used the lower cased tokens and in the other other approach we used the lower cased lemmas. \n",
    "\n",
    "**Question 6.3.2 (10 points):** In the next few cells, determine whether this difference resulted in the most similar obituaries being different? If we see differences for the most similar obituaries, do we see these differences if we consider the set of 5 closest obituaries? What about the 10 closest obituaries?\n",
    "\n",
    "In addition to your code, please include a brief paragraph answering these questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "062726f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc69b4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624279ce",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad40fd15",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9322432b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c0ef34",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
