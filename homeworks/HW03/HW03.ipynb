{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef79494d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"HW03.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f722b9a4",
   "metadata": {},
   "source": [
    "\n",
    "# Homework 3 - Analzying CULPA\n",
    "\n",
    "In this assignment, you will scrape and analyze course reviews from [CULPA](http://www.culpa.info/) and\n",
    "explore if there is a difference in the words used for reviews for female and male faculty on this site.\n",
    "\n",
    "This assignment is inspired by the following studies:\n",
    "\n",
    "- Ben Schmitt's Teaching Reviews [tool](http://benschmidt.org/profGender/) described in [HigherEd](https://www.insidehighered.com/news/2015/02/09/new-analysis-rate-my-professors-finds-patterns-words-used-describe-men-and-women)\n",
    "- Giacomo Gioli's Bachelor's Thesis at ZURICH UNIVERSITY OF APPLIED SCIENCES titled [Analysing Student Comments on RateMyProfessors.com Using NLP Techniques](https://digitalcollection.zhaw.ch/bitstream/11475/21754/3/gioligia_thesis.pdf)\n",
    "- [Gender bias in student evaluations](https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/gender-bias-in-student-evaluations/1224BE475C0AE75A2C2D8553210C4E27) in  PS: Political Science& Politics 2018\n",
    "- [NCSU study](http://news.ncsu.edu/2014/12/macnell-gender-2014/) covered in [Slate](https://slate.com/human-interest/2014/12/gender-bias-in-student-evaluations-professors-of-online-courses-who-present-as-male-get-better-marks.html)\n",
    "\n",
    "\n",
    "**Deadline:** Please submit this assignment to gradescope by Thursday June 3rd at 11:59pm EST.\n",
    "\n",
    "**What to submit:** Submit this completed notebook, a pdf version of your notebook, the excel file you upload to Wordify and the two excel files Wordify will email you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4f323b",
   "metadata": {},
   "source": [
    "Let's start by importing the following libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3f1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "from datetime import datetime\n",
    "import dateutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d054b53",
   "metadata": {},
   "source": [
    "## 1. Exploring RateMyProfessor (4 points)\n",
    "\n",
    "[Ben Shcmitt](http://benschmidt.org/), a Professor at NYU, developed this [interactive chart](http://benschmidt.org/profGender/) where you can explore the words used to describe male and female teachers in about 14 million reviews from RateMyProfessor.com.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1165c342",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1.1\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "**Question 1.1 (4 points):** Spend a few minutes playing with the interactive chart. What words (besides for \"his children\" and \"her children\") do you find are used more for male faculty and which for female faculty?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f15dd59",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfede67a",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## 2. Web Scraping CULPA (30 points)\n",
    "\n",
    "We will begin this assignment by scraping CULPA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef33d78",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.2\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.1 (2 points):** Use the `requests` library to get the html of the CULPA homepage and then use BeautifulSoup to store and parse the webpage. Store the created BeautifulSoup object in the variable named `soup` \n",
    "\n",
    "*Hint 1:* Demo 12 provides an example of how to use `requests` \n",
    "\n",
    "*Hint 2:* Remember from lecture that we can parse an html page by creating a new BeautifulSoup object and initializing it with the html as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99286e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_PATH = \"http://www.culpa.info\"\n",
    "response = ...\n",
    "html = ...\n",
    "soup = ...\n",
    "response, type(soup) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d59d7c1",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### 2.1 Departments (8 points)\n",
    "\n",
    "We are going to build a crawler to traverse pages on CULPA by departments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc2372",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.2\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "On the left side of the homepage of CULPA, there is a list of departments. \n",
    "\n",
    "**Question 2.2 (1 point):** What is the class name of the div that contains the list? Assign the class name of the div to the variable called `dept_list_div_name`.\n",
    "\n",
    "*Hint:* Either use the inspect element tool in your browser that we used in the Webscraping lecture or look at the html in the soup object from the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_list_div_name = ...\n",
    "dept_list_div_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c9ab37",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "The next cell will find all tags in the html that have the class name you specified in the previous answer and store the tags in a list called `dept_list_tag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2f3c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dept_list_tag = soup.find_all(attrs={\"class\": dept_list_div_name})\n",
    "len(dept_list_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a318a0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.3\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "Looking at dept_list_tag, you should notice that there is one `ul` tag and many `li` tags.\n",
    "\n",
    "**Question 2.3 (2 points):** In the next cell, briefly describe what these html tags represent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7bd8aa",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d8d0e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.4\n",
    "manual: False\n",
    "points: \n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.4 (3 points):** Use BeautifulSoup to parse `dept_list_tag` and extract each department's name and path to the department's webpage on CULPA.  Store the results in a list of tuples and save the list to a variable named `department_tups`.\n",
    "The first element in each tuple should be the department name and the second element in each tuple should be the path for the department's page on CULPA specified by the `href`. \n",
    "\n",
    "For example, the first item in the list should be `('af-am studies', '/departments/3')`\n",
    "\n",
    "*Note:* Right now, we only want departments, not courses (everything listed under *Core* (on the left side of the page) is classes, not departments).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a42d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "department_tups = []\n",
    "\n",
    "...\n",
    "len(department_tups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed9b309",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4ea7af",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.5\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.5 (2 points):** Download each department page from `department_tups` and store them in the folder `data/html/departments`. Make sure that each html page stored in that folder ends with \".html\". The last line in the code will print out how many files are stored in `data/html/departments`.\n",
    "\n",
    "*Note:* You likely need to make a new directory called `html/` under `data/`\n",
    "\n",
    "*My code took about 34 seconds to parse and store the pages for 63 departments* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tup in tqdm(department_tups):\n",
    "...\n",
    "\n",
    "!ls data/html/departments | wc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd7dd05",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.6\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "### 2.2 Courses (20 points)\n",
    "Each department page has a list of courses and we will use that for the next part of scraping CULPA.\n",
    "\n",
    "\n",
    "**Question 2.6 (1 point):** Looking at the html of a deparment's webpage, what is the name of the class of the html div that contains the list of courses? Assign the answer as a string to the variable `courses_list_class_name`.\n",
    "\n",
    "*Hint:* You might want to use \"Inspect Element\" in the same way that we did in lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5777569",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_list_class_name = ...\n",
    "courses_list_class_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfe56e7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.7\n",
    "manual: False\n",
    "points: \n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.7 (5 points):** Loop through the stored html pages to extract the following information for each course offered by the department:\n",
    "\n",
    "1. `Department Name` - The name based on the department `box` on the department page on CULPA. \n",
    "    - For example, the name for http://www.culpa.info/departments/3 is `African American Studies`\n",
    "2. `Department Id` - the number associated with the department on CULPA. \n",
    "    - For example, the department id for `African American Studies` is 3.\n",
    "3. `Course Name` - the text specified by the `course_name` span\n",
    "4. `Course Listing` - the text specified by the `course_number` span\n",
    "5. `Course Id` - the number associated with the course on CULPA (the digit at the end of the course link) \n",
    "6. `Course Path` - the path to the course. For example, the link for the `Caribbean Cultures and Societies` course would be `courses/7188`\n",
    "    \n",
    "Stores these columns in a dataframe called `course_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec8f86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEPART_HTML_PATH = \"data/html/departments/\"\n",
    "\n",
    "...\n",
    "print(course_df.shape)\n",
    "course_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7847b7bb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108d05b6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.8\n",
    "manual: True\n",
    "points: 6\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.8 (6 points):** It is often a good idea to get a sense of the distribution of your data. In the next cell, using a horizontal bar-plot, plot the number of courses in each department. Only include the 20 departments with the most number of courses. \n",
    "\n",
    "*Hint 1:* Don't forget to use good conventions in your figure (like adding a title, naming the axis, etc).\n",
    "\n",
    "*Hint 2:* You might want to use a dataframe function that *returns a Series containing counts of unique rows in the DataFrame*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6355f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff618d26",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "#### 2.2.1 Duplicate Courses (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4732a51a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.9\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "It is very likely `course_df` contains duplicate courses.\n",
    "\n",
    "**Question 2.9 (1 points):** If this is the case, explain why this might have happened and give an example? If not, explain what steps you took earlier to prevent this and justify why these specific steps were taken? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a369d8",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1228d4fe",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.10\n",
    "manual: False\n",
    "points: \n",
    "    - 1\n",
    "    - 1\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.10 (2 points):** In the next cell, remove duplicate courses and store the resulting dataframe in the variable `course_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b273b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446591ba",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af04e27e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.11\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.11 (4 points):** In the next cell, plot the number of courses in each department after duplicate courses were removed. Below the figure, make a new markdown cell and describe any differences you might notice. If there are no differences, make sure to note that. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe02833",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e3f76b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009c653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c8922fe",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### 2.2.2 Saving Courses (1 point)\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.12\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.12 (1 point):** Now that we have extracted information about courses offered by each department, save the dataframe in a csv file called `courses.csv`. \n",
    "Make sure to save the table in the directory called `data/tables`. Lastly, do not store the index of the table when you make the new csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74312c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca71bee7",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "Saving the dataframe at this point allows us to take a break and not have to re-run the previous code when we come back to continue working. When working on a project, it is a good practice to save data from intermediate steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba8da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_df = pd.read_csv(\"data/tables/courses.csv\")\n",
    "course_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038d6ed8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.3 Download Course Reviews (9 points)\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.13\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "\n",
    "For this part we will use the list of courses stored in `course_df`.\n",
    "\n",
    "**Question 2.13 (2 points):** Download each course page stored in `course_df['Course Link']` and store them in the folder `data/html/courses`. Make sure that each html page stored in that folder ends with \".html\".\n",
    "\n",
    "*My code took about 13 minutes to parse and store the pages for 2564 courses* \n",
    "\n",
    "*Note:* While the code is running, it is a good idea to look at `data/html/courses/` to make sure the courses were stored there. \n",
    "\n",
    "You might want to answer Question 2.13.1 while the next cell is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d2878",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "!ls data/html/courses | wc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271930f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.13.1\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "In this assignment we are downloading all the webpages and then parsing them, rather than extracting just the data we want when crawling the website.\n",
    "\n",
    "**Question 2.13.1 (2 points):** In the next cell, briefly describe what you think are the pro's and con's for these two different approaches?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d637fa",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5e9ea1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 2.4 Extracting course reviews (13 points)\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.14\n",
    "manual: False\n",
    "points: \n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "-->\n",
    "\n",
    "\n",
    "Now that we have stored the html of every course from CULPA, we can now extract the course reviews.\n",
    "\n",
    "**Question 2.14 (5 points):** Loop through the stored html pages in `data/html/courses` and parse the downloaded webpages using BeautifulSoup. You'll note that each course webage has a list of reviews. For each review on each course webpage, extract the following information:\n",
    "\n",
    "1. `Prof` - the name of the professor teaching the course\n",
    "1. `Date` - the date of when the review was written\n",
    "1. `Course Id` -  the number associated with the course on CULPA \n",
    "1. `Course Name`\n",
    "1. `Course Listing` - (the `course number` in the html)\n",
    "1. `Review` - the text of the review\n",
    "\n",
    "\n",
    "Store these columns in a dataframe called `review_df`. Make sure to only include reviews that have not been tagged as \"old\"\n",
    "\n",
    "*Hint:* What is the class name of the div that contains a review? In each of those divs, what is the class name that contains the actual content of the review, what is the class name that contains the meta data of the review (like date, course number, professor's name, etc)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76af182",
   "metadata": {},
   "outputs": [],
   "source": [
    "COURSE_HTML_PATH = \"data/html/courses/\"\n",
    "\n",
    "...\n",
    "review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ae585",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254a3be3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### 2.4.1 Duplicate Reviews (8 points)\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.15\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "\n",
    "It is very likely `review_df` contains duplicate review.\n",
    "\n",
    "**Question 2.15 (2 points):** If this is the case, explain why this might have happened and give an example? If not, explain what steps were taken earlier to prevent this and justify why specific steps were taken? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25702abe",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba7c9f6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.16\n",
    "manual: True\n",
    "points: 3\n",
    "-->\n",
    "Its a good idea to explore different aspects of your collected dataset.\n",
    "\n",
    "**Question 2.16 (3 points):** Plot the number of reviews each faculty member received. Only show the 15 faculty that received the most reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e94631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['Prof'].value_counts().head(15).plot(kind='barh') ## SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5641514",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.17\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "Let's now drop duplicate reviews.\n",
    "\n",
    "**Question 2.17 (1 point):** In the next cell, drop duplicate reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9080dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review_df.shape)\n",
    "review_df = ...\n",
    "review_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9edfae6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.18\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.18 (2 points):** In the next cell, plot the number of reviews each faculty received after reviews courses were removed. Below the figure, make a new markdown cell and describe any differences you might notice. If there are no differences, make sure to note that. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a0891",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['Prof'].value_counts().head(15).plot(kind='barh') ## SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123ad042",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "#### 2.4.2 Saving Reviews\n",
    "\n",
    "The next cell will now save the dataframe of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42558fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.to_csv(\"data/tables/reviews.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50818c4",
   "metadata": {},
   "source": [
    "## 3. Processing reviews (23 points)\n",
    "\n",
    "### 3.1 Cleaning Text (5 points)\n",
    "\n",
    "Now that we have the reviews, we will start cleaning the text for each review.\n",
    "However, let's first update the list of stopwords that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c3b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "keep_words = set(['he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself'])\n",
    "remove_stop_words = list(set(stopwords.words('english')).difference(keep_words))\n",
    "\" \".join(remove_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90664c6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.1\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "**Question 3.1 (1 point):** Briefly explain the previous code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6d57c8",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a441ae7f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.2\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "**Question 3.2 (2 points):** Write a function called `clean_text` that processes each review. Make sure the function:\n",
    "\n",
    "- lower cases the review\n",
    "- tokenizes the review\n",
    "- removes stop words and punctuation \n",
    "\n",
    "*Note:* Use the updated list of stopwords from the previous question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e49bb96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(input_string):\n",
    "    ...\n",
    "    \n",
    "    \n",
    "clean_text(review_df['Review'].iloc[0]), review_df['Review'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4063b7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.3\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "**Question 3.3 (2 points):** In the next cell, apply the function to the dataframe and store the cleaned reviews in a new column called `Cleaned Review`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f7b9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26f57a3",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### 3.2 Inferring Professor Gender (18 points)\n",
    "\n",
    "We are going to explore if there is a difference in the words used for reviews for female and male faculty.\n",
    "CULPA does not contain metadata for the gender of a professor so we will need to infer this from the text. \n",
    "\n",
    "For this section, we will infer the professor's gender by counting the number of gendered pro-nouns used in the review. This is something that is commonly done. \n",
    "For example, [Serina Chang](https://serinachang5.github.io/) (Columbia ugrad at the time) and [Kathleen McKeown](http://www.cs.columbia.edu/~kathy/) (Columbia CS Prof)\n",
    " write in their 2019 paper titled [*Automatically Inferring Gender Associations from Language*](https://www.aclweb.org/anthology/D19-1579.pdf)  \n",
    ">We labeled each review with the gender of the professor\n",
    "whom it was about, which we determined by comparing the count of male versus female pronouns\n",
    "over all reviews for that professor. This method\n",
    "was again effective, because the reviews are expressly written about a certain professor, so the\n",
    "pronouns typically resolve to that professor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af1472",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.4\n",
    "manual: False\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "**Question 3.4 (2 points):** Add at least two more gendered pronouns to the sets `male_pronouns` and `female_pronouns`.\n",
    "\n",
    "*Hint:* If any of the pronouns are in the set of stopwords, you might need to remove the pronoun from the set of stopwords above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9968b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_pronouns = set([\"he\"])\n",
    "female_pronouns = set([\"she\"])\n",
    "\n",
    "...\n",
    "...\n",
    "\n",
    "male_pronouns, female_pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8424f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST \n",
    "assert len(male_pronouns) >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15111bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST \n",
    "assert len(female_pronouns) >= 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaa2df3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.5\n",
    "manual: False\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "**Question 3.5 (2 points):** Implement the function `infer_gender` that determines the gender of a professor based on the content of the review. The function should return `\"M\"`, `\"F\"`, or `\"-\"` if the professor is male, female, or if the gender is unknown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "acb00d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_gender(input_string):\n",
    "    \n",
    "    ...\n",
    "    \n",
    "infer_gender(review_df['Cleaned Review'].iloc[0]), review_df['Cleaned Review'].iloc[0]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8ef4d1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.6\n",
    "manual: False\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "**Question 3.6 (2 points):** Apply `infer_gender` to the cleaned reviews and save the infered gender in a new column called `Prof_Gender`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7dd25041",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "review_df['Prof_Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dbddb3",
   "metadata": {},
   "source": [
    "#### 3.2.1 Validating Inferred Genders (11 points)\n",
    "\n",
    "It is important to validate the method we just applied to determine the gender of a professor based on the text of a review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb82e222",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.7\n",
    "manual: False\n",
    "points: 4\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 3.7 (4 points):** In the next cell, write code to deterime if there any professors that have more than one of the 3 possible labels? Store the list of professors that were assigned more than one of the 3 possible labels in the variable named `multiple_gender_labels`\n",
    "\n",
    "*Note:* **Do not** write a for loop to traverse the dataframe. This will result in received 0 points for this question.\n",
    "\n",
    "*Hint:* Use the dataframe operation ''involves some combination of splitting the object, applying a function, and combining the results of the dataframe method that will combine''."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "630300b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_gender_series = ...\n",
    "multiple_gender_labels = ...\n",
    "len(multiple_gender_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e5638f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.8\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "It make senses for a professor to have a \"-\" label and a \"M\" or \"F\" label. However, if our `infer_gender()` function works as intended, a prof most likely would not be labeled as both `F` and `M`.\n",
    "\n",
    "**Question 3.8 (1 points):** Write a function called `check_group_gender` that given a group (dataframe), determines whether there exists at least one row with a \"M\" label for `Prof_Gender` and one with a \"F\" label. The function should return `False` if the group has both `F` and `M` labels in the `Prof_Gender` column, and `True` if it does not.\n",
    "\n",
    "*Hint 1:* You can assume the dataframe has the same columns as `review_df`.\n",
    "\n",
    "*Hint 2:* Your function should only use one of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9fd444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_group_gender(group):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a762c236",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.9\n",
    "manual: True\n",
    "points: 4\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 3.9 (4 points):** Group `review_df` by `Prof` and apply the function `check_group_gender` to each group to determine if there are professors that have been tagged with both \"M\" and \"F\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aff3553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_gender_series = ...\n",
    "dup_gender_profs = ...\n",
    "dup_gender_profs_df = ...\n",
    "dup_gender_profs_df.sort_values(\"Prof\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f49caa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.10\n",
    "manual: False\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "You'll notice that there are indeed some professors that have both gendered labels. \n",
    "\n",
    "**Question 3.10 (2 points):** Looking at some reviews for any one of these Professors, provide a rationale why they had both gendered labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f75066",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6acf09",
   "metadata": {},
   "source": [
    "The next cell will tell us the total number of reviews and the number of reviews with a Professor who is tagged with both \"M\" and \"F\" based on their reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f7a36d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.shape[0], dup_gender_profs_df.shape[0], dup_gender_profs_df.shape[0]/review_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a406fc9f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 3.2.2 Cleaning Infered Gender (1 point)\n",
    "\n",
    "We can come up with methods to automatically fix these incorrect labels. For example, if the overwhelming majority of a professor's review was tag with \"F\" and just one review was tagged as \"M\", we could simple convert that one review to \"M\". \n",
    "\n",
    "However, remember the 80-20 effort-reward rule. Since these are a small percentage of our reviews (in my solutions it was just 2.2% of all reviews), let's go ahead and just remove reviews for these faculty members. \n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.11\n",
    "manual: False\n",
    "points: 1\n",
    "-->\n",
    "\n",
    "**Question 3.11 (1 point):** Remove the rows where the Professor is listed in `dup_gender_profs`. Store the resulting dataframe in `gender_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5f282a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = ...\n",
    "gender_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cc364708",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST\n",
    "assert len(gender_df.groupby('Prof').apply(check_group_gender).value_counts().keys()) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a37ee",
   "metadata": {},
   "source": [
    "We have just removed a small percentage of reviews from professors that had conflicting gender labels. Running the next cell will give statistics of how many professors have the following set of gender labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "87dbc303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genders(row):\n",
    "    return \" \".join(set(row['Prof_Gender']))\n",
    "\n",
    "gender_vc = gender_df.groupby('Prof').apply(genders).value_counts()\n",
    "gender_vc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f087a1",
   "metadata": {},
   "source": [
    "You likely will have some professors in your dataset that were tagged with a gender label and a \"-\" label. Running the next cell will determine the percetange of professors who have a gender label and a \"-\" label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0555dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(gender_vc['- M'] + gender_vc['- F']) / gender_vc.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b3ab9",
   "metadata": {},
   "source": [
    "Since this number is not that small (about 16% in my solution), we should go ahead convert the `-` labels to `M` or `F` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc9cae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_gender(group):\n",
    "    if 'M' in set(group['Prof_Gender']):\n",
    "        return 'M'\n",
    "    elif 'F' in set(group['Prof_Gender']):\n",
    "        return 'F'\n",
    "    else:\n",
    "        return '-'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d085b16",
   "metadata": {},
   "source": [
    "We will now create a dictionary that maps the name of the professor to a single inferred gender label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b00212a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "name2gender = gender_df.groupby('Prof').apply(which_gender).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4518f3a4",
   "metadata": {},
   "source": [
    "The next cell will now use that dictionary to update the inferred gender column in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6348fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = gender_df.assign(Prof_Gender=gender_df['Prof'].map(lambda x: name2gender[x] if name2gender[x] != '-' else np.nan))\n",
    "gender_df['Prof_Gender'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a641b9",
   "metadata": {},
   "source": [
    "Finally, we will now remove any reviews where we could not infer the gender of the professor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "54eed8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = gender_df.dropna(subset=['Prof_Gender']) \n",
    "gender_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e27fc",
   "metadata": {},
   "source": [
    "## 4. Discovering Biased Terms (12 points)\n",
    "\n",
    "In this course we discussed point-wise mutual information, a metric used to discover connotations between random variables. This [blog post on Towards Data Science](https://towardsdatascience.com/harvesting-the-power-of-mutual-information-to-find-bias-in-your-nlp-dataset-c172c0dddebe) provides a nice detailed discussion on how we can use pmi (and its variants) to identify biased or discriminative terms.\n",
    "\n",
    "In the original assignment, we would have now implemented PMI and applied it to our data. Instead, we will use [Wordify](https://wordify.unibocconi.it/index) *to identify words that discriminate categories in* the dataset you just collected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b8eac3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4.1\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "**Question 4.1 (2 points)** Use pandas to create an Excel file with two columns named `text` and `label`. \n",
    "For each row, the `text` should be the cleaned review and the `label` should the corresponding `Prof_Gender`.\n",
    "\n",
    "*Hint:* You might need to install openpyxl using pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "33cef9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46102cc8",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "Now, upload the excel sheet to Wordify twice. The first time, use the default threshold of 0.3. For the second time choose another threshold.\n",
    "\n",
    "After some time, you should receive an email from Wordify with results. The email will have an attached file that *contains two sheets: one with the positive indicators for each label and one with the negative indicators (note that if you have only two labels, the positive indicators of one label are the negative ones of the other, and vice versa).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6c3b2f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4.2\n",
    "manual: True\n",
    "points: 10\n",
    "-->\n",
    "\n",
    "**Question 4.2 (10 points):**  Once you receive results from Wordify, look through the results.\n",
    "In the next cell, write a paragraph answering the following questions:\n",
    "\n",
    "- Are there many biased terms in the dataset?\n",
    "- Are the biased terms you found in question 1.1 also biased terms on CULPA?\n",
    "- Were there many differences in discriminative terms between the two thresholds? If so, what were they?\n",
    "- Are the course reviews on CULPA biased like the course reviews on Rate My Professor or similar sites? If not, why do you think that might be the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea6c7d",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5889f29",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# 5. Feedback (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d75938",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5.1\n",
    "manual: false\n",
    "points: 1   \n",
    "-->\n",
    "\n",
    "**Question:** Roughly how many hours did you spend on this assignment. Assign the total number of hours to the variable `time_spent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a490c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_spent = ...\n",
    "time_spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c15d0cb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d2884",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5.2\n",
    "manual: True\n",
    "points: 1   \n",
    "-->\n",
    "\n",
    "**Optional:** Provide any comments or feedback below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d12a0bd",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadfa82e",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "**Submission:** Submit this completed notebook, a pdf version of your notebook, the excel file you upload to Wordify and the two excel files Wordify will email you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b2b671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7096a3c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c3fbcd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba6f3f8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09322700",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c27409f",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
