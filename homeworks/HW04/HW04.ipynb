{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abce56f8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"HW04.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593dbb42",
   "metadata": {},
   "source": [
    "# Homework 04 (88 points)\n",
    "\n",
    "In this tutorial, we are going to collect Tweets using the Twitter API and then use Naive Bayes and Logistic Regression to classify the tweets. You can work on this assignment in pairs\n",
    "\n",
    "\n",
    "**Deadline:** Please submit this assignment to gradescope by Thursday June 10th at 11:59pm EST.\n",
    "\n",
    "**What to submit:** Submit this completed notebook and a pdf version of your notebook. Only one person from each group needs to upload the completed assignment.\n",
    "\n",
    "**Note:** Do not use a for loop to iterate through a dataframe or pandas column. You will lose points in any solution where you loop through a dataframe using a for loop.   \n",
    "\n",
    "Let's start by importing the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecdf16a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import nltk\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5186f2fc",
   "metadata": {},
   "source": [
    "## 1. Naive Bayes (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bebe4e7",
   "metadata": {},
   "source": [
    "Below we have taken sentences from Emily Bronte's work and William Shakespeare's work. Your task is to compute the priors and likelihoods based on the training examples in order predict the author of the two test examples. You can use a calculator to compute these probabilities.\n",
    "\n",
    "| text | author |\n",
    "|----|-----|\n",
    "| from thought of grief are free | \tb |\n",
    "| an earnest grief a strong desire |\tb |\n",
    "| no fear of grief in her bright eyes should quiver | \tb |\n",
    "| and love I laugh to scorn | \tb |\n",
    "| and yet, love knows it is a greater grief | s | \n",
    "| that thou hast her it is not all my grief | s |\n",
    "|<caption>**Training Examples**</caption> |\n",
    "\n",
    "| doc_id| text | author |\n",
    "|----|-----|----|\n",
    "|doc_{1} | she carved thee for her seal and meant thereby | ? |\n",
    "|doc_{2} | no love toward others in that bosom sits | ? |\n",
    "|<caption>**Test Examples**</caption> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59215650",
   "metadata": {},
   "source": [
    "**Question 1.1 (2 points):** In the next cell, compute the priors and replace the question marks with the values estimated from the training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cb58ef",
   "metadata": {},
   "source": [
    "\n",
    "| P(Y) |    | \n",
    "| ---- | ---|\n",
    "| P(b) |  ? |\n",
    "| P(s) |  ? |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec84e911",
   "metadata": {},
   "source": [
    "**Question 1.2 (10 points):** In the next cell, compute the liklihoods and replace the question marks with the values estimated from the training data. You should use laplacian (add-one) smoothing, similar to the equation in the last slide of lecture 15. \n",
    "\n",
    "\n",
    "*Note:* If a word-type in the test set does not appear in the vocabulary of the training set, use the same approach that we did in the example in class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f9b07",
   "metadata": {},
   "source": [
    "\n",
    "| P(x_{i} \\| b) | | P(x_{i} \\| c) | |\n",
    "| ---- | ---|------| ---- |\n",
    "| P(from \\| b) |  ? |  P(from \\| c) |  ? |\n",
    "| P(thought \\| b) |  ? | P(thought \\| c) |  ? |\n",
    "| P(of \\| b) |  ? | P(of \\| c) |  ? |\n",
    "| P(grief \\| b) |  ? | P(grief \\| c) |  ? |\n",
    "| P(are \\| b) |  ? | P(are \\| c) |  ? |\n",
    "| P(free \\| b) |  ? | P(free \\| c) |  ? |\n",
    "| P(no \\| b) |  ? | P(no \\| c) |  ? |\n",
    "| P(love \\| b) |  ? | P(love \\| c) |  ? |\n",
    "| P(towrds \\| b) |  ? | P(towrds \\| c) |  ? |\n",
    "| P(others \\| b) |  ? | P(others \\| c) |  ? |\n",
    "| P(in \\| b) |  ? |  P(in \\| c) |  ? |\n",
    "| P(that \\| b) |  ?  | P(that \\| c) |  ? |\n",
    "| P(bosom \\| b) |  ?  | P(bosom \\| c) |  ? |\n",
    "| P(sits \\| b) |  ? | P(sits \\| c) |  ? |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242091a3",
   "metadata": {},
   "source": [
    "**Question 1.3 (6 points):** Combining the estimated priors and liklihoods, fill in the following log-probabilities:\n",
    "\n",
    "*Hint:* Slide 12 from lecture 17 has the naive bayes equation based on log-probabilities.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4f3d40",
   "metadata": {},
   "source": [
    "| P(b \\| X) | | P(s \\| X ) | |\n",
    "| ----------|--|-----------|--|\n",
    "| P(b \\| doc_{1}) | ? | P(s \\| doc_{1}) | ? |\n",
    "| P(b \\| doc_{2}) | ? | P(s \\| doc_{2}) | ? |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831cd455",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1.4\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "**Question 1.4 (2 points):** Based on the above, who is the author of doc_{1} and who is the author of doc_{2}?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f393de",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394345d7",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## 2. Identification of Informative COVID-19 English Tweets (67 points)\n",
    "\n",
    "Now we will turn our attention to the main part of the homework, using the Twitter API to collect tweets, and then using sklearn to train classifiers to classify Tweets as being informative about COVID-19.\n",
    "\n",
    "This assignment is based on a [Shared Task at the WNUT 2020 Workshop](https://www.aclweb.org/anthology/2020.wnut-1.41.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be978a9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.1\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "**Question 2.1 (2 points):** According to the shared task paper linked above, in your own words, how do they define a tweet that is \"informative\" about COVID-19 and how do they define a tweet that is \"uninformative\" about COVID-19?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae49f2c3",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0a4b04",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### 2.1 Collect data from Twitter (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c06675",
   "metadata": {},
   "source": [
    "In the data directory you will find the following three csv files: `train.csv`, `dev.csv`, and `test.csv`.<br>\n",
    "Each file contains two columns: `Id` (the twitter ID of the tweet) and `Label` (Informative or Uninformative)<br>\n",
    "The files respectively have 6936, 1000,  and 2000 examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097dfb92",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.2\n",
    "manual: True\n",
    "points: 13\n",
    "-->\n",
    "\n",
    "**Question 2.2 (13 points):** In the next cell, use the Tweepy API to get the text of the tweets based on each tweet's ID. For each datasplit, create a dataframe where the columns are `ID`, `Text`, and `Label`.\n",
    "    \n",
    "*Note:* It is likely that not all tweets will still be available.\n",
    "\n",
    "*Note:* This requires you to create an app on the Twitter developers site.\n",
    "\n",
    "*Hint:* Everything you need to complete this quesiton can be found in Demo13.\n",
    "\n",
    "**Important:** The text of the tweets are available directly from [Github](https://github.com/VinAIResearch/COVID19Tweet). You can elect to use that data directly instead, but if you do so and do not use the Tweepy API, you will not receive credit for section 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba075139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1241490299215634434</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245916400981381130</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1241132432402849793</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1236107253666607104</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1239673817552879619</td>\n",
       "      <td>UNINFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6931</th>\n",
       "      <td>1241325232415105025</td>\n",
       "      <td>UNINFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6932</th>\n",
       "      <td>1235624084089778176</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6933</th>\n",
       "      <td>1246018213995044870</td>\n",
       "      <td>UNINFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6934</th>\n",
       "      <td>1239750367329439744</td>\n",
       "      <td>UNINFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6935</th>\n",
       "      <td>1241528434624327680</td>\n",
       "      <td>UNINFORMATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6936 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Id          Label\n",
       "0     1241490299215634434    INFORMATIVE\n",
       "1     1245916400981381130    INFORMATIVE\n",
       "2     1241132432402849793    INFORMATIVE\n",
       "3     1236107253666607104    INFORMATIVE\n",
       "4     1239673817552879619  UNINFORMATIVE\n",
       "...                   ...            ...\n",
       "6931  1241325232415105025  UNINFORMATIVE\n",
       "6932  1235624084089778176    INFORMATIVE\n",
       "6933  1246018213995044870  UNINFORMATIVE\n",
       "6934  1239750367329439744  UNINFORMATIVE\n",
       "6935  1241528434624327680  UNINFORMATIVE\n",
       "\n",
       "[6936 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18764812",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.3\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "**Question 2.3 (2 points):** In the next cell, briefly describe how many Tweets were you able to collect for each of the train, dev, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f760cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350b54f4",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da813cac",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### 2.2 Classification (12 points)\n",
    "\n",
    "The goal of this part of the assignmnet is for you to gain comfort using sklearn to train a classifier. In the next cell we provided code to train a logisitc regression classifier. Run the code to see the model's accuray on the training and development sets.\n",
    "\n",
    "*Note:* This code assumes you created variables called `train_df` and `dev_df` in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e719c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # Imports the CountVectorizer from sklearn\n",
    "from sklearn.linear_model import LogisticRegression # Imports the LogisticRegression from sklearn\n",
    "import nltk # imports the nltk library\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_df['Text'])\n",
    "lr_model = LogisticRegression(max_iter = 1e4)\n",
    "lr_model.fit(X_train, train_df['Label'])\n",
    "lr_model.score(X_train, train_df['Label']), lr_model.score(vectorizer.transform(dev_df['Text']), dev_df['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965b9e20",
   "metadata": {},
   "source": [
    "\n",
    "**Question 2.4 (4 points):** In the cell above, please add a comment describing each line of code that we provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265f03e2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.5\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "In the cell above, when we used the CountVectorizer's fit_transform method, we used sklearn's built in tokenizer. The data we are using in this example are Tweets.\n",
    "\n",
    "**Question 2.5 (2 points):** In the next cell, train a logistic regression classifier like above but first tokenize the Tweets using nltk's Twitter Tokenizer.\n",
    "\n",
    "*Note:* Demo 13 provides an example on how to use the nltk's Twitter Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c38e85df",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3239744",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.6\n",
    "manual: True\n",
    "points: 6\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.6 (6 points):** In the next cell briefly describe how the model's accuracy change and sample 2 examples where the two models' predictions were different. \n",
    "\n",
    "*Note:* You should create a new code cell to find 2 examples where the models' predictions were different. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148b38cf",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a86ecfd",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### 2.3 TF-IDF features (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7bbec",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.7\n",
    "manual: True\n",
    "points: 4\n",
    "-->\n",
    "\n",
    "\n",
    "In the previous two examples, we trained models using the CountVectorizer. So far in the class we used tf-idf as a way to find \"interesting\" words. However, we can also use tf-idf vectors as our feature vectors.\n",
    "\n",
    "**Question 2.7 (4 points):** In the next cell, train two logistic regression classifiers using tf-idf vectors as features. The first model should use sklearn's tokenization (like the first example above) and the second model should use nltk's Twitter Tokenizer (like the second example).  Make sure the cell prints out each models' accuracy on the training and development sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f42768c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2062b0e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.8\n",
    "manual: True\n",
    "points: 6\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.8 (6 points):** In the next cell, briefly describe whether you see an improvement on the development set using TF-IDF vectors compared to CountVectors. Also, sample a few examples where the models' predictions changed when you used TF-IDF vectors compared to CountVectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83ece7",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deee218b",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### 2.4 Hyper-parameter Tuning (20 points)\n",
    "\n",
    "In Lecture 18 we discussed hyper-parameter tuning and walked through an example in the lecture's demo. Here, you will now get to choose a hyper-parameter to tune on the development set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37b8069",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.9\n",
    "manual: True\n",
    "points: 4\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.9 (4 points):** Looking at the LogisticRegression [documentation online](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), choose a hyper-parameter that you would like to tune. In the next cell, briefly describe which hyper-parameter you would like to tune.\n",
    "\n",
    "*Note:* The hyper-parameter you choose should be one where you specify a real value (i.e. a number)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bee578e",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff60b10",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.10\n",
    "manual: True\n",
    "points: 14\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.10 (14 points):** In the next cell, now loop through at least 15 values of the hyper-parameter and train one model for each value of the hyper-parameter. Make sure to evaluate each model on the development set.\n",
    "The code cell should create a line plot where the x-axis represents the hyper-parameter value and the y-axis represents the accuracy. Your figure should have two lines, one for accuracy on the training set and one for accuracy on the development set.\n",
    "\n",
    "\n",
    "*Note:* Use your results above to determine whether you should use TF-IDF or CountVectors as feature and whether you should use sklearn's built-in tokenizer or nltk's Twitter Tokenizer. \n",
    "\n",
    "*Hint:* Demo18 provides an example of creating a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2340f28b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a72a61c8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2.11\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "\n",
    "\n",
    "**Question 2.11 (2 points):** Now, that you have determined the best value for the hyper-paramater, train a logistic regression model with that value and finally evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a502f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca619718",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## 3. Feedback (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbbfa0f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.1 \n",
    "manual: false\n",
    "points: 1   \n",
    "-->\n",
    "\n",
    "**Question 3.1 (1 point):** Roughly how many hours did you spend on this assignment. Assign the total number of hours to the variable `time_spent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b7fa5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_spent = ...\n",
    "time_spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80b6b0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb55599",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3.2\n",
    "manual: True\n",
    "points: 0 \n",
    "-->\n",
    "\n",
    "**Optional:** Provide any comments or feedback below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcadc26",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ff4528",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5ec7fd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b27b52",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc4e5da",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d29262",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
